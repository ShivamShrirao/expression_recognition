{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../face_recognition/haarcascade_frontalface_default.xml')\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=\"../facial_expressions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(IMG_PATH+\"icml_face_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(to_replace=\"PrivateTest\",value=\"Testing\")\n",
    "df=df.replace(to_replace=\"PublicTest\",value=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>Testing</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>Testing</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion     Usage                                             pixels\n",
       "0            0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1            0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2            2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3            4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4            6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
       "...        ...       ...                                                ...\n",
       "35882        6   Testing  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
       "35883        3   Testing  178 174 172 173 181 188 191 194 196 199 200 20...\n",
       "35884        0   Testing  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
       "35885        3   Testing  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
       "35886        2   Testing  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
       "\n",
       "[35887 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_keypoints(image):\n",
    "    gray=image\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (face_dim, face_dim))\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    param=[0,0,face_dim,face_dim]\n",
    "    shape=predictor(gray,dlib.rectangle(*param))\n",
    "    xlist=[]\n",
    "    ylist=[]\n",
    "    for i in range(68):\n",
    "        xlist.append(np.float32(shape.part(i).x))\n",
    "        ylist.append(np.float32(shape.part(i).y))\n",
    "    xmean = np.mean(xlist)\n",
    "    ymean = np.mean(ylist)\n",
    "#     plt.imshow(gray,cmap='gray')\n",
    "#     plt.scatter(xlist,ylist, marker='.')\n",
    "#     plt.show()\n",
    "    xcentral = [(x-xmean) for x in xlist]\n",
    "    ycentral = [(y-ymean) for y in ylist]\n",
    "    res=[]\n",
    "    for (x,y) in zip(xcentral,ycentral):\n",
    "        res.append(x)\n",
    "        res.append(y)\n",
    "    return (np.asarray(res)/face_dim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"Training\":[],\"Testing\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35887            28980     34459  "
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    print(\"\\r\",i+1,end=\" \")\n",
    "    row=df.iloc[i]\n",
    "    img=np.array(list(map(np.uint8,row[2].split()))).reshape(48,48)\n",
    "    data[row[1]].append([row[0],ret_keypoints(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data.pkl\",\"wb\") as f:\n",
    "#     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=np.arange(len(XXD))\n",
    "# for i in range(5):\n",
    "#     np.random.shuffle(s)\n",
    "#     XXD=XXD[s]\n",
    "#     YYD=YYD[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,model_from_json\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,activation='relu', input_shape=(68*2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(emotions),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 1024)              140288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,166,855\n",
      "Trainable params: 1,162,503\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "XDB=np.vstack(np.asarray(data[\"Training\"])[:,1])\n",
    "YDY=np.asarray(data[\"Training\"])[:,0]\n",
    "YDB=np.zeros((len(YDY),len(emotions)))\n",
    "for i in range(len(YDB)):\n",
    "    YDB[i][YDY[i]]=1\n",
    "XTB=np.vstack(np.asarray(data[\"Testing\"])[:,1])\n",
    "YTY=np.asarray(data[\"Testing\"])[:,0]\n",
    "YTB=np.zeros((len(YTY),len(emotions)))\n",
    "for i in range(len(YTB)):\n",
    "    YTB[i][YTY[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extra_data.pkl', 'rb') as f:\n",
    "    exD,eyD = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "XDB=np.concatenate((XDB,exD))\n",
    "YDB=np.concatenate((YDB,eyD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(len(XDB))\n",
    "for i in range(5):\n",
    "    np.random.shuffle(s)\n",
    "    XDB=XDB[s]\n",
    "    YDB=YDB[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32955 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "32955/32955 [==============================] - 10s 307us/sample - loss: 1.6506 - accuracy: 0.3841 - val_loss: 1.7176 - val_accuracy: 0.3126\n",
      "Epoch 2/100\n",
      "32955/32955 [==============================] - 8s 255us/sample - loss: 1.4670 - accuracy: 0.4359 - val_loss: 1.7464 - val_accuracy: 0.3110\n",
      "Epoch 3/100\n",
      "32955/32955 [==============================] - 8s 245us/sample - loss: 1.4218 - accuracy: 0.4525 - val_loss: 1.6110 - val_accuracy: 0.3344\n",
      "Epoch 4/100\n",
      "32955/32955 [==============================] - 10s 291us/sample - loss: 1.3990 - accuracy: 0.4623 - val_loss: 1.4686 - val_accuracy: 0.4118\n",
      "Epoch 5/100\n",
      "32955/32955 [==============================] - 8s 242us/sample - loss: 1.3825 - accuracy: 0.4707 - val_loss: 1.5474 - val_accuracy: 0.3826\n",
      "Epoch 6/100\n",
      "32955/32955 [==============================] - 8s 228us/sample - loss: 1.3754 - accuracy: 0.4696 - val_loss: 1.6248 - val_accuracy: 0.3605\n",
      "Epoch 7/100\n",
      "32955/32955 [==============================] - 7s 223us/sample - loss: 1.3582 - accuracy: 0.4749 - val_loss: 1.9131 - val_accuracy: 0.2976\n",
      "Epoch 8/100\n",
      "32955/32955 [==============================] - 8s 233us/sample - loss: 1.3478 - accuracy: 0.4804 - val_loss: 1.6424 - val_accuracy: 0.3639\n",
      "Epoch 9/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.3432 - accuracy: 0.4851 - val_loss: 1.6038 - val_accuracy: 0.3661\n",
      "Epoch 10/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.3372 - accuracy: 0.4872 - val_loss: 1.5334 - val_accuracy: 0.3856\n",
      "Epoch 11/100\n",
      "32955/32955 [==============================] - 8s 229us/sample - loss: 1.3295 - accuracy: 0.4853 - val_loss: 1.6079 - val_accuracy: 0.3728\n",
      "Epoch 12/100\n",
      "32955/32955 [==============================] - 7s 222us/sample - loss: 1.3218 - accuracy: 0.4906 - val_loss: 1.4540 - val_accuracy: 0.4505\n",
      "Epoch 13/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.3145 - accuracy: 0.4932 - val_loss: 1.5806 - val_accuracy: 0.3661\n",
      "Epoch 14/100\n",
      "32955/32955 [==============================] - 8s 233us/sample - loss: 1.3091 - accuracy: 0.4945 - val_loss: 2.2873 - val_accuracy: 0.2485\n",
      "Epoch 15/100\n",
      "32955/32955 [==============================] - 8s 246us/sample - loss: 1.3009 - accuracy: 0.4989 - val_loss: 1.4982 - val_accuracy: 0.4202\n",
      "Epoch 16/100\n",
      "32955/32955 [==============================] - 8s 244us/sample - loss: 1.2985 - accuracy: 0.4986 - val_loss: 1.6417 - val_accuracy: 0.3775\n",
      "Epoch 17/100\n",
      "32955/32955 [==============================] - 8s 231us/sample - loss: 1.2922 - accuracy: 0.4999 - val_loss: 1.5207 - val_accuracy: 0.4146\n",
      "Epoch 18/100\n",
      "32955/32955 [==============================] - 7s 217us/sample - loss: 1.2893 - accuracy: 0.5025 - val_loss: 1.7464 - val_accuracy: 0.2820\n",
      "Epoch 19/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.2820 - accuracy: 0.5030 - val_loss: 1.4735 - val_accuracy: 0.4113\n",
      "Epoch 20/100\n",
      "32955/32955 [==============================] - 7s 228us/sample - loss: 1.2825 - accuracy: 0.5037 - val_loss: 1.4057 - val_accuracy: 0.4622\n",
      "Epoch 21/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.2732 - accuracy: 0.5064 - val_loss: 1.3728 - val_accuracy: 0.4622\n",
      "Epoch 22/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.2713 - accuracy: 0.5098 - val_loss: 1.7510 - val_accuracy: 0.3435\n",
      "Epoch 23/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.2634 - accuracy: 0.5131 - val_loss: 1.6516 - val_accuracy: 0.3675\n",
      "Epoch 24/100\n",
      "32955/32955 [==============================] - 8s 242us/sample - loss: 1.2610 - accuracy: 0.5139 - val_loss: 1.5048 - val_accuracy: 0.4199\n",
      "Epoch 25/100\n",
      "32955/32955 [==============================] - 8s 244us/sample - loss: 1.2548 - accuracy: 0.5139 - val_loss: 1.4000 - val_accuracy: 0.4720\n",
      "Epoch 26/100\n",
      "32955/32955 [==============================] - 7s 224us/sample - loss: 1.2567 - accuracy: 0.5135 - val_loss: 1.6030 - val_accuracy: 0.4015\n",
      "Epoch 27/100\n",
      "32955/32955 [==============================] - 7s 224us/sample - loss: 1.2481 - accuracy: 0.5212 - val_loss: 1.4876 - val_accuracy: 0.4425\n",
      "Epoch 28/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.2453 - accuracy: 0.5207 - val_loss: 1.5086 - val_accuracy: 0.4129\n",
      "Epoch 29/100\n",
      "32955/32955 [==============================] - 7s 222us/sample - loss: 1.2397 - accuracy: 0.5206 - val_loss: 1.4752 - val_accuracy: 0.4285\n",
      "Epoch 30/100\n",
      "32955/32955 [==============================] - 7s 224us/sample - loss: 1.2358 - accuracy: 0.5233 - val_loss: 1.4941 - val_accuracy: 0.3954\n",
      "Epoch 31/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.2340 - accuracy: 0.5238 - val_loss: 1.7689 - val_accuracy: 0.3441\n",
      "Epoch 32/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.2275 - accuracy: 0.5235 - val_loss: 1.4772 - val_accuracy: 0.4199\n",
      "Epoch 33/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.2268 - accuracy: 0.5252 - val_loss: 1.5357 - val_accuracy: 0.4060\n",
      "Epoch 34/100\n",
      "32955/32955 [==============================] - 7s 222us/sample - loss: 1.2234 - accuracy: 0.5306 - val_loss: 1.6125 - val_accuracy: 0.3862\n",
      "Epoch 35/100\n",
      "32955/32955 [==============================] - 8s 232us/sample - loss: 1.2205 - accuracy: 0.5318 - val_loss: 2.5091 - val_accuracy: 0.2647\n",
      "Epoch 36/100\n",
      "32955/32955 [==============================] - 8s 228us/sample - loss: 1.2114 - accuracy: 0.5305 - val_loss: 1.5245 - val_accuracy: 0.3798\n",
      "Epoch 37/100\n",
      "32955/32955 [==============================] - 7s 223us/sample - loss: 1.2125 - accuracy: 0.5315 - val_loss: 1.4040 - val_accuracy: 0.4400\n",
      "Epoch 38/100\n",
      "32955/32955 [==============================] - 8s 231us/sample - loss: 1.2074 - accuracy: 0.5331 - val_loss: 1.7658 - val_accuracy: 0.3895\n",
      "Epoch 39/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.2046 - accuracy: 0.5336 - val_loss: 1.8232 - val_accuracy: 0.4149\n",
      "Epoch 40/100\n",
      "32955/32955 [==============================] - 8s 246us/sample - loss: 1.2006 - accuracy: 0.5340 - val_loss: 1.4018 - val_accuracy: 0.4600\n",
      "Epoch 41/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1993 - accuracy: 0.5386 - val_loss: 1.5017 - val_accuracy: 0.4330\n",
      "Epoch 42/100\n",
      "32955/32955 [==============================] - 7s 225us/sample - loss: 1.1911 - accuracy: 0.5409 - val_loss: 1.4447 - val_accuracy: 0.4305\n",
      "Epoch 43/100\n",
      "32955/32955 [==============================] - 8s 234us/sample - loss: 1.1953 - accuracy: 0.5376 - val_loss: 1.3984 - val_accuracy: 0.4798\n",
      "Epoch 44/100\n",
      "32955/32955 [==============================] - 8s 252us/sample - loss: 1.1920 - accuracy: 0.5389 - val_loss: 1.4963 - val_accuracy: 0.4129\n",
      "Epoch 45/100\n",
      "32955/32955 [==============================] - 7s 226us/sample - loss: 1.1852 - accuracy: 0.5426 - val_loss: 1.4221 - val_accuracy: 0.4664\n",
      "Epoch 46/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1820 - accuracy: 0.5420 - val_loss: 2.0859 - val_accuracy: 0.2700\n",
      "Epoch 47/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1800 - accuracy: 0.5455 - val_loss: 1.3620 - val_accuracy: 0.4712\n",
      "Epoch 48/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1841 - accuracy: 0.5430 - val_loss: 1.4758 - val_accuracy: 0.4305\n",
      "Epoch 49/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1816 - accuracy: 0.5430 - val_loss: 1.4446 - val_accuracy: 0.4843\n",
      "Epoch 50/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.1710 - accuracy: 0.5493 - val_loss: 1.5197 - val_accuracy: 0.4057\n",
      "Epoch 51/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1741 - accuracy: 0.5464 - val_loss: 1.3713 - val_accuracy: 0.4904\n",
      "Epoch 52/100\n",
      "32955/32955 [==============================] - 7s 222us/sample - loss: 1.1705 - accuracy: 0.5498 - val_loss: 1.5257 - val_accuracy: 0.4338\n",
      "Epoch 53/100\n",
      "32955/32955 [==============================] - 7s 218us/sample - loss: 1.1641 - accuracy: 0.5476 - val_loss: 1.7380 - val_accuracy: 0.3876\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1642 - accuracy: 0.5491 - val_loss: 1.5191 - val_accuracy: 0.4074\n",
      "Epoch 55/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1587 - accuracy: 0.5520 - val_loss: 1.4774 - val_accuracy: 0.4344\n",
      "Epoch 56/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1594 - accuracy: 0.5526 - val_loss: 1.5052 - val_accuracy: 0.4071\n",
      "Epoch 57/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1542 - accuracy: 0.5495 - val_loss: 1.3894 - val_accuracy: 0.4444\n",
      "Epoch 58/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1495 - accuracy: 0.5568 - val_loss: 1.4304 - val_accuracy: 0.4363\n",
      "Epoch 59/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1506 - accuracy: 0.5547 - val_loss: 1.4014 - val_accuracy: 0.4645\n",
      "Epoch 60/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1481 - accuracy: 0.5562 - val_loss: 1.4685 - val_accuracy: 0.4294\n",
      "Epoch 61/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1459 - accuracy: 0.5540 - val_loss: 1.4610 - val_accuracy: 0.4366\n",
      "Epoch 62/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1411 - accuracy: 0.5572 - val_loss: 1.4461 - val_accuracy: 0.4347\n",
      "Epoch 63/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1427 - accuracy: 0.5598 - val_loss: 1.5949 - val_accuracy: 0.3525\n",
      "Epoch 64/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1399 - accuracy: 0.5577 - val_loss: 1.3813 - val_accuracy: 0.4620\n",
      "Epoch 65/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1333 - accuracy: 0.5625 - val_loss: 1.3367 - val_accuracy: 0.4801\n",
      "Epoch 66/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1377 - accuracy: 0.5597 - val_loss: 1.7889 - val_accuracy: 0.3285\n",
      "Epoch 67/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1389 - accuracy: 0.5602 - val_loss: 1.4418 - val_accuracy: 0.4622\n",
      "Epoch 68/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1282 - accuracy: 0.5659 - val_loss: 1.4556 - val_accuracy: 0.4422\n",
      "Epoch 69/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1315 - accuracy: 0.5622 - val_loss: 1.5235 - val_accuracy: 0.4335\n",
      "Epoch 70/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1255 - accuracy: 0.5666 - val_loss: 1.4494 - val_accuracy: 0.4413\n",
      "Epoch 71/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1265 - accuracy: 0.5619 - val_loss: 1.5763 - val_accuracy: 0.4168\n",
      "Epoch 72/100\n",
      "32955/32955 [==============================] - 7s 218us/sample - loss: 1.1180 - accuracy: 0.5621 - val_loss: 1.5281 - val_accuracy: 0.4124\n",
      "Epoch 73/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1212 - accuracy: 0.5667 - val_loss: 1.6883 - val_accuracy: 0.3859\n",
      "Epoch 74/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1215 - accuracy: 0.5665 - val_loss: 1.3592 - val_accuracy: 0.4817\n",
      "Epoch 75/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1120 - accuracy: 0.5707 - val_loss: 1.6637 - val_accuracy: 0.3603\n",
      "Epoch 76/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1134 - accuracy: 0.5724 - val_loss: 1.4724 - val_accuracy: 0.4706\n",
      "Epoch 77/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1057 - accuracy: 0.5714 - val_loss: 1.4685 - val_accuracy: 0.4383\n",
      "Epoch 78/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1065 - accuracy: 0.5723 - val_loss: 1.5490 - val_accuracy: 0.4280\n",
      "Epoch 79/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1056 - accuracy: 0.5727 - val_loss: 1.4664 - val_accuracy: 0.4528\n",
      "Epoch 80/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1068 - accuracy: 0.5719 - val_loss: 1.6039 - val_accuracy: 0.4335\n",
      "Epoch 81/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.1027 - accuracy: 0.5745 - val_loss: 1.4390 - val_accuracy: 0.4533\n",
      "Epoch 82/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.0966 - accuracy: 0.5745 - val_loss: 1.4525 - val_accuracy: 0.4544\n",
      "Epoch 83/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.1058 - accuracy: 0.5722 - val_loss: 1.6982 - val_accuracy: 0.3374\n",
      "Epoch 84/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.0969 - accuracy: 0.5751 - val_loss: 1.3602 - val_accuracy: 0.4817\n",
      "Epoch 85/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.0922 - accuracy: 0.5763 - val_loss: 1.5142 - val_accuracy: 0.4110\n",
      "Epoch 86/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.0925 - accuracy: 0.5793 - val_loss: 1.4995 - val_accuracy: 0.4522\n",
      "Epoch 87/100\n",
      "32955/32955 [==============================] - 7s 219us/sample - loss: 1.0901 - accuracy: 0.5760 - val_loss: 1.5270 - val_accuracy: 0.4015\n",
      "Epoch 88/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.0900 - accuracy: 0.5809 - val_loss: 1.3840 - val_accuracy: 0.4862\n",
      "Epoch 89/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.0935 - accuracy: 0.5763 - val_loss: 1.5029 - val_accuracy: 0.4377\n",
      "Epoch 90/100\n",
      "32955/32955 [==============================] - 7s 221us/sample - loss: 1.0873 - accuracy: 0.5785 - val_loss: 1.4981 - val_accuracy: 0.4380\n",
      "Epoch 91/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.0822 - accuracy: 0.5808 - val_loss: 1.4124 - val_accuracy: 0.4589\n",
      "Epoch 92/100\n",
      "32955/32955 [==============================] - 8s 242us/sample - loss: 1.0916 - accuracy: 0.5791 - val_loss: 1.7520 - val_accuracy: 0.3853\n",
      "Epoch 93/100\n",
      "32955/32955 [==============================] - 8s 248us/sample - loss: 1.0826 - accuracy: 0.5802 - val_loss: 1.4062 - val_accuracy: 0.4620\n",
      "Epoch 94/100\n",
      "32955/32955 [==============================] - 7s 222us/sample - loss: 1.0854 - accuracy: 0.5810 - val_loss: 1.4898 - val_accuracy: 0.4386\n",
      "Epoch 95/100\n",
      "32955/32955 [==============================] - 7s 220us/sample - loss: 1.0760 - accuracy: 0.5812 - val_loss: 1.4589 - val_accuracy: 0.4611\n",
      "Epoch 96/100\n",
      "32955/32955 [==============================] - 7s 224us/sample - loss: 1.0840 - accuracy: 0.5802 - val_loss: 1.3830 - val_accuracy: 0.4767\n",
      "Epoch 97/100\n",
      "32955/32955 [==============================] - 7s 223us/sample - loss: 1.0822 - accuracy: 0.5819 - val_loss: 1.4727 - val_accuracy: 0.4188\n",
      "Epoch 98/100\n",
      "32955/32955 [==============================] - 8s 244us/sample - loss: 1.0711 - accuracy: 0.5860 - val_loss: 1.5442 - val_accuracy: 0.4433\n",
      "Epoch 99/100\n",
      "32955/32955 [==============================] - 9s 271us/sample - loss: 1.0722 - accuracy: 0.5838 - val_loss: 1.4872 - val_accuracy: 0.4143\n",
      "Epoch 100/100\n",
      "32955/32955 [==============================] - 8s 234us/sample - loss: 1.0713 - accuracy: 0.5845 - val_loss: 1.4442 - val_accuracy: 0.4558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f219b629100>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(XDB,YDB,batch_size=64,epochs=100,validation_data=(XTB,YTB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_json = model.to_json()\n",
    "# with open(\"model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4608526051825021"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(XTB).argmax(axis=1)==YTB.argmax(axis=1)).sum()/len(XTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTB).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 6, ..., 0, 3, 2])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTB.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import udp_streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'udp_streamer' from '/home/archer/machine_learning/expression_recognition/udp_streamer.py'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(udp_streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from udp_streamer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = udp_handler()\n",
    "handler.make_listener('0.0.0.0',5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_rectangles(rgb):\n",
    "    faces = detector.detect_faces(rgb)\n",
    "    all_recs = []\n",
    "    for x in faces:\n",
    "        rec = x['box']\n",
    "        all_recs.append(dlib.rectangle(left=rec[0], top=rec[1], right=rec[0]+rec[2], bottom=rec[1]+rec[3]))\n",
    "    return all_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    global handler,img\n",
    "    buffer = handler.get_data()\n",
    "    if buffer is not None:\n",
    "        try:\n",
    "            npimg = np.frombuffer(buffer, dtype=np.uint8)\n",
    "            img = cv2.imdecode(npimg, 1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "#     ret, img = cam.read()\n",
    "    img=get_img()\n",
    "    try:\n",
    "        grimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    except:\n",
    "        continue\n",
    "    gimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     faces = face_cascade.detectMultiScale(gimg, 1.3, 5)\n",
    "    faces = face_rectangles(gimg)\n",
    "#     for (x,y,w,h) in faces:\n",
    "    for facrec in faces:\n",
    "        x=facrec.left()\n",
    "        y=facrec.top()\n",
    "        w=facrec.right()-x\n",
    "        h=facrec.bottom()-y\n",
    "        landmarks=[]\n",
    "        svx,svy=x,y\n",
    "        gray=grimg[y:y+int(1.1*h),max(0,x-int(0.15*w)):x+int(1.15*w)]\n",
    "        try:\n",
    "            gray=cv2.resize(gray, (face_dim, face_dim))\n",
    "        except:\n",
    "            continue\n",
    "        shape=predictor(gray,dlib.rectangle(0,0,face_dim,face_dim))\n",
    "        xlist=[]\n",
    "        ylist=[]\n",
    "        for i in range(68):\n",
    "            xp=shape.part(i).x\n",
    "            yp=shape.part(i).y\n",
    "            cv2.circle(gray, (xp, yp), 1, (255, 255, 255), -1)\n",
    "            xlist.append(float(xp))\n",
    "            ylist.append(float(yp))\n",
    "        cv2.imshow('gray',gray)\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        res=[]\n",
    "        for (x,y) in zip(xcentral,ycentral):\n",
    "            res.append(x)\n",
    "            res.append(y)\n",
    "        landmarks.append((np.asarray(res)/face_dim+1)/2)\n",
    "        if len(landmarks)>0:\n",
    "            y_out=model.predict(np.asarray(landmarks))\n",
    "            res=np.argmax(y_out,axis=1)\n",
    "            for r in res:\n",
    "                cv2.putText(img,emotions[r],(svx,svy),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "\n",
    "# cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
