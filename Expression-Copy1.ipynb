{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../face_recognition/haarcascade_frontalface_default.xml')\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=\"../facial_expressions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(IMG_PATH+\"icml_face_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(to_replace=\"PrivateTest\",value=\"Testing\")\n",
    "df=df.replace(to_replace=\"PublicTest\",value=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>Testing</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>Testing</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion     Usage                                             pixels\n",
       "0            0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1            0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2            2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3            4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4            6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
       "...        ...       ...                                                ...\n",
       "35882        6   Testing  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
       "35883        3   Testing  178 174 172 173 181 188 191 194 196 199 200 20...\n",
       "35884        0   Testing  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
       "35885        3   Testing  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
       "35886        2   Testing  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
       "\n",
       "[35887 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"Training\":[],\"Testing\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35887  4965      32797  "
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    print(\"\\r\",i+1,end=\" \")\n",
    "    row=df.iloc[i]\n",
    "    img=np.array(list(map(np.uint8,row[2].split()))).reshape(48,48)\n",
    "    data[row[1]].append([row[0],ret_keypoints(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_keypoints(image):\n",
    "    gray=image\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (face_dim, face_dim))\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    param=[0,0,face_dim,face_dim]\n",
    "    shape=predictor(gray,dlib.rectangle(*param))\n",
    "    xlist=[]\n",
    "    ylist=[]\n",
    "    for i in range(68):\n",
    "        xlist.append(np.float32(shape.part(i).x))\n",
    "        ylist.append(np.float32(shape.part(i).y))\n",
    "    xmean = np.mean(xlist)\n",
    "    ymean = np.mean(ylist)\n",
    "#     plt.imshow(gray,cmap='gray')\n",
    "#     plt.scatter(xlist,ylist, marker='.')\n",
    "#     plt.show()\n",
    "    xcentral = [(x-xmean) for x in xlist]\n",
    "    ycentral = [(y-ymean) for y in ylist]\n",
    "    res=[]\n",
    "    for (x,y) in zip(xcentral,ycentral):\n",
    "        res.append(x)\n",
    "        res.append(y)\n",
    "    return (np.asarray(res)/face_dim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=np.arange(len(XXD))\n",
    "# for i in range(5):\n",
    "#     np.random.shuffle(s)\n",
    "#     XXD=XXD[s]\n",
    "#     YYD=YYD[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,activation='tanh', input_shape=(68*2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512,activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(emotions),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "XDB=np.vstack(np.asarray(data[\"Training\"])[:,1])\n",
    "YDY=np.asarray(data[\"Training\"])[:,0]\n",
    "YDB=np.zeros((len(YDY),len(emotions)))\n",
    "for i in range(len(YDB)):\n",
    "    YDB[i][YDY[i]]=1\n",
    "XTB=np.vstack(np.asarray(data[\"Testing\"])[:,1])\n",
    "YTY=np.asarray(data[\"Testing\"])[:,0]\n",
    "YTB=np.zeros((len(YTY),len(emotions)))\n",
    "for i in range(len(YTB)):\n",
    "    YTB[i][YTY[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32298 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "32298/32298 [==============================] - 7s 214us/sample - loss: 1.2488 - accuracy: 0.5171 - val_loss: 1.4242 - val_accuracy: 0.4308\n",
      "Epoch 2/100\n",
      "32298/32298 [==============================] - 7s 204us/sample - loss: 1.2542 - accuracy: 0.5141 - val_loss: 1.3294 - val_accuracy: 0.4909\n",
      "Epoch 3/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2510 - accuracy: 0.5160 - val_loss: 1.3491 - val_accuracy: 0.4564\n",
      "Epoch 4/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2542 - accuracy: 0.5158 - val_loss: 1.4991 - val_accuracy: 0.4085\n",
      "Epoch 5/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2483 - accuracy: 0.5173 - val_loss: 1.3052 - val_accuracy: 0.4935\n",
      "Epoch 6/100\n",
      "32298/32298 [==============================] - 6s 195us/sample - loss: 1.2470 - accuracy: 0.5173 - val_loss: 1.3411 - val_accuracy: 0.4876\n",
      "Epoch 7/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2476 - accuracy: 0.5188 - val_loss: 1.3519 - val_accuracy: 0.4862\n",
      "Epoch 8/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2451 - accuracy: 0.5218 - val_loss: 1.3806 - val_accuracy: 0.4714\n",
      "Epoch 9/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2510 - accuracy: 0.5150 - val_loss: 1.3517 - val_accuracy: 0.4870\n",
      "Epoch 10/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2503 - accuracy: 0.5144 - val_loss: 1.3257 - val_accuracy: 0.4731\n",
      "Epoch 11/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2487 - accuracy: 0.5180 - val_loss: 1.3442 - val_accuracy: 0.4762\n",
      "Epoch 12/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2511 - accuracy: 0.5170 - val_loss: 1.3284 - val_accuracy: 0.4868\n",
      "Epoch 13/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2470 - accuracy: 0.5187 - val_loss: 1.4056 - val_accuracy: 0.4517\n",
      "Epoch 14/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2476 - accuracy: 0.5188 - val_loss: 1.3931 - val_accuracy: 0.4377\n",
      "Epoch 15/100\n",
      "32298/32298 [==============================] - 6s 192us/sample - loss: 1.2464 - accuracy: 0.5155 - val_loss: 1.4526 - val_accuracy: 0.4478\n",
      "Epoch 16/100\n",
      "32298/32298 [==============================] - 6s 195us/sample - loss: 1.2510 - accuracy: 0.5187 - val_loss: 1.5112 - val_accuracy: 0.4135\n",
      "Epoch 17/100\n",
      "32298/32298 [==============================] - 6s 196us/sample - loss: 1.2411 - accuracy: 0.5194 - val_loss: 1.4837 - val_accuracy: 0.4037\n",
      "Epoch 18/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2430 - accuracy: 0.5177 - val_loss: 1.3929 - val_accuracy: 0.4622\n",
      "Epoch 19/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2452 - accuracy: 0.5193 - val_loss: 1.2657 - val_accuracy: 0.5149\n",
      "Epoch 20/100\n",
      "32298/32298 [==============================] - 6s 196us/sample - loss: 1.2464 - accuracy: 0.5169 - val_loss: 1.3728 - val_accuracy: 0.4742\n",
      "Epoch 21/100\n",
      "32298/32298 [==============================] - 6s 195us/sample - loss: 1.2395 - accuracy: 0.5207 - val_loss: 1.4465 - val_accuracy: 0.4207\n",
      "Epoch 22/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2422 - accuracy: 0.5240 - val_loss: 1.3552 - val_accuracy: 0.4617\n",
      "Epoch 23/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2456 - accuracy: 0.5200 - val_loss: 1.3650 - val_accuracy: 0.4622\n",
      "Epoch 24/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2374 - accuracy: 0.5220 - val_loss: 1.3853 - val_accuracy: 0.4592\n",
      "Epoch 25/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2385 - accuracy: 0.5206 - val_loss: 1.4084 - val_accuracy: 0.4684\n",
      "Epoch 26/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2411 - accuracy: 0.5190 - val_loss: 1.4503 - val_accuracy: 0.4391\n",
      "Epoch 27/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.2371 - accuracy: 0.5209 - val_loss: 1.3889 - val_accuracy: 0.4561\n",
      "Epoch 28/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2391 - accuracy: 0.5213 - val_loss: 1.4165 - val_accuracy: 0.4739\n",
      "Epoch 29/100\n",
      "32298/32298 [==============================] - 6s 195us/sample - loss: 1.2389 - accuracy: 0.5201 - val_loss: 1.3349 - val_accuracy: 0.4751\n",
      "Epoch 30/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2416 - accuracy: 0.5183 - val_loss: 1.3543 - val_accuracy: 0.4642\n",
      "Epoch 31/100\n",
      "32298/32298 [==============================] - 6s 195us/sample - loss: 1.2410 - accuracy: 0.5217 - val_loss: 1.3113 - val_accuracy: 0.4921\n",
      "Epoch 32/100\n",
      "32298/32298 [==============================] - 6s 195us/sample - loss: 1.2339 - accuracy: 0.5212 - val_loss: 1.3617 - val_accuracy: 0.4642\n",
      "Epoch 33/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2388 - accuracy: 0.5220 - val_loss: 1.3325 - val_accuracy: 0.4976\n",
      "Epoch 34/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2419 - accuracy: 0.5224 - val_loss: 1.3575 - val_accuracy: 0.4742\n",
      "Epoch 35/100\n",
      "32298/32298 [==============================] - 6s 195us/sample - loss: 1.2359 - accuracy: 0.5211 - val_loss: 1.3346 - val_accuracy: 0.4817\n",
      "Epoch 36/100\n",
      "32298/32298 [==============================] - 6s 199us/sample - loss: 1.2305 - accuracy: 0.5238 - val_loss: 1.4152 - val_accuracy: 0.4266\n",
      "Epoch 37/100\n",
      "32298/32298 [==============================] - 6s 196us/sample - loss: 1.2420 - accuracy: 0.5202 - val_loss: 1.3704 - val_accuracy: 0.4756\n",
      "Epoch 38/100\n",
      "32298/32298 [==============================] - 6s 194us/sample - loss: 1.2350 - accuracy: 0.5211 - val_loss: 1.3315 - val_accuracy: 0.4739\n",
      "Epoch 39/100\n",
      "32298/32298 [==============================] - 7s 203us/sample - loss: 1.2336 - accuracy: 0.5234 - val_loss: 1.4336 - val_accuracy: 0.4617\n",
      "Epoch 40/100\n",
      "32298/32298 [==============================] - 7s 207us/sample - loss: 1.2315 - accuracy: 0.5228 - val_loss: 1.4383 - val_accuracy: 0.4497\n",
      "Epoch 41/100\n",
      "32298/32298 [==============================] - 7s 206us/sample - loss: 1.2391 - accuracy: 0.5200 - val_loss: 1.2865 - val_accuracy: 0.5026\n",
      "Epoch 42/100\n",
      "32298/32298 [==============================] - 6s 201us/sample - loss: 1.2354 - accuracy: 0.5238 - val_loss: 1.3056 - val_accuracy: 0.4890\n",
      "Epoch 43/100\n",
      "32298/32298 [==============================] - 6s 199us/sample - loss: 1.2274 - accuracy: 0.5266 - val_loss: 1.3004 - val_accuracy: 0.5043\n",
      "Epoch 44/100\n",
      "32298/32298 [==============================] - 7s 207us/sample - loss: 1.2329 - accuracy: 0.5241 - val_loss: 1.5982 - val_accuracy: 0.4029\n",
      "Epoch 45/100\n",
      "32298/32298 [==============================] - 6s 201us/sample - loss: 1.2290 - accuracy: 0.5252 - val_loss: 1.4602 - val_accuracy: 0.4302\n",
      "Epoch 46/100\n",
      "32298/32298 [==============================] - 7s 218us/sample - loss: 1.2318 - accuracy: 0.5230 - val_loss: 1.3242 - val_accuracy: 0.4876\n",
      "Epoch 47/100\n",
      "32298/32298 [==============================] - 7s 228us/sample - loss: 1.2293 - accuracy: 0.5249 - val_loss: 1.4137 - val_accuracy: 0.4684\n",
      "Epoch 48/100\n",
      "32298/32298 [==============================] - 7s 228us/sample - loss: 1.2317 - accuracy: 0.5234 - val_loss: 1.3101 - val_accuracy: 0.4921\n",
      "Epoch 49/100\n",
      " 7168/32298 [=====>........................] - ETA: 5s - loss: 1.2208 - accuracy: 0.5225"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-315-2d48190af28e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXDB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYDB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYTB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    775\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mtraining_data_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             training_result = run_one_epoch(\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mtraining_data_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1605\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m     \"\"\"\n\u001b[0;32m-> 1607\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1608\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1692\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    538\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    541\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                                num_outputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(XDB,YDB,batch_size=64,epochs=100,validation_data=(XTB,YTB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_json = model.to_json()\n",
    "# with open(\"model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4993034271384787"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(XTB).argmax(axis=1)==YTB.argmax(axis=1)).sum()/len(XTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 4, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTB).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 6, ..., 0, 3, 2])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTB.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import udp_streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'udp_streamer' from '/home/archer/machine_learning/expression_recognition/udp_streamer.py'>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(udp_streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from udp_streamer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = udp_handler()\n",
    "handler.make_listener('0.0.0.0',5554)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_rectangles(rgb):\n",
    "    faces = detector.detect_faces(rgb)\n",
    "    all_recs = []\n",
    "    for x in faces:\n",
    "        rec = x['box']\n",
    "        all_recs.append(dlib.rectangle(left=rec[0], top=rec[1], right=rec[0]+rec[2], bottom=rec[1]+rec[3]))\n",
    "    return all_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    global handler,img\n",
    "    buffer = handler.get_data()\n",
    "    if buffer is not None:\n",
    "        try:\n",
    "            npimg = np.frombuffer(buffer, dtype=np.uint8)\n",
    "            img = cv2.imdecode(npimg, 1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "#     ret, img = cam.read()\n",
    "    img=get_img()\n",
    "    try:\n",
    "        grimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    except:\n",
    "        continue\n",
    "    gimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     faces = face_cascade.detectMultiScale(gimg, 1.3, 5)\n",
    "    faces = face_rectangles(gimg)\n",
    "#     for (x,y,w,h) in faces:\n",
    "    for facrec in faces:\n",
    "        x=facrec.left()\n",
    "        y=facrec.top()\n",
    "        w=facrec.right()-x\n",
    "        h=facrec.bottom()-y\n",
    "        landmarks=[]\n",
    "        svx,svy=x,y\n",
    "        gray=grimg[y:y+int(1.1*h),max(0,x-int(0.15*w)):x+int(1.15*w)]\n",
    "        try:\n",
    "            gray=cv2.resize(gray, (face_dim, face_dim))\n",
    "        except:\n",
    "            continue\n",
    "        shape=predictor(gray,dlib.rectangle(0,0,face_dim,face_dim))\n",
    "        xlist=[]\n",
    "        ylist=[]\n",
    "        for i in range(68):\n",
    "            xp=shape.part(i).x\n",
    "            yp=shape.part(i).y\n",
    "            cv2.circle(gray, (xp, yp), 2, (255, 255, 255), -1)\n",
    "            xlist.append(float(xp))\n",
    "            ylist.append(float(yp))\n",
    "        cv2.imshow('gray',gray)\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        res=[]\n",
    "        for (x,y) in zip(xcentral,ycentral):\n",
    "            res.append(x)\n",
    "            res.append(y)\n",
    "        landmarks.append((np.asarray(res)/face_dim+1)/2)\n",
    "        if len(landmarks)>0:\n",
    "            y_out=model.predict(np.asarray(landmarks))\n",
    "            res=np.argmax(y_out,axis=1)\n",
    "            for r in res:\n",
    "                cv2.putText(img,emotions[r],(svx,svy),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
