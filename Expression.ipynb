{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../face_recognition/haarcascade_frontalface_default.xml')\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=\"../facial_expressions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"anger\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_keypoints(impath):\n",
    "    try:\n",
    "        image = cv2.imread(impath)\n",
    "    except:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (face_dim, face_dim))\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces)==0:\n",
    "        param=[0,0,face_dim,face_dim]\n",
    "    else:\n",
    "        param=faces[0]\n",
    "    shape=predictor(gray,dlib.rectangle(*param))\n",
    "    xlist=[]\n",
    "    ylist=[]\n",
    "    for i in range(68):\n",
    "        xlist.append(float(shape.part(i).x))\n",
    "        ylist.append(float(shape.part(i).y))\n",
    "    xmean = np.mean(xlist)\n",
    "    ymean = np.mean(ylist)\n",
    "#     plt.imshow(gray,cmap='gray')\n",
    "#     plt.scatter(xlist,ylist, marker='.')\n",
    "#     plt.show()\n",
    "    xcentral = [(x-xmean) for x in xlist]\n",
    "    ycentral = [(y-ymean) for y in ylist]\n",
    "    res=[]\n",
    "    for (x,y) in zip(xcentral,ycentral):\n",
    "        res.append(x)\n",
    "        res.append(y)\n",
    "    return (np.asarray(res)/face_dim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_keypoints():\n",
    "    X_inp=[]\n",
    "    y_inp=[]\n",
    "    for em in emotions:\n",
    "        ltt=os.listdir(IMG_PATH+em)\n",
    "        lnltt=len(ltt)\n",
    "        for idx,imn in enumerate(ltt):\n",
    "            print(\"\\r\",idx+1,'/',lnltt,end=\" \")\n",
    "            landmarks=ret_keypoints(IMG_PATH+em+\"/\"+imn)\n",
    "            if landmarks is not None:\n",
    "                X_inp.append(landmarks)\n",
    "                yy=np.zeros(len(emotions))\n",
    "                yy[emotions.index(em)]=1\n",
    "                y_inp.append(yy)\n",
    "        print()\n",
    "    return np.asarray(X_inp),np.asarray(y_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 124 / 124 \n",
      " 84 / 84 \n",
      " 67 / 67 \n",
      " 127 / 127 6 / 127 \n",
      " 123 / 123 \n",
      " 132 / 132 \n"
     ]
    }
   ],
   "source": [
    "XXD,YYD=prep_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(len(XXD))\n",
    "for i in range(5):\n",
    "    np.random.shuffle(s)\n",
    "    XXD=XXD[s]\n",
    "    YYD=YYD[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,activation='relu', input_shape=(68*2,)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(emotions),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               70144     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 238,726\n",
      "Trainable params: 236,934\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut=80\n",
    "XDB=XXD[cut:]\n",
    "YDB=YYD[cut:]\n",
    "\n",
    "XTB=XXD[:cut]\n",
    "YTB=YYD[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 577 samples, validate on 80 samples\n",
      "Epoch 1/500\n",
      "577/577 [==============================] - 0s 691us/sample - loss: 1.2996 - accuracy: 0.4905 - val_loss: 2.1716 - val_accuracy: 0.2375\n",
      "Epoch 2/500\n",
      "577/577 [==============================] - 0s 346us/sample - loss: 1.3917 - accuracy: 0.4645 - val_loss: 3.1831 - val_accuracy: 0.3000\n",
      "Epoch 3/500\n",
      "577/577 [==============================] - 0s 338us/sample - loss: 1.4039 - accuracy: 0.4731 - val_loss: 1.6290 - val_accuracy: 0.4375\n",
      "Epoch 4/500\n",
      "577/577 [==============================] - 0s 340us/sample - loss: 1.3921 - accuracy: 0.4333 - val_loss: 1.6439 - val_accuracy: 0.3375\n",
      "Epoch 5/500\n",
      "577/577 [==============================] - 0s 349us/sample - loss: 1.3849 - accuracy: 0.4610 - val_loss: 2.3363 - val_accuracy: 0.1750\n",
      "Epoch 6/500\n",
      "577/577 [==============================] - 0s 348us/sample - loss: 1.3353 - accuracy: 0.4593 - val_loss: 1.6244 - val_accuracy: 0.3375\n",
      "Epoch 7/500\n",
      "577/577 [==============================] - 0s 347us/sample - loss: 1.3404 - accuracy: 0.4558 - val_loss: 2.0307 - val_accuracy: 0.3500\n",
      "Epoch 8/500\n",
      "577/577 [==============================] - 0s 339us/sample - loss: 1.3221 - accuracy: 0.4939 - val_loss: 1.4999 - val_accuracy: 0.3625\n",
      "Epoch 9/500\n",
      "577/577 [==============================] - 0s 300us/sample - loss: 1.3693 - accuracy: 0.4679 - val_loss: 1.9560 - val_accuracy: 0.3000\n",
      "Epoch 10/500\n",
      "577/577 [==============================] - 0s 375us/sample - loss: 1.3555 - accuracy: 0.4766 - val_loss: 1.7584 - val_accuracy: 0.3000\n",
      "Epoch 11/500\n",
      "577/577 [==============================] - 0s 341us/sample - loss: 1.2843 - accuracy: 0.5234 - val_loss: 1.6720 - val_accuracy: 0.3375\n",
      "Epoch 12/500\n",
      "577/577 [==============================] - 0s 393us/sample - loss: 1.3600 - accuracy: 0.4645 - val_loss: 2.1103 - val_accuracy: 0.3000\n",
      "Epoch 13/500\n",
      "577/577 [==============================] - 0s 311us/sample - loss: 1.3176 - accuracy: 0.4853 - val_loss: 1.9686 - val_accuracy: 0.3000\n",
      "Epoch 14/500\n",
      "577/577 [==============================] - 0s 354us/sample - loss: 1.3635 - accuracy: 0.4749 - val_loss: 2.4051 - val_accuracy: 0.2625\n",
      "Epoch 15/500\n",
      "577/577 [==============================] - 0s 380us/sample - loss: 1.3597 - accuracy: 0.4697 - val_loss: 1.7974 - val_accuracy: 0.3875\n",
      "Epoch 16/500\n",
      "577/577 [==============================] - 0s 343us/sample - loss: 1.2981 - accuracy: 0.4783 - val_loss: 3.0900 - val_accuracy: 0.2500\n",
      "Epoch 17/500\n",
      "577/577 [==============================] - 0s 339us/sample - loss: 1.3561 - accuracy: 0.4731 - val_loss: 2.0016 - val_accuracy: 0.3250\n",
      "Epoch 18/500\n",
      "577/577 [==============================] - 0s 333us/sample - loss: 1.3334 - accuracy: 0.4835 - val_loss: 1.6565 - val_accuracy: 0.3250\n",
      "Epoch 19/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 1.3256 - accuracy: 0.4783 - val_loss: 1.7932 - val_accuracy: 0.3000\n",
      "Epoch 20/500\n",
      "577/577 [==============================] - 0s 605us/sample - loss: 1.3241 - accuracy: 0.4835 - val_loss: 1.7995 - val_accuracy: 0.3375\n",
      "Epoch 21/500\n",
      "577/577 [==============================] - 0s 493us/sample - loss: 1.2972 - accuracy: 0.4991 - val_loss: 1.4713 - val_accuracy: 0.4125\n",
      "Epoch 22/500\n",
      "577/577 [==============================] - 0s 361us/sample - loss: 1.3008 - accuracy: 0.4870 - val_loss: 1.8384 - val_accuracy: 0.3375\n",
      "Epoch 23/500\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 1.3072 - accuracy: 0.5043 - val_loss: 2.2604 - val_accuracy: 0.3250\n",
      "Epoch 24/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.3485 - accuracy: 0.4645 - val_loss: 1.7385 - val_accuracy: 0.3000\n",
      "Epoch 25/500\n",
      "577/577 [==============================] - 0s 312us/sample - loss: 1.2943 - accuracy: 0.5043 - val_loss: 1.7273 - val_accuracy: 0.4125\n",
      "Epoch 26/500\n",
      "577/577 [==============================] - 0s 537us/sample - loss: 1.3067 - accuracy: 0.4853 - val_loss: 1.8663 - val_accuracy: 0.3500\n",
      "Epoch 27/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 1.2979 - accuracy: 0.4957 - val_loss: 1.5935 - val_accuracy: 0.3500\n",
      "Epoch 28/500\n",
      "577/577 [==============================] - 0s 454us/sample - loss: 1.3149 - accuracy: 0.5009 - val_loss: 1.6684 - val_accuracy: 0.3500\n",
      "Epoch 29/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.3497 - accuracy: 0.4662 - val_loss: 1.6143 - val_accuracy: 0.3500\n",
      "Epoch 30/500\n",
      "577/577 [==============================] - 0s 354us/sample - loss: 1.3111 - accuracy: 0.4593 - val_loss: 1.7053 - val_accuracy: 0.3625\n",
      "Epoch 31/500\n",
      "577/577 [==============================] - 0s 362us/sample - loss: 1.3051 - accuracy: 0.4939 - val_loss: 1.9211 - val_accuracy: 0.3000\n",
      "Epoch 32/500\n",
      "577/577 [==============================] - 0s 400us/sample - loss: 1.2948 - accuracy: 0.5026 - val_loss: 1.6584 - val_accuracy: 0.3625\n",
      "Epoch 33/500\n",
      "577/577 [==============================] - 0s 381us/sample - loss: 1.2878 - accuracy: 0.5286 - val_loss: 1.9578 - val_accuracy: 0.2750\n",
      "Epoch 34/500\n",
      "577/577 [==============================] - 0s 318us/sample - loss: 1.2899 - accuracy: 0.4783 - val_loss: 2.0516 - val_accuracy: 0.2500\n",
      "Epoch 35/500\n",
      "577/577 [==============================] - 0s 327us/sample - loss: 1.2894 - accuracy: 0.4939 - val_loss: 1.4569 - val_accuracy: 0.4625\n",
      "Epoch 36/500\n",
      "577/577 [==============================] - 0s 296us/sample - loss: 1.3135 - accuracy: 0.4818 - val_loss: 2.1161 - val_accuracy: 0.2250\n",
      "Epoch 37/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 1.3125 - accuracy: 0.4939 - val_loss: 1.7567 - val_accuracy: 0.3500\n",
      "Epoch 38/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 1.2929 - accuracy: 0.4939 - val_loss: 2.3459 - val_accuracy: 0.2125\n",
      "Epoch 39/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.3175 - accuracy: 0.4870 - val_loss: 1.9489 - val_accuracy: 0.2750\n",
      "Epoch 40/500\n",
      "577/577 [==============================] - 0s 376us/sample - loss: 1.2806 - accuracy: 0.5182 - val_loss: 2.4835 - val_accuracy: 0.3000\n",
      "Epoch 41/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 1.2867 - accuracy: 0.5130 - val_loss: 1.6317 - val_accuracy: 0.3500\n",
      "Epoch 42/500\n",
      "577/577 [==============================] - 0s 393us/sample - loss: 1.2683 - accuracy: 0.5199 - val_loss: 1.5083 - val_accuracy: 0.3500\n",
      "Epoch 43/500\n",
      "577/577 [==============================] - 0s 381us/sample - loss: 1.2853 - accuracy: 0.5009 - val_loss: 1.8665 - val_accuracy: 0.3000\n",
      "Epoch 44/500\n",
      "577/577 [==============================] - 0s 349us/sample - loss: 1.2991 - accuracy: 0.4991 - val_loss: 1.7605 - val_accuracy: 0.2750\n",
      "Epoch 45/500\n",
      "577/577 [==============================] - 0s 375us/sample - loss: 1.2587 - accuracy: 0.5043 - val_loss: 1.7653 - val_accuracy: 0.3250\n",
      "Epoch 46/500\n",
      "577/577 [==============================] - 0s 480us/sample - loss: 1.3010 - accuracy: 0.4697 - val_loss: 1.9325 - val_accuracy: 0.3750\n",
      "Epoch 47/500\n",
      "577/577 [==============================] - 0s 340us/sample - loss: 1.2580 - accuracy: 0.5026 - val_loss: 2.0011 - val_accuracy: 0.3250\n",
      "Epoch 48/500\n",
      "577/577 [==============================] - 0s 547us/sample - loss: 1.2716 - accuracy: 0.4974 - val_loss: 2.1861 - val_accuracy: 0.2500\n",
      "Epoch 49/500\n",
      "577/577 [==============================] - 0s 405us/sample - loss: 1.2675 - accuracy: 0.4922 - val_loss: 1.5866 - val_accuracy: 0.3625\n",
      "Epoch 50/500\n",
      "577/577 [==============================] - 0s 464us/sample - loss: 1.2379 - accuracy: 0.5182 - val_loss: 2.0953 - val_accuracy: 0.2875\n",
      "Epoch 51/500\n",
      "577/577 [==============================] - 0s 368us/sample - loss: 1.2489 - accuracy: 0.5165 - val_loss: 2.0215 - val_accuracy: 0.2500\n",
      "Epoch 52/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 1.2575 - accuracy: 0.5199 - val_loss: 1.7026 - val_accuracy: 0.3625\n",
      "Epoch 53/500\n",
      "577/577 [==============================] - 0s 369us/sample - loss: 1.2761 - accuracy: 0.4853 - val_loss: 1.6455 - val_accuracy: 0.3750\n",
      "Epoch 54/500\n",
      "577/577 [==============================] - 0s 364us/sample - loss: 1.2730 - accuracy: 0.4974 - val_loss: 1.9195 - val_accuracy: 0.3250\n",
      "Epoch 55/500\n",
      "577/577 [==============================] - 0s 391us/sample - loss: 1.3045 - accuracy: 0.4991 - val_loss: 1.9734 - val_accuracy: 0.2750\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 385us/sample - loss: 1.2686 - accuracy: 0.4939 - val_loss: 1.5664 - val_accuracy: 0.3000\n",
      "Epoch 57/500\n",
      "577/577 [==============================] - 0s 325us/sample - loss: 1.2602 - accuracy: 0.5130 - val_loss: 1.5442 - val_accuracy: 0.3875\n",
      "Epoch 58/500\n",
      "577/577 [==============================] - 0s 298us/sample - loss: 1.2669 - accuracy: 0.5182 - val_loss: 1.5171 - val_accuracy: 0.4250\n",
      "Epoch 59/500\n",
      "577/577 [==============================] - 0s 338us/sample - loss: 1.2588 - accuracy: 0.5147 - val_loss: 1.8063 - val_accuracy: 0.3375\n",
      "Epoch 60/500\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 1.2379 - accuracy: 0.5165 - val_loss: 3.0640 - val_accuracy: 0.2875\n",
      "Epoch 61/500\n",
      "577/577 [==============================] - 0s 440us/sample - loss: 1.2675 - accuracy: 0.5043 - val_loss: 2.4258 - val_accuracy: 0.3250\n",
      "Epoch 62/500\n",
      "577/577 [==============================] - 0s 331us/sample - loss: 1.2730 - accuracy: 0.5095 - val_loss: 1.8001 - val_accuracy: 0.3500\n",
      "Epoch 63/500\n",
      "577/577 [==============================] - 0s 318us/sample - loss: 1.2496 - accuracy: 0.4870 - val_loss: 1.6813 - val_accuracy: 0.3625\n",
      "Epoch 64/500\n",
      "577/577 [==============================] - 0s 359us/sample - loss: 1.2653 - accuracy: 0.5286 - val_loss: 1.6014 - val_accuracy: 0.4125\n",
      "Epoch 65/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 1.2664 - accuracy: 0.5113 - val_loss: 1.7929 - val_accuracy: 0.3125\n",
      "Epoch 66/500\n",
      "577/577 [==============================] - 0s 306us/sample - loss: 1.2405 - accuracy: 0.5199 - val_loss: 1.7289 - val_accuracy: 0.3375\n",
      "Epoch 67/500\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 1.2876 - accuracy: 0.4991 - val_loss: 2.3731 - val_accuracy: 0.3375\n",
      "Epoch 68/500\n",
      "577/577 [==============================] - 0s 310us/sample - loss: 1.2618 - accuracy: 0.4991 - val_loss: 2.0416 - val_accuracy: 0.2875\n",
      "Epoch 69/500\n",
      "577/577 [==============================] - 0s 331us/sample - loss: 1.2320 - accuracy: 0.5113 - val_loss: 1.6586 - val_accuracy: 0.3375\n",
      "Epoch 70/500\n",
      "577/577 [==============================] - 0s 371us/sample - loss: 1.2186 - accuracy: 0.5407 - val_loss: 1.7913 - val_accuracy: 0.2750\n",
      "Epoch 71/500\n",
      "577/577 [==============================] - 0s 350us/sample - loss: 1.2277 - accuracy: 0.5217 - val_loss: 1.6667 - val_accuracy: 0.3000\n",
      "Epoch 72/500\n",
      "577/577 [==============================] - 0s 478us/sample - loss: 1.2443 - accuracy: 0.5390 - val_loss: 1.9616 - val_accuracy: 0.2625\n",
      "Epoch 73/500\n",
      "577/577 [==============================] - 0s 349us/sample - loss: 1.2381 - accuracy: 0.5061 - val_loss: 2.0480 - val_accuracy: 0.2625\n",
      "Epoch 74/500\n",
      "577/577 [==============================] - 0s 452us/sample - loss: 1.2232 - accuracy: 0.5321 - val_loss: 1.6937 - val_accuracy: 0.3750\n",
      "Epoch 75/500\n",
      "577/577 [==============================] - 0s 483us/sample - loss: 1.2601 - accuracy: 0.5130 - val_loss: 1.7117 - val_accuracy: 0.4000\n",
      "Epoch 76/500\n",
      "577/577 [==============================] - 0s 373us/sample - loss: 1.1999 - accuracy: 0.5355 - val_loss: 1.6346 - val_accuracy: 0.3875\n",
      "Epoch 77/500\n",
      "577/577 [==============================] - 0s 351us/sample - loss: 1.2150 - accuracy: 0.5338 - val_loss: 2.1360 - val_accuracy: 0.2750\n",
      "Epoch 78/500\n",
      "577/577 [==============================] - 0s 386us/sample - loss: 1.2250 - accuracy: 0.5182 - val_loss: 1.6855 - val_accuracy: 0.3750\n",
      "Epoch 79/500\n",
      "577/577 [==============================] - 0s 364us/sample - loss: 1.1908 - accuracy: 0.5199 - val_loss: 2.1709 - val_accuracy: 0.2125\n",
      "Epoch 80/500\n",
      "577/577 [==============================] - 0s 376us/sample - loss: 1.2046 - accuracy: 0.5303 - val_loss: 1.9822 - val_accuracy: 0.3250\n",
      "Epoch 81/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.2457 - accuracy: 0.5182 - val_loss: 2.2546 - val_accuracy: 0.2000\n",
      "Epoch 82/500\n",
      "577/577 [==============================] - 0s 342us/sample - loss: 1.2083 - accuracy: 0.5477 - val_loss: 2.4121 - val_accuracy: 0.3125\n",
      "Epoch 83/500\n",
      "577/577 [==============================] - 0s 397us/sample - loss: 1.2275 - accuracy: 0.5234 - val_loss: 1.6364 - val_accuracy: 0.3875\n",
      "Epoch 84/500\n",
      "577/577 [==============================] - 0s 371us/sample - loss: 1.2798 - accuracy: 0.4835 - val_loss: 2.3602 - val_accuracy: 0.2125\n",
      "Epoch 85/500\n",
      "577/577 [==============================] - 0s 359us/sample - loss: 1.2463 - accuracy: 0.5061 - val_loss: 2.4605 - val_accuracy: 0.2375\n",
      "Epoch 86/500\n",
      "577/577 [==============================] - 0s 349us/sample - loss: 1.2391 - accuracy: 0.5165 - val_loss: 1.6199 - val_accuracy: 0.3625\n",
      "Epoch 87/500\n",
      "577/577 [==============================] - 0s 329us/sample - loss: 1.2153 - accuracy: 0.5234 - val_loss: 2.2211 - val_accuracy: 0.2750\n",
      "Epoch 88/500\n",
      "577/577 [==============================] - 0s 383us/sample - loss: 1.2226 - accuracy: 0.5234 - val_loss: 1.9898 - val_accuracy: 0.3125\n",
      "Epoch 89/500\n",
      "577/577 [==============================] - 0s 468us/sample - loss: 1.2224 - accuracy: 0.5321 - val_loss: 1.8356 - val_accuracy: 0.3250\n",
      "Epoch 90/500\n",
      "577/577 [==============================] - 0s 328us/sample - loss: 1.1740 - accuracy: 0.5165 - val_loss: 1.6183 - val_accuracy: 0.3875\n",
      "Epoch 91/500\n",
      "577/577 [==============================] - 0s 368us/sample - loss: 1.2922 - accuracy: 0.4939 - val_loss: 1.6050 - val_accuracy: 0.3500\n",
      "Epoch 92/500\n",
      "577/577 [==============================] - 0s 393us/sample - loss: 1.2352 - accuracy: 0.5095 - val_loss: 2.9976 - val_accuracy: 0.3250\n",
      "Epoch 93/500\n",
      "577/577 [==============================] - 0s 364us/sample - loss: 1.2565 - accuracy: 0.5217 - val_loss: 2.2793 - val_accuracy: 0.2750\n",
      "Epoch 94/500\n",
      "577/577 [==============================] - 0s 351us/sample - loss: 1.2206 - accuracy: 0.5373 - val_loss: 1.7998 - val_accuracy: 0.3375\n",
      "Epoch 95/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.2293 - accuracy: 0.4905 - val_loss: 1.5048 - val_accuracy: 0.4250\n",
      "Epoch 96/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.2095 - accuracy: 0.5234 - val_loss: 1.6055 - val_accuracy: 0.3250\n",
      "Epoch 97/500\n",
      "577/577 [==============================] - 0s 429us/sample - loss: 1.1741 - accuracy: 0.5373 - val_loss: 1.5461 - val_accuracy: 0.4000\n",
      "Epoch 98/500\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 1.2164 - accuracy: 0.5182 - val_loss: 2.2542 - val_accuracy: 0.2750\n",
      "Epoch 99/500\n",
      "577/577 [==============================] - 0s 350us/sample - loss: 1.2029 - accuracy: 0.4991 - val_loss: 2.3944 - val_accuracy: 0.2250\n",
      "Epoch 100/500\n",
      "577/577 [==============================] - 0s 363us/sample - loss: 1.2170 - accuracy: 0.5407 - val_loss: 2.3006 - val_accuracy: 0.3125\n",
      "Epoch 101/500\n",
      "577/577 [==============================] - 0s 367us/sample - loss: 1.2239 - accuracy: 0.5338 - val_loss: 1.7633 - val_accuracy: 0.3500\n",
      "Epoch 102/500\n",
      "577/577 [==============================] - 0s 506us/sample - loss: 1.2562 - accuracy: 0.5199 - val_loss: 1.6508 - val_accuracy: 0.4125\n",
      "Epoch 103/500\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 1.1921 - accuracy: 0.5511 - val_loss: 1.9806 - val_accuracy: 0.3625\n",
      "Epoch 104/500\n",
      "577/577 [==============================] - 0s 355us/sample - loss: 1.1823 - accuracy: 0.5373 - val_loss: 1.7983 - val_accuracy: 0.3500\n",
      "Epoch 105/500\n",
      "577/577 [==============================] - 0s 391us/sample - loss: 1.1991 - accuracy: 0.5494 - val_loss: 2.1124 - val_accuracy: 0.3500\n",
      "Epoch 106/500\n",
      "577/577 [==============================] - 0s 410us/sample - loss: 1.2242 - accuracy: 0.5251 - val_loss: 1.9118 - val_accuracy: 0.3000\n",
      "Epoch 107/500\n",
      "577/577 [==============================] - 0s 357us/sample - loss: 1.2212 - accuracy: 0.5199 - val_loss: 1.7547 - val_accuracy: 0.3875\n",
      "Epoch 108/500\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 1.2072 - accuracy: 0.5321 - val_loss: 1.6177 - val_accuracy: 0.3500\n",
      "Epoch 109/500\n",
      "577/577 [==============================] - 0s 348us/sample - loss: 1.2278 - accuracy: 0.5234 - val_loss: 1.8413 - val_accuracy: 0.3500\n",
      "Epoch 110/500\n",
      "577/577 [==============================] - 0s 471us/sample - loss: 1.1946 - accuracy: 0.5286 - val_loss: 1.7143 - val_accuracy: 0.4000\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 333us/sample - loss: 1.2490 - accuracy: 0.5286 - val_loss: 1.7873 - val_accuracy: 0.3375\n",
      "Epoch 112/500\n",
      "577/577 [==============================] - 0s 334us/sample - loss: 1.2230 - accuracy: 0.5234 - val_loss: 1.6833 - val_accuracy: 0.3250\n",
      "Epoch 113/500\n",
      "577/577 [==============================] - 0s 327us/sample - loss: 1.1949 - accuracy: 0.5407 - val_loss: 1.5848 - val_accuracy: 0.3875\n",
      "Epoch 114/500\n",
      "577/577 [==============================] - 0s 300us/sample - loss: 1.1597 - accuracy: 0.5477 - val_loss: 1.8529 - val_accuracy: 0.3375\n",
      "Epoch 115/500\n",
      "577/577 [==============================] - 0s 361us/sample - loss: 1.1912 - accuracy: 0.5199 - val_loss: 1.4704 - val_accuracy: 0.3875\n",
      "Epoch 116/500\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 1.2267 - accuracy: 0.5061 - val_loss: 1.9434 - val_accuracy: 0.3000\n",
      "Epoch 117/500\n",
      "577/577 [==============================] - 0s 333us/sample - loss: 1.1536 - accuracy: 0.5546 - val_loss: 1.6928 - val_accuracy: 0.3125\n",
      "Epoch 118/500\n",
      "577/577 [==============================] - 0s 310us/sample - loss: 1.1795 - accuracy: 0.5598 - val_loss: 2.4280 - val_accuracy: 0.2625\n",
      "Epoch 119/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 1.1901 - accuracy: 0.5459 - val_loss: 1.7761 - val_accuracy: 0.3625\n",
      "Epoch 120/500\n",
      "577/577 [==============================] - 0s 411us/sample - loss: 1.1978 - accuracy: 0.5355 - val_loss: 2.1457 - val_accuracy: 0.3375\n",
      "Epoch 121/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.1832 - accuracy: 0.5511 - val_loss: 1.9845 - val_accuracy: 0.3250\n",
      "Epoch 122/500\n",
      "577/577 [==============================] - 0s 343us/sample - loss: 1.1889 - accuracy: 0.5407 - val_loss: 1.8883 - val_accuracy: 0.2750\n",
      "Epoch 123/500\n",
      "577/577 [==============================] - 0s 370us/sample - loss: 1.1386 - accuracy: 0.5615 - val_loss: 1.7896 - val_accuracy: 0.3375\n",
      "Epoch 124/500\n",
      "577/577 [==============================] - 0s 348us/sample - loss: 1.2166 - accuracy: 0.5009 - val_loss: 1.6367 - val_accuracy: 0.3625\n",
      "Epoch 125/500\n",
      "577/577 [==============================] - 0s 426us/sample - loss: 1.2116 - accuracy: 0.5217 - val_loss: 1.6020 - val_accuracy: 0.4250\n",
      "Epoch 126/500\n",
      "577/577 [==============================] - 0s 328us/sample - loss: 1.2031 - accuracy: 0.5407 - val_loss: 1.7669 - val_accuracy: 0.2875\n",
      "Epoch 127/500\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 1.1398 - accuracy: 0.5355 - val_loss: 1.6799 - val_accuracy: 0.3750\n",
      "Epoch 128/500\n",
      "577/577 [==============================] - 0s 377us/sample - loss: 1.1852 - accuracy: 0.5269 - val_loss: 1.8587 - val_accuracy: 0.3250\n",
      "Epoch 129/500\n",
      "577/577 [==============================] - 0s 350us/sample - loss: 1.1717 - accuracy: 0.5407 - val_loss: 2.5929 - val_accuracy: 0.2000\n",
      "Epoch 130/500\n",
      "577/577 [==============================] - 0s 486us/sample - loss: 1.1534 - accuracy: 0.5615 - val_loss: 1.6310 - val_accuracy: 0.3875\n",
      "Epoch 131/500\n",
      "577/577 [==============================] - 0s 410us/sample - loss: 1.1559 - accuracy: 0.5529 - val_loss: 1.7566 - val_accuracy: 0.3500\n",
      "Epoch 132/500\n",
      "577/577 [==============================] - 0s 369us/sample - loss: 1.2087 - accuracy: 0.5303 - val_loss: 1.7903 - val_accuracy: 0.3750\n",
      "Epoch 133/500\n",
      "577/577 [==============================] - 0s 338us/sample - loss: 1.1746 - accuracy: 0.5494 - val_loss: 1.6999 - val_accuracy: 0.4375\n",
      "Epoch 134/500\n",
      "577/577 [==============================] - 0s 408us/sample - loss: 1.1909 - accuracy: 0.5373 - val_loss: 1.6523 - val_accuracy: 0.3625\n",
      "Epoch 135/500\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 1.1798 - accuracy: 0.5563 - val_loss: 1.9369 - val_accuracy: 0.3500\n",
      "Epoch 136/500\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 1.1992 - accuracy: 0.5390 - val_loss: 1.6069 - val_accuracy: 0.3625\n",
      "Epoch 137/500\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 1.1888 - accuracy: 0.5286 - val_loss: 1.5402 - val_accuracy: 0.4625\n",
      "Epoch 138/500\n",
      "577/577 [==============================] - 0s 363us/sample - loss: 1.1716 - accuracy: 0.5598 - val_loss: 2.2513 - val_accuracy: 0.2125\n",
      "Epoch 139/500\n",
      "577/577 [==============================] - 0s 398us/sample - loss: 1.1661 - accuracy: 0.5529 - val_loss: 1.8144 - val_accuracy: 0.2750\n",
      "Epoch 140/500\n",
      "577/577 [==============================] - 0s 352us/sample - loss: 1.1592 - accuracy: 0.5407 - val_loss: 1.4512 - val_accuracy: 0.4375\n",
      "Epoch 141/500\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 1.1937 - accuracy: 0.5546 - val_loss: 1.5802 - val_accuracy: 0.4625\n",
      "Epoch 142/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.1812 - accuracy: 0.5182 - val_loss: 1.7357 - val_accuracy: 0.4125\n",
      "Epoch 143/500\n",
      "577/577 [==============================] - 0s 396us/sample - loss: 1.1478 - accuracy: 0.5598 - val_loss: 2.4180 - val_accuracy: 0.3375\n",
      "Epoch 144/500\n",
      "577/577 [==============================] - 0s 330us/sample - loss: 1.1591 - accuracy: 0.5407 - val_loss: 1.9160 - val_accuracy: 0.3500\n",
      "Epoch 145/500\n",
      "577/577 [==============================] - 0s 366us/sample - loss: 1.1650 - accuracy: 0.5494 - val_loss: 2.1613 - val_accuracy: 0.2750\n",
      "Epoch 146/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.1893 - accuracy: 0.5113 - val_loss: 1.8517 - val_accuracy: 0.4000\n",
      "Epoch 147/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.2128 - accuracy: 0.5321 - val_loss: 2.3591 - val_accuracy: 0.3625\n",
      "Epoch 148/500\n",
      "577/577 [==============================] - 0s 378us/sample - loss: 1.1561 - accuracy: 0.5667 - val_loss: 1.9362 - val_accuracy: 0.3500\n",
      "Epoch 149/500\n",
      "577/577 [==============================] - 0s 352us/sample - loss: 1.1261 - accuracy: 0.5650 - val_loss: 1.4387 - val_accuracy: 0.4125\n",
      "Epoch 150/500\n",
      "577/577 [==============================] - 0s 354us/sample - loss: 1.1627 - accuracy: 0.5373 - val_loss: 1.7486 - val_accuracy: 0.3750\n",
      "Epoch 151/500\n",
      "577/577 [==============================] - 0s 349us/sample - loss: 1.1189 - accuracy: 0.5667 - val_loss: 1.6578 - val_accuracy: 0.3625\n",
      "Epoch 152/500\n",
      "577/577 [==============================] - 0s 336us/sample - loss: 1.1986 - accuracy: 0.5321 - val_loss: 1.6111 - val_accuracy: 0.3375\n",
      "Epoch 153/500\n",
      "577/577 [==============================] - 0s 405us/sample - loss: 1.2085 - accuracy: 0.5529 - val_loss: 1.8338 - val_accuracy: 0.3250\n",
      "Epoch 154/500\n",
      "577/577 [==============================] - 0s 350us/sample - loss: 1.1413 - accuracy: 0.5355 - val_loss: 1.7334 - val_accuracy: 0.3875\n",
      "Epoch 155/500\n",
      "577/577 [==============================] - 0s 352us/sample - loss: 1.1709 - accuracy: 0.5494 - val_loss: 1.6976 - val_accuracy: 0.3875\n",
      "Epoch 156/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 1.1556 - accuracy: 0.5390 - val_loss: 1.7859 - val_accuracy: 0.3125\n",
      "Epoch 157/500\n",
      "577/577 [==============================] - 0s 373us/sample - loss: 1.1075 - accuracy: 0.5667 - val_loss: 1.7984 - val_accuracy: 0.4125\n",
      "Epoch 158/500\n",
      "577/577 [==============================] - 0s 521us/sample - loss: 1.1277 - accuracy: 0.5407 - val_loss: 1.9897 - val_accuracy: 0.3125\n",
      "Epoch 159/500\n",
      "577/577 [==============================] - 0s 431us/sample - loss: 1.1217 - accuracy: 0.5633 - val_loss: 1.6430 - val_accuracy: 0.3500\n",
      "Epoch 160/500\n",
      "577/577 [==============================] - 0s 348us/sample - loss: 1.1930 - accuracy: 0.5425 - val_loss: 2.0466 - val_accuracy: 0.3500\n",
      "Epoch 161/500\n",
      "577/577 [==============================] - 0s 376us/sample - loss: 1.1053 - accuracy: 0.5875 - val_loss: 1.7011 - val_accuracy: 0.3000\n",
      "Epoch 162/500\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 1.2065 - accuracy: 0.5338 - val_loss: 1.8229 - val_accuracy: 0.3750\n",
      "Epoch 163/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.0964 - accuracy: 0.5511 - val_loss: 1.6595 - val_accuracy: 0.3750\n",
      "Epoch 164/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.1289 - accuracy: 0.5303 - val_loss: 2.1916 - val_accuracy: 0.3500\n",
      "Epoch 165/500\n",
      "577/577 [==============================] - 0s 359us/sample - loss: 1.2018 - accuracy: 0.5303 - val_loss: 3.4073 - val_accuracy: 0.2750\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 455us/sample - loss: 1.1988 - accuracy: 0.5615 - val_loss: 1.7651 - val_accuracy: 0.3750\n",
      "Epoch 167/500\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 1.1638 - accuracy: 0.5598 - val_loss: 1.8874 - val_accuracy: 0.3250\n",
      "Epoch 168/500\n",
      "577/577 [==============================] - 0s 324us/sample - loss: 1.1626 - accuracy: 0.5355 - val_loss: 1.6163 - val_accuracy: 0.3750\n",
      "Epoch 169/500\n",
      "577/577 [==============================] - 0s 345us/sample - loss: 1.1344 - accuracy: 0.5477 - val_loss: 1.6724 - val_accuracy: 0.3375\n",
      "Epoch 170/500\n",
      "577/577 [==============================] - 0s 366us/sample - loss: 1.1473 - accuracy: 0.5407 - val_loss: 1.6496 - val_accuracy: 0.4125\n",
      "Epoch 171/500\n",
      "577/577 [==============================] - 0s 379us/sample - loss: 1.1352 - accuracy: 0.5806 - val_loss: 1.7163 - val_accuracy: 0.3750\n",
      "Epoch 172/500\n",
      "577/577 [==============================] - 0s 355us/sample - loss: 1.1065 - accuracy: 0.5529 - val_loss: 2.3238 - val_accuracy: 0.2875\n",
      "Epoch 173/500\n",
      "577/577 [==============================] - 0s 338us/sample - loss: 1.1372 - accuracy: 0.5563 - val_loss: 1.6105 - val_accuracy: 0.3625\n",
      "Epoch 174/500\n",
      "577/577 [==============================] - 0s 383us/sample - loss: 1.0901 - accuracy: 0.5529 - val_loss: 1.7321 - val_accuracy: 0.3500\n",
      "Epoch 175/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.1413 - accuracy: 0.5667 - val_loss: 1.9540 - val_accuracy: 0.3375\n",
      "Epoch 176/500\n",
      "577/577 [==============================] - 0s 385us/sample - loss: 1.1776 - accuracy: 0.5442 - val_loss: 2.0222 - val_accuracy: 0.2625\n",
      "Epoch 177/500\n",
      "577/577 [==============================] - 0s 325us/sample - loss: 1.0733 - accuracy: 0.5945 - val_loss: 1.8076 - val_accuracy: 0.2875\n",
      "Epoch 178/500\n",
      "577/577 [==============================] - 0s 386us/sample - loss: 1.0891 - accuracy: 0.5719 - val_loss: 1.8218 - val_accuracy: 0.4125\n",
      "Epoch 179/500\n",
      "577/577 [==============================] - 0s 343us/sample - loss: 1.1280 - accuracy: 0.5581 - val_loss: 1.7426 - val_accuracy: 0.3625\n",
      "Epoch 180/500\n",
      "577/577 [==============================] - 0s 457us/sample - loss: 1.1794 - accuracy: 0.5286 - val_loss: 1.7379 - val_accuracy: 0.3500\n",
      "Epoch 181/500\n",
      "577/577 [==============================] - 0s 318us/sample - loss: 1.1458 - accuracy: 0.5390 - val_loss: 1.7569 - val_accuracy: 0.3375\n",
      "Epoch 182/500\n",
      "577/577 [==============================] - 0s 340us/sample - loss: 1.1164 - accuracy: 0.5633 - val_loss: 2.0584 - val_accuracy: 0.2625\n",
      "Epoch 183/500\n",
      "577/577 [==============================] - 0s 330us/sample - loss: 1.1418 - accuracy: 0.5459 - val_loss: 2.4104 - val_accuracy: 0.2250\n",
      "Epoch 184/500\n",
      "577/577 [==============================] - 0s 367us/sample - loss: 1.1530 - accuracy: 0.5459 - val_loss: 1.6808 - val_accuracy: 0.3625\n",
      "Epoch 185/500\n",
      "577/577 [==============================] - 0s 393us/sample - loss: 1.1719 - accuracy: 0.5269 - val_loss: 1.7929 - val_accuracy: 0.3625\n",
      "Epoch 186/500\n",
      "577/577 [==============================] - 0s 385us/sample - loss: 1.1373 - accuracy: 0.5442 - val_loss: 2.3434 - val_accuracy: 0.2750\n",
      "Epoch 187/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.1660 - accuracy: 0.5702 - val_loss: 1.7574 - val_accuracy: 0.3875\n",
      "Epoch 188/500\n",
      "577/577 [==============================] - 0s 355us/sample - loss: 1.0972 - accuracy: 0.5667 - val_loss: 1.8231 - val_accuracy: 0.3125\n",
      "Epoch 189/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 1.1003 - accuracy: 0.5546 - val_loss: 2.1471 - val_accuracy: 0.2750\n",
      "Epoch 190/500\n",
      "577/577 [==============================] - 0s 484us/sample - loss: 1.1146 - accuracy: 0.5511 - val_loss: 2.0557 - val_accuracy: 0.3875\n",
      "Epoch 191/500\n",
      "577/577 [==============================] - 0s 433us/sample - loss: 1.1402 - accuracy: 0.5529 - val_loss: 2.5179 - val_accuracy: 0.2750\n",
      "Epoch 192/500\n",
      "577/577 [==============================] - 0s 422us/sample - loss: 1.1483 - accuracy: 0.5546 - val_loss: 1.9006 - val_accuracy: 0.3250\n",
      "Epoch 193/500\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 1.0746 - accuracy: 0.5789 - val_loss: 2.2239 - val_accuracy: 0.3375\n",
      "Epoch 194/500\n",
      "577/577 [==============================] - 0s 375us/sample - loss: 1.1339 - accuracy: 0.5650 - val_loss: 1.9030 - val_accuracy: 0.3625\n",
      "Epoch 195/500\n",
      "577/577 [==============================] - 0s 343us/sample - loss: 1.0748 - accuracy: 0.5685 - val_loss: 1.7958 - val_accuracy: 0.3250\n",
      "Epoch 196/500\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 1.1627 - accuracy: 0.5321 - val_loss: 2.0300 - val_accuracy: 0.3875\n",
      "Epoch 197/500\n",
      "577/577 [==============================] - 0s 357us/sample - loss: 1.1208 - accuracy: 0.5477 - val_loss: 1.5755 - val_accuracy: 0.3625\n",
      "Epoch 198/500\n",
      "577/577 [==============================] - 0s 352us/sample - loss: 1.1377 - accuracy: 0.5511 - val_loss: 1.6271 - val_accuracy: 0.4000\n",
      "Epoch 199/500\n",
      "577/577 [==============================] - 0s 415us/sample - loss: 1.1004 - accuracy: 0.5581 - val_loss: 1.6196 - val_accuracy: 0.3750\n",
      "Epoch 200/500\n",
      "577/577 [==============================] - 0s 338us/sample - loss: 1.0810 - accuracy: 0.5962 - val_loss: 1.5364 - val_accuracy: 0.4375\n",
      "Epoch 201/500\n",
      "577/577 [==============================] - 0s 341us/sample - loss: 1.0923 - accuracy: 0.5875 - val_loss: 1.7295 - val_accuracy: 0.4250\n",
      "Epoch 202/500\n",
      "577/577 [==============================] - 0s 337us/sample - loss: 1.1105 - accuracy: 0.5546 - val_loss: 3.0275 - val_accuracy: 0.2500\n",
      "Epoch 203/500\n",
      "577/577 [==============================] - 0s 376us/sample - loss: 1.0950 - accuracy: 0.5511 - val_loss: 2.1118 - val_accuracy: 0.2875\n",
      "Epoch 204/500\n",
      "577/577 [==============================] - 0s 386us/sample - loss: 1.0927 - accuracy: 0.5789 - val_loss: 2.6458 - val_accuracy: 0.1875\n",
      "Epoch 205/500\n",
      "577/577 [==============================] - 0s 362us/sample - loss: 1.1312 - accuracy: 0.5615 - val_loss: 1.5495 - val_accuracy: 0.4125\n",
      "Epoch 206/500\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 1.1393 - accuracy: 0.5563 - val_loss: 1.6598 - val_accuracy: 0.3625\n",
      "Epoch 207/500\n",
      "577/577 [==============================] - 0s 372us/sample - loss: 1.1203 - accuracy: 0.5581 - val_loss: 1.7850 - val_accuracy: 0.3500\n",
      "Epoch 208/500\n",
      "577/577 [==============================] - 0s 415us/sample - loss: 1.1188 - accuracy: 0.5477 - val_loss: 2.2978 - val_accuracy: 0.3000\n",
      "Epoch 209/500\n",
      "577/577 [==============================] - 0s 381us/sample - loss: 1.1234 - accuracy: 0.5823 - val_loss: 1.7962 - val_accuracy: 0.3750\n",
      "Epoch 210/500\n",
      "577/577 [==============================] - 0s 377us/sample - loss: 1.1625 - accuracy: 0.5390 - val_loss: 1.6132 - val_accuracy: 0.3875\n",
      "Epoch 211/500\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 1.0862 - accuracy: 0.5927 - val_loss: 2.4670 - val_accuracy: 0.2625\n",
      "Epoch 212/500\n",
      "577/577 [==============================] - 0s 339us/sample - loss: 1.1425 - accuracy: 0.5563 - val_loss: 1.6150 - val_accuracy: 0.3500\n",
      "Epoch 213/500\n",
      "577/577 [==============================] - 0s 405us/sample - loss: 1.1230 - accuracy: 0.5546 - val_loss: 1.8099 - val_accuracy: 0.3125\n",
      "Epoch 214/500\n",
      "577/577 [==============================] - 0s 368us/sample - loss: 1.1296 - accuracy: 0.5633 - val_loss: 2.2163 - val_accuracy: 0.2750\n",
      "Epoch 215/500\n",
      "577/577 [==============================] - 0s 415us/sample - loss: 1.1068 - accuracy: 0.5841 - val_loss: 1.9474 - val_accuracy: 0.2875\n",
      "Epoch 216/500\n",
      "577/577 [==============================] - 0s 495us/sample - loss: 1.0857 - accuracy: 0.5563 - val_loss: 1.9315 - val_accuracy: 0.3625\n",
      "Epoch 217/500\n",
      "577/577 [==============================] - 0s 398us/sample - loss: 1.1161 - accuracy: 0.5546 - val_loss: 2.0314 - val_accuracy: 0.3500\n",
      "Epoch 218/500\n",
      "577/577 [==============================] - 0s 339us/sample - loss: 1.0920 - accuracy: 0.5650 - val_loss: 1.6709 - val_accuracy: 0.3375\n",
      "Epoch 219/500\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 1.0954 - accuracy: 0.5927 - val_loss: 1.7970 - val_accuracy: 0.3375\n",
      "Epoch 220/500\n",
      "577/577 [==============================] - 0s 327us/sample - loss: 1.0947 - accuracy: 0.5494 - val_loss: 1.7448 - val_accuracy: 0.3750\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 316us/sample - loss: 1.1000 - accuracy: 0.5615 - val_loss: 1.6629 - val_accuracy: 0.4000\n",
      "Epoch 222/500\n",
      "577/577 [==============================] - 0s 357us/sample - loss: 1.0368 - accuracy: 0.5875 - val_loss: 2.0789 - val_accuracy: 0.3250\n",
      "Epoch 223/500\n",
      "577/577 [==============================] - 0s 303us/sample - loss: 1.1199 - accuracy: 0.5598 - val_loss: 1.6287 - val_accuracy: 0.4500\n",
      "Epoch 224/500\n",
      "577/577 [==============================] - 0s 332us/sample - loss: 1.0851 - accuracy: 0.5806 - val_loss: 1.6919 - val_accuracy: 0.4125\n",
      "Epoch 225/500\n",
      "577/577 [==============================] - 0s 305us/sample - loss: 1.1065 - accuracy: 0.5442 - val_loss: 2.1153 - val_accuracy: 0.3625\n",
      "Epoch 226/500\n",
      "577/577 [==============================] - 0s 336us/sample - loss: 1.1198 - accuracy: 0.5477 - val_loss: 1.7393 - val_accuracy: 0.4000\n",
      "Epoch 227/500\n",
      "577/577 [==============================] - 0s 379us/sample - loss: 1.1015 - accuracy: 0.5477 - val_loss: 2.7983 - val_accuracy: 0.2375\n",
      "Epoch 228/500\n",
      "577/577 [==============================] - 0s 326us/sample - loss: 1.0535 - accuracy: 0.5858 - val_loss: 1.7039 - val_accuracy: 0.4375\n",
      "Epoch 229/500\n",
      "577/577 [==============================] - 0s 288us/sample - loss: 1.0715 - accuracy: 0.6049 - val_loss: 1.5709 - val_accuracy: 0.4000\n",
      "Epoch 230/500\n",
      "577/577 [==============================] - 0s 326us/sample - loss: 1.0893 - accuracy: 0.5754 - val_loss: 2.5071 - val_accuracy: 0.2250\n",
      "Epoch 231/500\n",
      "577/577 [==============================] - 0s 296us/sample - loss: 1.0771 - accuracy: 0.5823 - val_loss: 1.7105 - val_accuracy: 0.3500\n",
      "Epoch 232/500\n",
      "577/577 [==============================] - 0s 379us/sample - loss: 1.1038 - accuracy: 0.5581 - val_loss: 1.8067 - val_accuracy: 0.3375\n",
      "Epoch 233/500\n",
      "577/577 [==============================] - 0s 326us/sample - loss: 1.1164 - accuracy: 0.5494 - val_loss: 1.8914 - val_accuracy: 0.2875\n",
      "Epoch 234/500\n",
      "577/577 [==============================] - 0s 284us/sample - loss: 1.0962 - accuracy: 0.5806 - val_loss: 2.3263 - val_accuracy: 0.2875\n",
      "Epoch 235/500\n",
      "577/577 [==============================] - 0s 300us/sample - loss: 1.1179 - accuracy: 0.5494 - val_loss: 2.1872 - val_accuracy: 0.2625\n",
      "Epoch 236/500\n",
      "577/577 [==============================] - 0s 412us/sample - loss: 1.0564 - accuracy: 0.5719 - val_loss: 1.6447 - val_accuracy: 0.3625\n",
      "Epoch 237/500\n",
      "577/577 [==============================] - 0s 384us/sample - loss: 1.1047 - accuracy: 0.5598 - val_loss: 1.8048 - val_accuracy: 0.3000\n",
      "Epoch 238/500\n",
      "577/577 [==============================] - 0s 539us/sample - loss: 1.1333 - accuracy: 0.5563 - val_loss: 2.4573 - val_accuracy: 0.1750\n",
      "Epoch 239/500\n",
      "577/577 [==============================] - 0s 334us/sample - loss: 1.1027 - accuracy: 0.5615 - val_loss: 2.0503 - val_accuracy: 0.3375\n",
      "Epoch 240/500\n",
      "577/577 [==============================] - 0s 319us/sample - loss: 1.1142 - accuracy: 0.5685 - val_loss: 2.2710 - val_accuracy: 0.3125\n",
      "Epoch 241/500\n",
      "577/577 [==============================] - 0s 332us/sample - loss: 1.0594 - accuracy: 0.5875 - val_loss: 1.9438 - val_accuracy: 0.4250\n",
      "Epoch 242/500\n",
      "577/577 [==============================] - 0s 486us/sample - loss: 1.0999 - accuracy: 0.5459 - val_loss: 2.2661 - val_accuracy: 0.3375\n",
      "Epoch 243/500\n",
      "577/577 [==============================] - 0s 340us/sample - loss: 1.1158 - accuracy: 0.5598 - val_loss: 1.7604 - val_accuracy: 0.4125\n",
      "Epoch 244/500\n",
      "577/577 [==============================] - 0s 324us/sample - loss: 1.0773 - accuracy: 0.5598 - val_loss: 2.2311 - val_accuracy: 0.3125\n",
      "Epoch 245/500\n",
      "577/577 [==============================] - 0s 342us/sample - loss: 1.0209 - accuracy: 0.5997 - val_loss: 1.9076 - val_accuracy: 0.3375\n",
      "Epoch 246/500\n",
      "577/577 [==============================] - 0s 386us/sample - loss: 1.0322 - accuracy: 0.6031 - val_loss: 1.7267 - val_accuracy: 0.3125\n",
      "Epoch 247/500\n",
      "577/577 [==============================] - 0s 378us/sample - loss: 1.0500 - accuracy: 0.5962 - val_loss: 2.2846 - val_accuracy: 0.3000\n",
      "Epoch 248/500\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 1.0561 - accuracy: 0.5841 - val_loss: 2.3464 - val_accuracy: 0.3375\n",
      "Epoch 249/500\n",
      "577/577 [==============================] - 0s 534us/sample - loss: 1.1047 - accuracy: 0.5667 - val_loss: 1.9626 - val_accuracy: 0.3500\n",
      "Epoch 250/500\n",
      "577/577 [==============================] - 0s 529us/sample - loss: 1.1417 - accuracy: 0.5771 - val_loss: 2.2491 - val_accuracy: 0.3500\n",
      "Epoch 251/500\n",
      "577/577 [==============================] - 0s 570us/sample - loss: 1.0666 - accuracy: 0.5650 - val_loss: 1.6976 - val_accuracy: 0.4500\n",
      "Epoch 252/500\n",
      "577/577 [==============================] - 1s 879us/sample - loss: 1.0778 - accuracy: 0.5945 - val_loss: 1.8480 - val_accuracy: 0.3750\n",
      "Epoch 253/500\n",
      "577/577 [==============================] - 0s 586us/sample - loss: 1.0631 - accuracy: 0.5841 - val_loss: 3.0412 - val_accuracy: 0.2500\n",
      "Epoch 254/500\n",
      "577/577 [==============================] - 0s 395us/sample - loss: 1.0853 - accuracy: 0.5893 - val_loss: 2.2201 - val_accuracy: 0.3125\n",
      "Epoch 255/500\n",
      "577/577 [==============================] - 0s 403us/sample - loss: 1.1086 - accuracy: 0.5737 - val_loss: 1.9011 - val_accuracy: 0.3500\n",
      "Epoch 256/500\n",
      "577/577 [==============================] - 0s 810us/sample - loss: 1.1266 - accuracy: 0.5789 - val_loss: 2.5904 - val_accuracy: 0.2875\n",
      "Epoch 257/500\n",
      "577/577 [==============================] - 0s 466us/sample - loss: 1.1110 - accuracy: 0.5442 - val_loss: 1.9944 - val_accuracy: 0.3250\n",
      "Epoch 258/500\n",
      "577/577 [==============================] - 0s 626us/sample - loss: 1.0530 - accuracy: 0.6118 - val_loss: 2.2826 - val_accuracy: 0.2875\n",
      "Epoch 259/500\n",
      "577/577 [==============================] - 0s 615us/sample - loss: 1.0965 - accuracy: 0.5945 - val_loss: 1.8974 - val_accuracy: 0.4000\n",
      "Epoch 260/500\n",
      "577/577 [==============================] - 0s 384us/sample - loss: 1.0237 - accuracy: 0.6118 - val_loss: 1.7145 - val_accuracy: 0.3625\n",
      "Epoch 261/500\n",
      "577/577 [==============================] - 0s 378us/sample - loss: 1.0767 - accuracy: 0.5702 - val_loss: 1.6597 - val_accuracy: 0.4000\n",
      "Epoch 262/500\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 1.0371 - accuracy: 0.6205 - val_loss: 2.0596 - val_accuracy: 0.4000\n",
      "Epoch 263/500\n",
      "577/577 [==============================] - 0s 406us/sample - loss: 1.0904 - accuracy: 0.5719 - val_loss: 1.7102 - val_accuracy: 0.3750\n",
      "Epoch 264/500\n",
      "577/577 [==============================] - 0s 704us/sample - loss: 1.1284 - accuracy: 0.5598 - val_loss: 1.8149 - val_accuracy: 0.3250\n",
      "Epoch 265/500\n",
      "577/577 [==============================] - 0s 331us/sample - loss: 1.0647 - accuracy: 0.6101 - val_loss: 1.9405 - val_accuracy: 0.3000\n",
      "Epoch 266/500\n",
      "577/577 [==============================] - 0s 397us/sample - loss: 1.0991 - accuracy: 0.5598 - val_loss: 2.1868 - val_accuracy: 0.2375\n",
      "Epoch 267/500\n",
      "577/577 [==============================] - 0s 615us/sample - loss: 1.0583 - accuracy: 0.5823 - val_loss: 2.5919 - val_accuracy: 0.2875\n",
      "Epoch 268/500\n",
      "577/577 [==============================] - 0s 458us/sample - loss: 1.0813 - accuracy: 0.5754 - val_loss: 1.8737 - val_accuracy: 0.3250\n",
      "Epoch 269/500\n",
      "577/577 [==============================] - 0s 552us/sample - loss: 1.0167 - accuracy: 0.6049 - val_loss: 1.5682 - val_accuracy: 0.3875\n",
      "Epoch 270/500\n",
      "577/577 [==============================] - 0s 385us/sample - loss: 1.0502 - accuracy: 0.5875 - val_loss: 1.5967 - val_accuracy: 0.4125\n",
      "Epoch 271/500\n",
      "577/577 [==============================] - 0s 369us/sample - loss: 1.0245 - accuracy: 0.5771 - val_loss: 1.6481 - val_accuracy: 0.4250\n",
      "Epoch 272/500\n",
      "577/577 [==============================] - 0s 354us/sample - loss: 1.1084 - accuracy: 0.5702 - val_loss: 1.9230 - val_accuracy: 0.3375\n",
      "Epoch 273/500\n",
      "577/577 [==============================] - 0s 361us/sample - loss: 1.0582 - accuracy: 0.5979 - val_loss: 2.5082 - val_accuracy: 0.2625\n",
      "Epoch 274/500\n",
      "577/577 [==============================] - 0s 346us/sample - loss: 1.0314 - accuracy: 0.5979 - val_loss: 2.3719 - val_accuracy: 0.2500\n",
      "Epoch 275/500\n",
      "577/577 [==============================] - 0s 415us/sample - loss: 1.0691 - accuracy: 0.5945 - val_loss: 3.3109 - val_accuracy: 0.2375\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 645us/sample - loss: 1.0346 - accuracy: 0.5893 - val_loss: 1.7764 - val_accuracy: 0.3500\n",
      "Epoch 277/500\n",
      "577/577 [==============================] - 0s 299us/sample - loss: 1.0223 - accuracy: 0.5875 - val_loss: 1.7577 - val_accuracy: 0.4250\n",
      "Epoch 278/500\n",
      "577/577 [==============================] - 0s 391us/sample - loss: 1.0487 - accuracy: 0.6049 - val_loss: 1.7949 - val_accuracy: 0.4000\n",
      "Epoch 279/500\n",
      "577/577 [==============================] - 0s 571us/sample - loss: 1.0822 - accuracy: 0.5719 - val_loss: 1.6788 - val_accuracy: 0.3500\n",
      "Epoch 280/500\n",
      "577/577 [==============================] - 0s 584us/sample - loss: 1.0887 - accuracy: 0.5875 - val_loss: 2.8988 - val_accuracy: 0.3000\n",
      "Epoch 281/500\n",
      "577/577 [==============================] - 0s 513us/sample - loss: 1.0543 - accuracy: 0.5893 - val_loss: 1.8441 - val_accuracy: 0.4125\n",
      "Epoch 282/500\n",
      "577/577 [==============================] - 0s 414us/sample - loss: 1.1299 - accuracy: 0.5754 - val_loss: 1.9098 - val_accuracy: 0.3875\n",
      "Epoch 283/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 1.0625 - accuracy: 0.5910 - val_loss: 2.3365 - val_accuracy: 0.2625\n",
      "Epoch 284/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 1.0528 - accuracy: 0.5771 - val_loss: 1.7282 - val_accuracy: 0.3625\n",
      "Epoch 285/500\n",
      "577/577 [==============================] - 0s 359us/sample - loss: 1.0792 - accuracy: 0.5737 - val_loss: 1.7283 - val_accuracy: 0.4500\n",
      "Epoch 286/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.0278 - accuracy: 0.5858 - val_loss: 1.9058 - val_accuracy: 0.3125\n",
      "Epoch 287/500\n",
      "577/577 [==============================] - 0s 652us/sample - loss: 1.0009 - accuracy: 0.6343 - val_loss: 1.6373 - val_accuracy: 0.3000\n",
      "Epoch 288/500\n",
      "577/577 [==============================] - 0s 362us/sample - loss: 1.0168 - accuracy: 0.5875 - val_loss: 1.7299 - val_accuracy: 0.3250\n",
      "Epoch 289/500\n",
      "577/577 [==============================] - 0s 370us/sample - loss: 1.0927 - accuracy: 0.5771 - val_loss: 1.8625 - val_accuracy: 0.3125\n",
      "Epoch 290/500\n",
      "577/577 [==============================] - 0s 381us/sample - loss: 1.0768 - accuracy: 0.5737 - val_loss: 1.8643 - val_accuracy: 0.3500\n",
      "Epoch 291/500\n",
      "577/577 [==============================] - 0s 596us/sample - loss: 1.0360 - accuracy: 0.5997 - val_loss: 1.8341 - val_accuracy: 0.4000\n",
      "Epoch 292/500\n",
      "577/577 [==============================] - 0s 446us/sample - loss: 1.0167 - accuracy: 0.5823 - val_loss: 1.7490 - val_accuracy: 0.3500\n",
      "Epoch 293/500\n",
      "577/577 [==============================] - 0s 377us/sample - loss: 1.0954 - accuracy: 0.5667 - val_loss: 1.7899 - val_accuracy: 0.3125\n",
      "Epoch 294/500\n",
      "577/577 [==============================] - 0s 696us/sample - loss: 1.0770 - accuracy: 0.5546 - val_loss: 1.9773 - val_accuracy: 0.2875\n",
      "Epoch 295/500\n",
      "577/577 [==============================] - 0s 422us/sample - loss: 1.0491 - accuracy: 0.5893 - val_loss: 2.3273 - val_accuracy: 0.3500\n",
      "Epoch 296/500\n",
      "577/577 [==============================] - 0s 652us/sample - loss: 1.0868 - accuracy: 0.5633 - val_loss: 2.4763 - val_accuracy: 0.3500\n",
      "Epoch 297/500\n",
      "577/577 [==============================] - 0s 701us/sample - loss: 1.0525 - accuracy: 0.5719 - val_loss: 2.1343 - val_accuracy: 0.3625\n",
      "Epoch 298/500\n",
      "577/577 [==============================] - 0s 570us/sample - loss: 1.1344 - accuracy: 0.5633 - val_loss: 2.4522 - val_accuracy: 0.2875\n",
      "Epoch 299/500\n",
      "577/577 [==============================] - 0s 361us/sample - loss: 1.0729 - accuracy: 0.5858 - val_loss: 2.1102 - val_accuracy: 0.3500\n",
      "Epoch 300/500\n",
      "577/577 [==============================] - 0s 615us/sample - loss: 1.0492 - accuracy: 0.5858 - val_loss: 1.8711 - val_accuracy: 0.3375\n",
      "Epoch 301/500\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 1.0629 - accuracy: 0.5771 - val_loss: 1.9001 - val_accuracy: 0.4125\n",
      "Epoch 302/500\n",
      "577/577 [==============================] - 0s 570us/sample - loss: 1.0604 - accuracy: 0.5979 - val_loss: 2.1488 - val_accuracy: 0.3250\n",
      "Epoch 303/500\n",
      "577/577 [==============================] - 0s 424us/sample - loss: 1.0755 - accuracy: 0.5598 - val_loss: 2.7474 - val_accuracy: 0.3500\n",
      "Epoch 304/500\n",
      "577/577 [==============================] - 0s 590us/sample - loss: 1.0477 - accuracy: 0.5875 - val_loss: 2.0375 - val_accuracy: 0.3375\n",
      "Epoch 305/500\n",
      "577/577 [==============================] - 0s 516us/sample - loss: 1.0746 - accuracy: 0.5806 - val_loss: 1.6882 - val_accuracy: 0.4250\n",
      "Epoch 306/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 1.0572 - accuracy: 0.5667 - val_loss: 1.6295 - val_accuracy: 0.3750\n",
      "Epoch 307/500\n",
      "577/577 [==============================] - 0s 592us/sample - loss: 1.0710 - accuracy: 0.5754 - val_loss: 1.9137 - val_accuracy: 0.3750\n",
      "Epoch 308/500\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 1.0698 - accuracy: 0.6014 - val_loss: 2.3729 - val_accuracy: 0.1875\n",
      "Epoch 309/500\n",
      "577/577 [==============================] - 0s 592us/sample - loss: 1.1060 - accuracy: 0.5719 - val_loss: 2.2936 - val_accuracy: 0.2375\n",
      "Epoch 310/500\n",
      "577/577 [==============================] - 0s 626us/sample - loss: 1.0422 - accuracy: 0.5771 - val_loss: 1.9109 - val_accuracy: 0.3625\n",
      "Epoch 311/500\n",
      "577/577 [==============================] - 0s 452us/sample - loss: 1.0013 - accuracy: 0.6031 - val_loss: 2.0801 - val_accuracy: 0.3375\n",
      "Epoch 312/500\n",
      "577/577 [==============================] - 0s 443us/sample - loss: 1.0577 - accuracy: 0.5806 - val_loss: 1.8219 - val_accuracy: 0.3500\n",
      "Epoch 313/500\n",
      "577/577 [==============================] - 0s 567us/sample - loss: 1.0252 - accuracy: 0.6031 - val_loss: 1.8380 - val_accuracy: 0.4375\n",
      "Epoch 314/500\n",
      "577/577 [==============================] - 0s 478us/sample - loss: 1.0614 - accuracy: 0.5841 - val_loss: 2.4000 - val_accuracy: 0.3000\n",
      "Epoch 315/500\n",
      "577/577 [==============================] - 0s 392us/sample - loss: 1.0334 - accuracy: 0.5702 - val_loss: 2.2146 - val_accuracy: 0.4000\n",
      "Epoch 316/500\n",
      "577/577 [==============================] - 0s 669us/sample - loss: 1.0402 - accuracy: 0.6066 - val_loss: 1.7436 - val_accuracy: 0.3625\n",
      "Epoch 317/500\n",
      "577/577 [==============================] - 0s 380us/sample - loss: 0.9825 - accuracy: 0.6205 - val_loss: 3.1802 - val_accuracy: 0.2625\n",
      "Epoch 318/500\n",
      "577/577 [==============================] - 0s 380us/sample - loss: 1.0408 - accuracy: 0.5997 - val_loss: 1.9064 - val_accuracy: 0.3875\n",
      "Epoch 319/500\n",
      "577/577 [==============================] - 0s 328us/sample - loss: 1.0576 - accuracy: 0.6049 - val_loss: 1.7189 - val_accuracy: 0.4250\n",
      "Epoch 320/500\n",
      "577/577 [==============================] - 0s 343us/sample - loss: 1.0541 - accuracy: 0.5875 - val_loss: 2.0283 - val_accuracy: 0.3250\n",
      "Epoch 321/500\n",
      "577/577 [==============================] - 0s 412us/sample - loss: 1.0665 - accuracy: 0.5962 - val_loss: 2.0375 - val_accuracy: 0.2625\n",
      "Epoch 322/500\n",
      "577/577 [==============================] - 0s 462us/sample - loss: 1.0864 - accuracy: 0.5910 - val_loss: 2.2431 - val_accuracy: 0.3000\n",
      "Epoch 323/500\n",
      "577/577 [==============================] - 0s 384us/sample - loss: 1.0407 - accuracy: 0.5910 - val_loss: 2.9060 - val_accuracy: 0.2375\n",
      "Epoch 324/500\n",
      "577/577 [==============================] - 0s 365us/sample - loss: 1.0732 - accuracy: 0.5962 - val_loss: 1.7152 - val_accuracy: 0.4125\n",
      "Epoch 325/500\n",
      "577/577 [==============================] - 0s 385us/sample - loss: 1.0394 - accuracy: 0.6083 - val_loss: 1.7787 - val_accuracy: 0.3750\n",
      "Epoch 326/500\n",
      "577/577 [==============================] - 0s 386us/sample - loss: 1.0660 - accuracy: 0.5823 - val_loss: 1.7963 - val_accuracy: 0.3500\n",
      "Epoch 327/500\n",
      "577/577 [==============================] - 0s 346us/sample - loss: 1.0143 - accuracy: 0.6205 - val_loss: 1.7978 - val_accuracy: 0.3250\n",
      "Epoch 328/500\n",
      "577/577 [==============================] - 0s 411us/sample - loss: 1.0441 - accuracy: 0.5979 - val_loss: 1.7222 - val_accuracy: 0.3500\n",
      "Epoch 329/500\n",
      "577/577 [==============================] - 0s 405us/sample - loss: 1.0489 - accuracy: 0.5979 - val_loss: 2.0449 - val_accuracy: 0.3500\n",
      "Epoch 330/500\n",
      "577/577 [==============================] - 0s 403us/sample - loss: 0.9922 - accuracy: 0.6170 - val_loss: 2.1191 - val_accuracy: 0.2875\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 410us/sample - loss: 1.0435 - accuracy: 0.5875 - val_loss: 2.1468 - val_accuracy: 0.3625\n",
      "Epoch 332/500\n",
      "577/577 [==============================] - 0s 300us/sample - loss: 1.0855 - accuracy: 0.5875 - val_loss: 1.8257 - val_accuracy: 0.4250\n",
      "Epoch 333/500\n",
      "577/577 [==============================] - 0s 366us/sample - loss: 1.0327 - accuracy: 0.5979 - val_loss: 2.0406 - val_accuracy: 0.3250\n",
      "Epoch 334/500\n",
      "577/577 [==============================] - 0s 369us/sample - loss: 1.0481 - accuracy: 0.5927 - val_loss: 1.7879 - val_accuracy: 0.3875\n",
      "Epoch 335/500\n",
      "577/577 [==============================] - 0s 373us/sample - loss: 1.0036 - accuracy: 0.6170 - val_loss: 1.9022 - val_accuracy: 0.3875\n",
      "Epoch 336/500\n",
      "577/577 [==============================] - 0s 632us/sample - loss: 1.0611 - accuracy: 0.5789 - val_loss: 1.9487 - val_accuracy: 0.3750\n",
      "Epoch 337/500\n",
      "577/577 [==============================] - 0s 399us/sample - loss: 1.0638 - accuracy: 0.5823 - val_loss: 1.6773 - val_accuracy: 0.4000\n",
      "Epoch 338/500\n",
      "577/577 [==============================] - 0s 570us/sample - loss: 1.0371 - accuracy: 0.6066 - val_loss: 2.0960 - val_accuracy: 0.3000\n",
      "Epoch 339/500\n",
      "577/577 [==============================] - 0s 511us/sample - loss: 1.0283 - accuracy: 0.5875 - val_loss: 2.0149 - val_accuracy: 0.3500\n",
      "Epoch 340/500\n",
      "577/577 [==============================] - 0s 483us/sample - loss: 1.0073 - accuracy: 0.6153 - val_loss: 1.9022 - val_accuracy: 0.3625\n",
      "Epoch 341/500\n",
      "577/577 [==============================] - 0s 575us/sample - loss: 1.0505 - accuracy: 0.5823 - val_loss: 1.7819 - val_accuracy: 0.3625\n",
      "Epoch 342/500\n",
      "577/577 [==============================] - 0s 657us/sample - loss: 1.0168 - accuracy: 0.6049 - val_loss: 2.0501 - val_accuracy: 0.3375\n",
      "Epoch 343/500\n",
      "577/577 [==============================] - 0s 639us/sample - loss: 1.0020 - accuracy: 0.5927 - val_loss: 1.9181 - val_accuracy: 0.3625\n",
      "Epoch 344/500\n",
      "577/577 [==============================] - 0s 395us/sample - loss: 0.9614 - accuracy: 0.6205 - val_loss: 2.2561 - val_accuracy: 0.3625\n",
      "Epoch 345/500\n",
      "577/577 [==============================] - 0s 446us/sample - loss: 0.9928 - accuracy: 0.6049 - val_loss: 1.6263 - val_accuracy: 0.3875\n",
      "Epoch 346/500\n",
      "577/577 [==============================] - 0s 649us/sample - loss: 0.9836 - accuracy: 0.6274 - val_loss: 1.9616 - val_accuracy: 0.3500\n",
      "Epoch 347/500\n",
      "577/577 [==============================] - 0s 757us/sample - loss: 0.9732 - accuracy: 0.6083 - val_loss: 1.9329 - val_accuracy: 0.3625\n",
      "Epoch 348/500\n",
      "577/577 [==============================] - 0s 462us/sample - loss: 0.9529 - accuracy: 0.6170 - val_loss: 1.7289 - val_accuracy: 0.4000\n",
      "Epoch 349/500\n",
      "577/577 [==============================] - 0s 383us/sample - loss: 1.0361 - accuracy: 0.5910 - val_loss: 1.8398 - val_accuracy: 0.4000\n",
      "Epoch 350/500\n",
      "577/577 [==============================] - 0s 384us/sample - loss: 1.0115 - accuracy: 0.5962 - val_loss: 1.9515 - val_accuracy: 0.3375\n",
      "Epoch 351/500\n",
      "577/577 [==============================] - 0s 336us/sample - loss: 1.0489 - accuracy: 0.5789 - val_loss: 1.7434 - val_accuracy: 0.3750\n",
      "Epoch 352/500\n",
      "577/577 [==============================] - 0s 418us/sample - loss: 1.0211 - accuracy: 0.5979 - val_loss: 2.0176 - val_accuracy: 0.3250\n",
      "Epoch 353/500\n",
      "577/577 [==============================] - 0s 384us/sample - loss: 1.0078 - accuracy: 0.6170 - val_loss: 2.3530 - val_accuracy: 0.4375\n",
      "Epoch 354/500\n",
      "577/577 [==============================] - 0s 340us/sample - loss: 1.0174 - accuracy: 0.5771 - val_loss: 2.2468 - val_accuracy: 0.4375\n",
      "Epoch 355/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 0.9987 - accuracy: 0.6066 - val_loss: 1.7259 - val_accuracy: 0.4375\n",
      "Epoch 356/500\n",
      "577/577 [==============================] - 0s 430us/sample - loss: 1.0231 - accuracy: 0.6256 - val_loss: 2.1351 - val_accuracy: 0.3625\n",
      "Epoch 357/500\n",
      "577/577 [==============================] - 0s 677us/sample - loss: 1.0132 - accuracy: 0.5962 - val_loss: 2.0213 - val_accuracy: 0.3375\n",
      "Epoch 358/500\n",
      "577/577 [==============================] - 0s 391us/sample - loss: 1.0603 - accuracy: 0.5633 - val_loss: 1.8593 - val_accuracy: 0.4125\n",
      "Epoch 359/500\n",
      "577/577 [==============================] - 0s 611us/sample - loss: 0.9838 - accuracy: 0.6049 - val_loss: 2.4025 - val_accuracy: 0.3375\n",
      "Epoch 360/500\n",
      "577/577 [==============================] - 0s 549us/sample - loss: 0.9993 - accuracy: 0.5979 - val_loss: 1.8907 - val_accuracy: 0.4000\n",
      "Epoch 361/500\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 1.0027 - accuracy: 0.6014 - val_loss: 2.9449 - val_accuracy: 0.2500\n",
      "Epoch 362/500\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 0.9525 - accuracy: 0.6239 - val_loss: 3.0484 - val_accuracy: 0.2875\n",
      "Epoch 363/500\n",
      "577/577 [==============================] - 0s 446us/sample - loss: 1.0159 - accuracy: 0.6187 - val_loss: 3.0120 - val_accuracy: 0.3125\n",
      "Epoch 364/500\n",
      "577/577 [==============================] - 0s 646us/sample - loss: 1.0146 - accuracy: 0.5997 - val_loss: 2.0093 - val_accuracy: 0.3500\n",
      "Epoch 365/500\n",
      "577/577 [==============================] - 0s 344us/sample - loss: 0.9637 - accuracy: 0.6378 - val_loss: 2.1640 - val_accuracy: 0.3000\n",
      "Epoch 366/500\n",
      "577/577 [==============================] - 0s 460us/sample - loss: 1.0645 - accuracy: 0.5997 - val_loss: 1.8459 - val_accuracy: 0.3750\n",
      "Epoch 367/500\n",
      "577/577 [==============================] - 0s 381us/sample - loss: 1.0246 - accuracy: 0.6135 - val_loss: 2.6440 - val_accuracy: 0.2875\n",
      "Epoch 368/500\n",
      "577/577 [==============================] - 0s 658us/sample - loss: 0.9471 - accuracy: 0.6187 - val_loss: 1.8210 - val_accuracy: 0.3625\n",
      "Epoch 369/500\n",
      "577/577 [==============================] - 0s 697us/sample - loss: 0.9941 - accuracy: 0.6153 - val_loss: 1.8144 - val_accuracy: 0.3875\n",
      "Epoch 370/500\n",
      "577/577 [==============================] - 0s 722us/sample - loss: 1.0203 - accuracy: 0.5927 - val_loss: 2.6041 - val_accuracy: 0.3625\n",
      "Epoch 371/500\n",
      "577/577 [==============================] - 0s 670us/sample - loss: 0.9856 - accuracy: 0.6135 - val_loss: 2.6815 - val_accuracy: 0.2750\n",
      "Epoch 372/500\n",
      "577/577 [==============================] - 0s 402us/sample - loss: 0.9875 - accuracy: 0.6049 - val_loss: 2.6018 - val_accuracy: 0.2875\n",
      "Epoch 373/500\n",
      "577/577 [==============================] - 0s 467us/sample - loss: 0.9828 - accuracy: 0.6031 - val_loss: 1.7596 - val_accuracy: 0.3625\n",
      "Epoch 374/500\n",
      "577/577 [==============================] - 0s 545us/sample - loss: 1.0268 - accuracy: 0.5858 - val_loss: 2.0009 - val_accuracy: 0.2875\n",
      "Epoch 375/500\n",
      "577/577 [==============================] - 0s 638us/sample - loss: 1.0177 - accuracy: 0.6343 - val_loss: 1.6506 - val_accuracy: 0.4000\n",
      "Epoch 376/500\n",
      "577/577 [==============================] - 0s 532us/sample - loss: 0.9800 - accuracy: 0.6308 - val_loss: 1.6311 - val_accuracy: 0.4750\n",
      "Epoch 377/500\n",
      "577/577 [==============================] - 0s 367us/sample - loss: 0.9850 - accuracy: 0.6343 - val_loss: 1.7050 - val_accuracy: 0.3875\n",
      "Epoch 378/500\n",
      "577/577 [==============================] - 0s 341us/sample - loss: 1.0159 - accuracy: 0.5615 - val_loss: 2.0859 - val_accuracy: 0.3500\n",
      "Epoch 379/500\n",
      "577/577 [==============================] - 0s 396us/sample - loss: 1.0303 - accuracy: 0.5789 - val_loss: 1.8658 - val_accuracy: 0.3750\n",
      "Epoch 380/500\n",
      "577/577 [==============================] - 0s 335us/sample - loss: 1.0164 - accuracy: 0.5997 - val_loss: 2.0329 - val_accuracy: 0.4000\n",
      "Epoch 381/500\n",
      "577/577 [==============================] - 0s 373us/sample - loss: 1.0280 - accuracy: 0.5997 - val_loss: 2.4402 - val_accuracy: 0.2750\n",
      "Epoch 382/500\n",
      "577/577 [==============================] - 0s 303us/sample - loss: 1.0153 - accuracy: 0.5945 - val_loss: 2.0844 - val_accuracy: 0.3625\n",
      "Epoch 383/500\n",
      "577/577 [==============================] - 0s 363us/sample - loss: 0.9856 - accuracy: 0.6101 - val_loss: 2.6472 - val_accuracy: 0.2250\n",
      "Epoch 384/500\n",
      "577/577 [==============================] - 0s 348us/sample - loss: 1.0065 - accuracy: 0.5962 - val_loss: 1.8464 - val_accuracy: 0.3500\n",
      "Epoch 385/500\n",
      "577/577 [==============================] - 0s 626us/sample - loss: 0.9854 - accuracy: 0.5979 - val_loss: 1.9011 - val_accuracy: 0.3500\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 442us/sample - loss: 0.9759 - accuracy: 0.6343 - val_loss: 2.4858 - val_accuracy: 0.3000\n",
      "Epoch 387/500\n",
      "577/577 [==============================] - 0s 645us/sample - loss: 0.9926 - accuracy: 0.6326 - val_loss: 2.1022 - val_accuracy: 0.3125\n",
      "Epoch 388/500\n",
      "577/577 [==============================] - 0s 336us/sample - loss: 1.0327 - accuracy: 0.6014 - val_loss: 2.6343 - val_accuracy: 0.3500\n",
      "Epoch 389/500\n",
      "577/577 [==============================] - 0s 449us/sample - loss: 0.9647 - accuracy: 0.6187 - val_loss: 1.9728 - val_accuracy: 0.3750\n",
      "Epoch 390/500\n",
      "577/577 [==============================] - 0s 392us/sample - loss: 1.0397 - accuracy: 0.5910 - val_loss: 2.2009 - val_accuracy: 0.3250\n",
      "Epoch 391/500\n",
      "577/577 [==============================] - 0s 295us/sample - loss: 1.0037 - accuracy: 0.6118 - val_loss: 1.9881 - val_accuracy: 0.3625\n",
      "Epoch 392/500\n",
      "577/577 [==============================] - 0s 309us/sample - loss: 1.0214 - accuracy: 0.5893 - val_loss: 2.7838 - val_accuracy: 0.2500\n",
      "Epoch 393/500\n",
      "577/577 [==============================] - 0s 359us/sample - loss: 0.9984 - accuracy: 0.6049 - val_loss: 3.0328 - val_accuracy: 0.3625\n",
      "Epoch 394/500\n",
      "577/577 [==============================] - 0s 569us/sample - loss: 0.9997 - accuracy: 0.5945 - val_loss: 2.0857 - val_accuracy: 0.3875\n",
      "Epoch 395/500\n",
      "577/577 [==============================] - 0s 344us/sample - loss: 1.0280 - accuracy: 0.6014 - val_loss: 1.7753 - val_accuracy: 0.4375\n",
      "Epoch 396/500\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 0.9612 - accuracy: 0.6187 - val_loss: 2.1484 - val_accuracy: 0.3000\n",
      "Epoch 397/500\n",
      "577/577 [==============================] - 0s 508us/sample - loss: 1.0120 - accuracy: 0.6135 - val_loss: 2.1176 - val_accuracy: 0.2750\n",
      "Epoch 398/500\n",
      "577/577 [==============================] - 0s 351us/sample - loss: 0.9997 - accuracy: 0.5997 - val_loss: 2.1729 - val_accuracy: 0.3750\n",
      "Epoch 399/500\n",
      "577/577 [==============================] - 0s 344us/sample - loss: 0.9472 - accuracy: 0.6239 - val_loss: 1.6833 - val_accuracy: 0.3875\n",
      "Epoch 400/500\n",
      "577/577 [==============================] - 0s 323us/sample - loss: 0.9800 - accuracy: 0.6083 - val_loss: 1.7812 - val_accuracy: 0.4000\n",
      "Epoch 401/500\n",
      "577/577 [==============================] - 0s 392us/sample - loss: 1.0437 - accuracy: 0.5893 - val_loss: 3.3758 - val_accuracy: 0.3250\n",
      "Epoch 402/500\n",
      "577/577 [==============================] - 0s 486us/sample - loss: 0.9806 - accuracy: 0.6239 - val_loss: 1.9899 - val_accuracy: 0.3500\n",
      "Epoch 403/500\n",
      "577/577 [==============================] - 0s 343us/sample - loss: 0.9195 - accuracy: 0.6568 - val_loss: 1.8115 - val_accuracy: 0.3750\n",
      "Epoch 404/500\n",
      "577/577 [==============================] - 0s 286us/sample - loss: 0.9588 - accuracy: 0.6274 - val_loss: 1.6095 - val_accuracy: 0.4250\n",
      "Epoch 405/500\n",
      "577/577 [==============================] - 0s 344us/sample - loss: 0.9800 - accuracy: 0.6274 - val_loss: 2.4993 - val_accuracy: 0.3125\n",
      "Epoch 406/500\n",
      "577/577 [==============================] - 0s 400us/sample - loss: 1.0492 - accuracy: 0.5893 - val_loss: 2.0699 - val_accuracy: 0.3250\n",
      "Epoch 407/500\n",
      "577/577 [==============================] - 0s 329us/sample - loss: 0.9615 - accuracy: 0.6205 - val_loss: 2.6347 - val_accuracy: 0.3750\n",
      "Epoch 408/500\n",
      "577/577 [==============================] - 0s 452us/sample - loss: 0.9873 - accuracy: 0.6205 - val_loss: 2.3016 - val_accuracy: 0.3625\n",
      "Epoch 409/500\n",
      "577/577 [==============================] - 0s 333us/sample - loss: 0.9859 - accuracy: 0.5979 - val_loss: 1.9631 - val_accuracy: 0.4625\n",
      "Epoch 410/500\n",
      "577/577 [==============================] - 0s 474us/sample - loss: 1.0142 - accuracy: 0.5979 - val_loss: 1.9701 - val_accuracy: 0.4125\n",
      "Epoch 411/500\n",
      "577/577 [==============================] - 0s 433us/sample - loss: 0.9873 - accuracy: 0.6049 - val_loss: 2.0317 - val_accuracy: 0.3375\n",
      "Epoch 412/500\n",
      "577/577 [==============================] - 0s 322us/sample - loss: 1.0023 - accuracy: 0.5997 - val_loss: 2.3275 - val_accuracy: 0.3500\n",
      "Epoch 413/500\n",
      "577/577 [==============================] - 0s 319us/sample - loss: 0.9996 - accuracy: 0.5979 - val_loss: 2.4877 - val_accuracy: 0.3000\n",
      "Epoch 414/500\n",
      "577/577 [==============================] - 0s 286us/sample - loss: 0.9962 - accuracy: 0.6049 - val_loss: 1.8427 - val_accuracy: 0.3500\n",
      "Epoch 415/500\n",
      "577/577 [==============================] - 0s 322us/sample - loss: 0.9963 - accuracy: 0.6049 - val_loss: 2.0104 - val_accuracy: 0.3625\n",
      "Epoch 416/500\n",
      "577/577 [==============================] - 0s 585us/sample - loss: 0.9850 - accuracy: 0.6239 - val_loss: 2.1110 - val_accuracy: 0.3500\n",
      "Epoch 417/500\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 1.0027 - accuracy: 0.6066 - val_loss: 1.8840 - val_accuracy: 0.3625\n",
      "Epoch 418/500\n",
      "577/577 [==============================] - 0s 530us/sample - loss: 0.9635 - accuracy: 0.6343 - val_loss: 1.7315 - val_accuracy: 0.3750\n",
      "Epoch 419/500\n",
      "577/577 [==============================] - 0s 355us/sample - loss: 0.9725 - accuracy: 0.6066 - val_loss: 1.7248 - val_accuracy: 0.3875\n",
      "Epoch 420/500\n",
      "577/577 [==============================] - 0s 569us/sample - loss: 0.9884 - accuracy: 0.6153 - val_loss: 2.0256 - val_accuracy: 0.3250\n",
      "Epoch 421/500\n",
      "577/577 [==============================] - 0s 413us/sample - loss: 1.0195 - accuracy: 0.5875 - val_loss: 2.1765 - val_accuracy: 0.3625\n",
      "Epoch 422/500\n",
      "577/577 [==============================] - 0s 476us/sample - loss: 0.9984 - accuracy: 0.6395 - val_loss: 1.9059 - val_accuracy: 0.4125\n",
      "Epoch 423/500\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 0.9611 - accuracy: 0.6153 - val_loss: 2.2666 - val_accuracy: 0.2875\n",
      "Epoch 424/500\n",
      "577/577 [==============================] - 0s 507us/sample - loss: 1.0452 - accuracy: 0.5945 - val_loss: 2.8177 - val_accuracy: 0.3750\n",
      "Epoch 425/500\n",
      "577/577 [==============================] - 0s 402us/sample - loss: 0.9946 - accuracy: 0.6291 - val_loss: 1.8006 - val_accuracy: 0.3250\n",
      "Epoch 426/500\n",
      "577/577 [==============================] - 0s 498us/sample - loss: 1.0093 - accuracy: 0.6482 - val_loss: 1.6111 - val_accuracy: 0.4250\n",
      "Epoch 427/500\n",
      "577/577 [==============================] - 0s 476us/sample - loss: 0.9885 - accuracy: 0.5945 - val_loss: 2.6029 - val_accuracy: 0.3000\n",
      "Epoch 428/500\n",
      "577/577 [==============================] - 0s 379us/sample - loss: 1.0194 - accuracy: 0.5997 - val_loss: 1.8684 - val_accuracy: 0.3625\n",
      "Epoch 429/500\n",
      "577/577 [==============================] - 0s 462us/sample - loss: 0.9918 - accuracy: 0.6187 - val_loss: 1.8654 - val_accuracy: 0.3750\n",
      "Epoch 430/500\n",
      "577/577 [==============================] - 0s 493us/sample - loss: 0.9447 - accuracy: 0.6239 - val_loss: 2.1354 - val_accuracy: 0.3750\n",
      "Epoch 431/500\n",
      "577/577 [==============================] - 0s 505us/sample - loss: 1.0033 - accuracy: 0.6118 - val_loss: 2.1394 - val_accuracy: 0.3000\n",
      "Epoch 432/500\n",
      "577/577 [==============================] - 0s 546us/sample - loss: 0.9980 - accuracy: 0.6153 - val_loss: 1.9925 - val_accuracy: 0.3125\n",
      "Epoch 433/500\n",
      "577/577 [==============================] - 0s 388us/sample - loss: 0.9910 - accuracy: 0.6170 - val_loss: 2.4652 - val_accuracy: 0.3375\n",
      "Epoch 434/500\n",
      "577/577 [==============================] - 0s 459us/sample - loss: 0.9449 - accuracy: 0.6170 - val_loss: 1.8001 - val_accuracy: 0.3250\n",
      "Epoch 435/500\n",
      "577/577 [==============================] - 0s 506us/sample - loss: 0.9841 - accuracy: 0.6049 - val_loss: 2.2298 - val_accuracy: 0.3375\n",
      "Epoch 436/500\n",
      "577/577 [==============================] - 0s 407us/sample - loss: 0.9830 - accuracy: 0.5962 - val_loss: 2.3528 - val_accuracy: 0.3000\n",
      "Epoch 437/500\n",
      "577/577 [==============================] - 0s 494us/sample - loss: 1.0339 - accuracy: 0.5858 - val_loss: 1.8265 - val_accuracy: 0.3375\n",
      "Epoch 438/500\n",
      "577/577 [==============================] - 0s 541us/sample - loss: 0.9640 - accuracy: 0.6205 - val_loss: 1.9360 - val_accuracy: 0.2875\n",
      "Epoch 439/500\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 0.9987 - accuracy: 0.6135 - val_loss: 2.3072 - val_accuracy: 0.2750\n",
      "Epoch 440/500\n",
      "577/577 [==============================] - 0s 342us/sample - loss: 1.0179 - accuracy: 0.5875 - val_loss: 1.8498 - val_accuracy: 0.4250\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 327us/sample - loss: 1.0040 - accuracy: 0.5893 - val_loss: 2.1416 - val_accuracy: 0.3625\n",
      "Epoch 442/500\n",
      "577/577 [==============================] - 0s 340us/sample - loss: 0.9485 - accuracy: 0.6205 - val_loss: 1.7577 - val_accuracy: 0.4625\n",
      "Epoch 443/500\n",
      "577/577 [==============================] - 0s 354us/sample - loss: 0.9860 - accuracy: 0.6205 - val_loss: 1.9583 - val_accuracy: 0.3125\n",
      "Epoch 444/500\n",
      "577/577 [==============================] - 0s 317us/sample - loss: 0.9538 - accuracy: 0.6291 - val_loss: 2.3254 - val_accuracy: 0.3750\n",
      "Epoch 445/500\n",
      "577/577 [==============================] - 0s 330us/sample - loss: 0.9317 - accuracy: 0.6447 - val_loss: 2.9273 - val_accuracy: 0.3375\n",
      "Epoch 446/500\n",
      "577/577 [==============================] - 0s 293us/sample - loss: 0.9494 - accuracy: 0.6308 - val_loss: 2.5297 - val_accuracy: 0.2625\n",
      "Epoch 447/500\n",
      "577/577 [==============================] - 0s 309us/sample - loss: 0.9790 - accuracy: 0.6395 - val_loss: 2.4639 - val_accuracy: 0.2750\n",
      "Epoch 448/500\n",
      "577/577 [==============================] - 0s 298us/sample - loss: 0.9666 - accuracy: 0.6239 - val_loss: 2.2511 - val_accuracy: 0.2750\n",
      "Epoch 449/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 1.0037 - accuracy: 0.6187 - val_loss: 2.1238 - val_accuracy: 0.2500\n",
      "Epoch 450/500\n",
      "577/577 [==============================] - 0s 331us/sample - loss: 0.9407 - accuracy: 0.6430 - val_loss: 1.8660 - val_accuracy: 0.3750\n",
      "Epoch 451/500\n",
      "577/577 [==============================] - 0s 287us/sample - loss: 0.9017 - accuracy: 0.6360 - val_loss: 1.8556 - val_accuracy: 0.3625\n",
      "Epoch 452/500\n",
      "577/577 [==============================] - 0s 299us/sample - loss: 1.0034 - accuracy: 0.6066 - val_loss: 1.8446 - val_accuracy: 0.3750\n",
      "Epoch 453/500\n",
      "577/577 [==============================] - 0s 294us/sample - loss: 0.9348 - accuracy: 0.6308 - val_loss: 1.6866 - val_accuracy: 0.4250\n",
      "Epoch 454/500\n",
      "577/577 [==============================] - 0s 293us/sample - loss: 0.9755 - accuracy: 0.6083 - val_loss: 2.0376 - val_accuracy: 0.3875\n",
      "Epoch 455/500\n",
      "577/577 [==============================] - 0s 340us/sample - loss: 0.9503 - accuracy: 0.6326 - val_loss: 2.3213 - val_accuracy: 0.3750\n",
      "Epoch 456/500\n",
      "577/577 [==============================] - 0s 306us/sample - loss: 0.9539 - accuracy: 0.6343 - val_loss: 1.9744 - val_accuracy: 0.3750\n",
      "Epoch 457/500\n",
      "577/577 [==============================] - 0s 289us/sample - loss: 0.9893 - accuracy: 0.6135 - val_loss: 1.7893 - val_accuracy: 0.4375\n",
      "Epoch 458/500\n",
      "577/577 [==============================] - 0s 299us/sample - loss: 1.0495 - accuracy: 0.5997 - val_loss: 1.7030 - val_accuracy: 0.3000\n",
      "Epoch 459/500\n",
      "577/577 [==============================] - 0s 331us/sample - loss: 1.0044 - accuracy: 0.6101 - val_loss: 1.8089 - val_accuracy: 0.4250\n",
      "Epoch 460/500\n",
      "577/577 [==============================] - 0s 334us/sample - loss: 0.9773 - accuracy: 0.6291 - val_loss: 1.8207 - val_accuracy: 0.3125\n",
      "Epoch 461/500\n",
      "577/577 [==============================] - 0s 304us/sample - loss: 1.0096 - accuracy: 0.6031 - val_loss: 1.5983 - val_accuracy: 0.4250\n",
      "Epoch 462/500\n",
      "577/577 [==============================] - 0s 318us/sample - loss: 0.9620 - accuracy: 0.6205 - val_loss: 2.5220 - val_accuracy: 0.2250\n",
      "Epoch 463/500\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 0.9952 - accuracy: 0.6170 - val_loss: 2.5055 - val_accuracy: 0.3000\n",
      "Epoch 464/500\n",
      "577/577 [==============================] - 0s 716us/sample - loss: 0.9772 - accuracy: 0.6135 - val_loss: 2.5441 - val_accuracy: 0.3375\n",
      "Epoch 465/500\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 0.9994 - accuracy: 0.6031 - val_loss: 2.2401 - val_accuracy: 0.3500\n",
      "Epoch 466/500\n",
      "577/577 [==============================] - 0s 393us/sample - loss: 0.9474 - accuracy: 0.6412 - val_loss: 2.0439 - val_accuracy: 0.3750\n",
      "Epoch 467/500\n",
      "577/577 [==============================] - 0s 445us/sample - loss: 0.9556 - accuracy: 0.6343 - val_loss: 2.0645 - val_accuracy: 0.3250\n",
      "Epoch 468/500\n",
      "577/577 [==============================] - 0s 296us/sample - loss: 0.9739 - accuracy: 0.5875 - val_loss: 2.0939 - val_accuracy: 0.3125\n",
      "Epoch 469/500\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 0.9375 - accuracy: 0.6360 - val_loss: 1.8997 - val_accuracy: 0.3500\n",
      "Epoch 470/500\n",
      "577/577 [==============================] - 0s 322us/sample - loss: 0.9424 - accuracy: 0.6551 - val_loss: 2.3033 - val_accuracy: 0.3500\n",
      "Epoch 471/500\n",
      "577/577 [==============================] - 0s 291us/sample - loss: 0.9534 - accuracy: 0.6170 - val_loss: 3.1947 - val_accuracy: 0.2500\n",
      "Epoch 472/500\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 0.9908 - accuracy: 0.6187 - val_loss: 2.9110 - val_accuracy: 0.2125\n",
      "Epoch 473/500\n",
      "577/577 [==============================] - 0s 315us/sample - loss: 0.9927 - accuracy: 0.6170 - val_loss: 2.4065 - val_accuracy: 0.2875\n",
      "Epoch 474/500\n",
      "577/577 [==============================] - 0s 347us/sample - loss: 0.9495 - accuracy: 0.5910 - val_loss: 1.7404 - val_accuracy: 0.3625\n",
      "Epoch 475/500\n",
      "577/577 [==============================] - 0s 297us/sample - loss: 0.9735 - accuracy: 0.6205 - val_loss: 1.6976 - val_accuracy: 0.4500\n",
      "Epoch 476/500\n",
      "577/577 [==============================] - 0s 309us/sample - loss: 0.9990 - accuracy: 0.6256 - val_loss: 1.9191 - val_accuracy: 0.3750\n",
      "Epoch 477/500\n",
      "577/577 [==============================] - 0s 345us/sample - loss: 0.9532 - accuracy: 0.6256 - val_loss: 2.0421 - val_accuracy: 0.3750\n",
      "Epoch 478/500\n",
      "577/577 [==============================] - 0s 304us/sample - loss: 0.9618 - accuracy: 0.6222 - val_loss: 1.8281 - val_accuracy: 0.3625\n",
      "Epoch 479/500\n",
      "577/577 [==============================] - 0s 308us/sample - loss: 0.9433 - accuracy: 0.6343 - val_loss: 2.8359 - val_accuracy: 0.3500\n",
      "Epoch 480/500\n",
      "577/577 [==============================] - 0s 491us/sample - loss: 0.9418 - accuracy: 0.6222 - val_loss: 2.4295 - val_accuracy: 0.3375\n",
      "Epoch 481/500\n",
      "577/577 [==============================] - 0s 448us/sample - loss: 0.9394 - accuracy: 0.6291 - val_loss: 1.8733 - val_accuracy: 0.3000\n",
      "Epoch 482/500\n",
      "577/577 [==============================] - 0s 443us/sample - loss: 0.9746 - accuracy: 0.6049 - val_loss: 2.3988 - val_accuracy: 0.3250\n",
      "Epoch 483/500\n",
      "577/577 [==============================] - 0s 527us/sample - loss: 0.9021 - accuracy: 0.6395 - val_loss: 2.1576 - val_accuracy: 0.3250\n",
      "Epoch 484/500\n",
      "577/577 [==============================] - 0s 361us/sample - loss: 0.9959 - accuracy: 0.6205 - val_loss: 2.0284 - val_accuracy: 0.3750\n",
      "Epoch 485/500\n",
      "577/577 [==============================] - 0s 307us/sample - loss: 0.9161 - accuracy: 0.6274 - val_loss: 2.3274 - val_accuracy: 0.3250\n",
      "Epoch 486/500\n",
      "577/577 [==============================] - 0s 300us/sample - loss: 0.9397 - accuracy: 0.6499 - val_loss: 2.0186 - val_accuracy: 0.3750\n",
      "Epoch 487/500\n",
      "577/577 [==============================] - 0s 345us/sample - loss: 0.9339 - accuracy: 0.6395 - val_loss: 2.1191 - val_accuracy: 0.3500\n",
      "Epoch 488/500\n",
      "577/577 [==============================] - 0s 335us/sample - loss: 0.9636 - accuracy: 0.6118 - val_loss: 2.4077 - val_accuracy: 0.4125\n",
      "Epoch 489/500\n",
      "577/577 [==============================] - 0s 357us/sample - loss: 0.9656 - accuracy: 0.6568 - val_loss: 3.0465 - val_accuracy: 0.2625\n",
      "Epoch 490/500\n",
      "577/577 [==============================] - 0s 315us/sample - loss: 0.9913 - accuracy: 0.5962 - val_loss: 2.3032 - val_accuracy: 0.3375\n",
      "Epoch 491/500\n",
      "577/577 [==============================] - 0s 299us/sample - loss: 0.9666 - accuracy: 0.6308 - val_loss: 3.1301 - val_accuracy: 0.3625\n",
      "Epoch 492/500\n",
      "577/577 [==============================] - 0s 308us/sample - loss: 0.9185 - accuracy: 0.6239 - val_loss: 2.2566 - val_accuracy: 0.3625\n",
      "Epoch 493/500\n",
      "577/577 [==============================] - 0s 333us/sample - loss: 1.0337 - accuracy: 0.5962 - val_loss: 1.9128 - val_accuracy: 0.3500\n",
      "Epoch 494/500\n",
      "577/577 [==============================] - 0s 367us/sample - loss: 0.9662 - accuracy: 0.6395 - val_loss: 1.9102 - val_accuracy: 0.3500\n",
      "Epoch 495/500\n",
      "577/577 [==============================] - 0s 313us/sample - loss: 1.0173 - accuracy: 0.6205 - val_loss: 2.5475 - val_accuracy: 0.3125\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 300us/sample - loss: 0.9476 - accuracy: 0.6360 - val_loss: 2.1466 - val_accuracy: 0.3250\n",
      "Epoch 497/500\n",
      "577/577 [==============================] - 0s 302us/sample - loss: 1.0235 - accuracy: 0.5979 - val_loss: 2.3225 - val_accuracy: 0.3125\n",
      "Epoch 498/500\n",
      "577/577 [==============================] - 0s 321us/sample - loss: 0.9465 - accuracy: 0.6256 - val_loss: 2.5792 - val_accuracy: 0.3000\n",
      "Epoch 499/500\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 0.9256 - accuracy: 0.6430 - val_loss: 2.5938 - val_accuracy: 0.3500\n",
      "Epoch 500/500\n",
      "577/577 [==============================] - 0s 490us/sample - loss: 0.9890 - accuracy: 0.6205 - val_loss: 2.9113 - val_accuracy: 0.3625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9fa00fa850>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(XDB,YDB,batch_size=16,epochs=200,validation_data=(XTB,YTB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.325"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(XTB).argmax(axis=1)==YTB.argmax(axis=1)).sum()/len(XTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 3, 5, 3, 0, 0, 3, 3, 3, 3, 1, 5, 5, 3, 3, 3, 0, 3, 3, 0, 5,\n",
       "       3, 1, 3, 3, 5, 5, 3, 5, 0, 0, 0, 5, 5, 3, 5, 3, 5, 3, 0, 5, 3, 3,\n",
       "       0, 0, 3, 0, 3, 5, 5, 3, 0, 3, 3, 0, 0, 1, 5, 3, 0, 0, 3, 3, 5, 3,\n",
       "       3, 3, 0, 5, 3, 0, 5, 3, 0, 3, 5, 3, 5, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTB).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 3, 0, 3, 0, 1, 2, 1, 3, 4, 0, 0, 5, 3, 4, 4, 3, 1, 0, 1, 5,\n",
       "       3, 0, 5, 1, 0, 2, 3, 2, 1, 4, 4, 5, 5, 0, 5, 3, 5, 1, 4, 2, 3, 0,\n",
       "       0, 0, 4, 1, 1, 0, 1, 4, 1, 5, 3, 3, 1, 0, 0, 3, 0, 4, 3, 5, 0, 3,\n",
       "       1, 4, 4, 0, 5, 1, 2, 2, 0, 4, 5, 3, 0, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTB.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
