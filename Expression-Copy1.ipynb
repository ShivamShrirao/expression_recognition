{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../face_recognition/haarcascade_frontalface_default.xml')\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=\"../facial_expressions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(IMG_PATH+\"icml_face_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(to_replace=\"PrivateTest\",value=\"Testing\")\n",
    "df=df.replace(to_replace=\"PublicTest\",value=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>Testing</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>Testing</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion     Usage                                             pixels\n",
       "0            0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1            0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2            2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3            4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4            6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
       "...        ...       ...                                                ...\n",
       "35882        6   Testing  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
       "35883        3   Testing  178 174 172 173 181 188 191 194 196 199 200 20...\n",
       "35884        0   Testing  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
       "35885        3   Testing  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
       "35886        2   Testing  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
       "\n",
       "[35887 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"Training\":[],\"Testing\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35887  4965      32797  "
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    print(\"\\r\",i+1,end=\" \")\n",
    "    row=df.iloc[i]\n",
    "    img=np.array(list(map(np.uint8,row[2].split()))).reshape(48,48)\n",
    "    data[row[1]].append([row[0],ret_keypoints(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_keypoints(image):\n",
    "    gray=image\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (face_dim, face_dim))\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    param=[0,0,face_dim,face_dim]\n",
    "    shape=predictor(gray,dlib.rectangle(*param))\n",
    "    xlist=[]\n",
    "    ylist=[]\n",
    "    for i in range(68):\n",
    "        xlist.append(np.float32(shape.part(i).x))\n",
    "        ylist.append(np.float32(shape.part(i).y))\n",
    "    xmean = np.mean(xlist)\n",
    "    ymean = np.mean(ylist)\n",
    "#     plt.imshow(gray,cmap='gray')\n",
    "#     plt.scatter(xlist,ylist, marker='.')\n",
    "#     plt.show()\n",
    "    xcentral = [(x-xmean) for x in xlist]\n",
    "    ycentral = [(y-ymean) for y in ylist]\n",
    "    res=[]\n",
    "    for (x,y) in zip(xcentral,ycentral):\n",
    "        res.append(x)\n",
    "        res.append(y)\n",
    "    return (np.asarray(res)/face_dim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=np.arange(len(XXD))\n",
    "# for i in range(5):\n",
    "#     np.random.shuffle(s)\n",
    "#     XXD=XXD[s]\n",
    "#     YYD=YYD[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,activation='relu', input_shape=(68*2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(emotions),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 1024)              140288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 837,895\n",
      "Trainable params: 834,055\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "XDB=np.vstack(np.asarray(data[\"Training\"])[:,1])\n",
    "YDY=np.asarray(data[\"Training\"])[:,0]\n",
    "YDB=np.zeros((len(YDY),len(emotions)))\n",
    "for i in range(len(YDB)):\n",
    "    YDB[i][YDY[i]]=1\n",
    "XTB=np.vstack(np.asarray(data[\"Testing\"])[:,1])\n",
    "YTY=np.asarray(data[\"Testing\"])[:,0]\n",
    "YTB=np.zeros((len(YTY),len(emotions)))\n",
    "for i in range(len(YTB)):\n",
    "    YTB[i][YTY[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32298 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "32298/32298 [==============================] - 8s 250us/sample - loss: 1.7771 - accuracy: 0.3559 - val_loss: 1.5882 - val_accuracy: 0.3834\n",
      "Epoch 2/100\n",
      "32298/32298 [==============================] - 7s 219us/sample - loss: 1.5203 - accuracy: 0.4204 - val_loss: 1.5737 - val_accuracy: 0.4009\n",
      "Epoch 3/100\n",
      "32298/32298 [==============================] - 7s 232us/sample - loss: 1.4671 - accuracy: 0.4366 - val_loss: 1.4173 - val_accuracy: 0.4620\n",
      "Epoch 4/100\n",
      "32298/32298 [==============================] - 7s 214us/sample - loss: 1.4435 - accuracy: 0.4443 - val_loss: 1.7628 - val_accuracy: 0.2672\n",
      "Epoch 5/100\n",
      "32298/32298 [==============================] - 7s 223us/sample - loss: 1.4316 - accuracy: 0.4524 - val_loss: 1.6560 - val_accuracy: 0.3527\n",
      "Epoch 6/100\n",
      "32298/32298 [==============================] - 7s 210us/sample - loss: 1.4184 - accuracy: 0.4596 - val_loss: 1.7413 - val_accuracy: 0.3062\n",
      "Epoch 7/100\n",
      "32298/32298 [==============================] - 7s 219us/sample - loss: 1.4090 - accuracy: 0.4590 - val_loss: 2.1238 - val_accuracy: 0.2335\n",
      "Epoch 8/100\n",
      "32298/32298 [==============================] - 7s 217us/sample - loss: 1.3982 - accuracy: 0.4642 - val_loss: 1.5915 - val_accuracy: 0.3739\n",
      "Epoch 9/100\n",
      "32298/32298 [==============================] - 7s 232us/sample - loss: 1.3932 - accuracy: 0.4614 - val_loss: 1.5928 - val_accuracy: 0.4076\n",
      "Epoch 10/100\n",
      "32298/32298 [==============================] - 7s 221us/sample - loss: 1.3840 - accuracy: 0.4672 - val_loss: 1.6604 - val_accuracy: 0.3422\n",
      "Epoch 11/100\n",
      "32298/32298 [==============================] - 7s 214us/sample - loss: 1.3819 - accuracy: 0.4700 - val_loss: 1.6656 - val_accuracy: 0.3670\n",
      "Epoch 12/100\n",
      "32298/32298 [==============================] - 7s 214us/sample - loss: 1.3785 - accuracy: 0.4670 - val_loss: 1.5133 - val_accuracy: 0.4288\n",
      "Epoch 13/100\n",
      "32298/32298 [==============================] - 7s 213us/sample - loss: 1.3721 - accuracy: 0.4685 - val_loss: 1.4967 - val_accuracy: 0.4032\n",
      "Epoch 14/100\n",
      "32298/32298 [==============================] - 7s 216us/sample - loss: 1.3662 - accuracy: 0.4735 - val_loss: 1.6382 - val_accuracy: 0.3483\n",
      "Epoch 15/100\n",
      "32298/32298 [==============================] - 7s 214us/sample - loss: 1.3634 - accuracy: 0.4776 - val_loss: 1.4362 - val_accuracy: 0.4280\n",
      "Epoch 16/100\n",
      "32298/32298 [==============================] - 8s 257us/sample - loss: 1.3630 - accuracy: 0.4741 - val_loss: 1.5666 - val_accuracy: 0.3884\n",
      "Epoch 17/100\n",
      "32298/32298 [==============================] - 8s 260us/sample - loss: 1.3544 - accuracy: 0.4768 - val_loss: 1.4419 - val_accuracy: 0.4400\n",
      "Epoch 18/100\n",
      "32298/32298 [==============================] - 7s 232us/sample - loss: 1.3493 - accuracy: 0.4791 - val_loss: 1.4841 - val_accuracy: 0.4188\n",
      "Epoch 19/100\n",
      "32298/32298 [==============================] - 8s 254us/sample - loss: 1.3457 - accuracy: 0.4826 - val_loss: 2.0637 - val_accuracy: 0.2951\n",
      "Epoch 20/100\n",
      "32298/32298 [==============================] - 10s 295us/sample - loss: 1.3471 - accuracy: 0.4830 - val_loss: 1.4996 - val_accuracy: 0.3929\n",
      "Epoch 21/100\n",
      "32298/32298 [==============================] - 7s 231us/sample - loss: 1.3441 - accuracy: 0.4804 - val_loss: 1.5155 - val_accuracy: 0.3764\n",
      "Epoch 22/100\n",
      "32298/32298 [==============================] - 6s 192us/sample - loss: 1.3426 - accuracy: 0.4828 - val_loss: 1.6647 - val_accuracy: 0.3098\n",
      "Epoch 23/100\n",
      "32298/32298 [==============================] - 6s 179us/sample - loss: 1.3393 - accuracy: 0.4816 - val_loss: 1.5756 - val_accuracy: 0.4099\n",
      "Epoch 24/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.3347 - accuracy: 0.4859 - val_loss: 1.4697 - val_accuracy: 0.3973\n",
      "Epoch 25/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.3325 - accuracy: 0.4882 - val_loss: 1.3548 - val_accuracy: 0.4600\n",
      "Epoch 26/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.3322 - accuracy: 0.4884 - val_loss: 1.3951 - val_accuracy: 0.4505\n",
      "Epoch 27/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.3277 - accuracy: 0.4882 - val_loss: 1.4048 - val_accuracy: 0.4567\n",
      "Epoch 28/100\n",
      "32298/32298 [==============================] - 6s 180us/sample - loss: 1.3256 - accuracy: 0.4885 - val_loss: 1.4140 - val_accuracy: 0.4447\n",
      "Epoch 29/100\n",
      "32298/32298 [==============================] - 7s 212us/sample - loss: 1.3263 - accuracy: 0.4888 - val_loss: 1.8684 - val_accuracy: 0.2577\n",
      "Epoch 30/100\n",
      "32298/32298 [==============================] - 6s 197us/sample - loss: 1.3239 - accuracy: 0.4890 - val_loss: 1.5736 - val_accuracy: 0.3851\n",
      "Epoch 31/100\n",
      "32298/32298 [==============================] - 6s 188us/sample - loss: 1.3211 - accuracy: 0.4915 - val_loss: 1.3797 - val_accuracy: 0.4756\n",
      "Epoch 32/100\n",
      "32298/32298 [==============================] - 6s 182us/sample - loss: 1.3209 - accuracy: 0.4893 - val_loss: 1.5314 - val_accuracy: 0.3931\n",
      "Epoch 33/100\n",
      "32298/32298 [==============================] - 6s 181us/sample - loss: 1.3148 - accuracy: 0.4924 - val_loss: 1.5784 - val_accuracy: 0.3945\n",
      "Epoch 34/100\n",
      "32298/32298 [==============================] - 7s 232us/sample - loss: 1.3175 - accuracy: 0.4929 - val_loss: 1.4571 - val_accuracy: 0.4224\n",
      "Epoch 35/100\n",
      "32298/32298 [==============================] - 6s 185us/sample - loss: 1.3149 - accuracy: 0.4934 - val_loss: 1.4342 - val_accuracy: 0.4416\n",
      "Epoch 36/100\n",
      "32298/32298 [==============================] - 6s 186us/sample - loss: 1.3114 - accuracy: 0.4921 - val_loss: 1.5925 - val_accuracy: 0.3943\n",
      "Epoch 37/100\n",
      "32298/32298 [==============================] - 7s 212us/sample - loss: 1.3121 - accuracy: 0.4910 - val_loss: 1.5261 - val_accuracy: 0.4082\n",
      "Epoch 38/100\n",
      "32298/32298 [==============================] - 6s 193us/sample - loss: 1.3130 - accuracy: 0.4947 - val_loss: 1.4580 - val_accuracy: 0.4452\n",
      "Epoch 39/100\n",
      "32298/32298 [==============================] - 6s 186us/sample - loss: 1.3086 - accuracy: 0.4962 - val_loss: 1.3151 - val_accuracy: 0.4809\n",
      "Epoch 40/100\n",
      "32298/32298 [==============================] - 7s 208us/sample - loss: 1.3117 - accuracy: 0.4953 - val_loss: 1.6198 - val_accuracy: 0.3809\n",
      "Epoch 41/100\n",
      "32298/32298 [==============================] - 6s 196us/sample - loss: 1.3028 - accuracy: 0.4950 - val_loss: 1.3710 - val_accuracy: 0.4670\n",
      "Epoch 42/100\n",
      "32298/32298 [==============================] - 6s 187us/sample - loss: 1.3007 - accuracy: 0.4961 - val_loss: 1.4608 - val_accuracy: 0.4179\n",
      "Epoch 43/100\n",
      "32298/32298 [==============================] - 6s 181us/sample - loss: 1.3035 - accuracy: 0.4985 - val_loss: 1.3479 - val_accuracy: 0.4561\n",
      "Epoch 44/100\n",
      "32298/32298 [==============================] - 6s 189us/sample - loss: 1.3026 - accuracy: 0.4985 - val_loss: 1.4038 - val_accuracy: 0.4692\n",
      "Epoch 45/100\n",
      "32298/32298 [==============================] - 8s 235us/sample - loss: 1.2982 - accuracy: 0.4967 - val_loss: 1.3129 - val_accuracy: 0.4870\n",
      "Epoch 46/100\n",
      "32298/32298 [==============================] - 7s 212us/sample - loss: 1.2990 - accuracy: 0.4989 - val_loss: 1.5070 - val_accuracy: 0.4163\n",
      "Epoch 47/100\n",
      "32298/32298 [==============================] - 6s 189us/sample - loss: 1.2932 - accuracy: 0.5006 - val_loss: 1.3631 - val_accuracy: 0.4700\n",
      "Epoch 48/100\n",
      "32298/32298 [==============================] - 6s 192us/sample - loss: 1.2989 - accuracy: 0.4992 - val_loss: 1.4361 - val_accuracy: 0.4595\n",
      "Epoch 49/100\n",
      "32298/32298 [==============================] - 6s 177us/sample - loss: 1.2959 - accuracy: 0.4991 - val_loss: 1.3258 - val_accuracy: 0.4737\n",
      "Epoch 50/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.2928 - accuracy: 0.5035 - val_loss: 1.4349 - val_accuracy: 0.4361\n",
      "Epoch 51/100\n",
      "32298/32298 [==============================] - 6s 177us/sample - loss: 1.2909 - accuracy: 0.5032 - val_loss: 1.4270 - val_accuracy: 0.4480\n",
      "Epoch 52/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.2917 - accuracy: 0.5032 - val_loss: 1.3578 - val_accuracy: 0.4728\n",
      "Epoch 53/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.2904 - accuracy: 0.5008 - val_loss: 1.4229 - val_accuracy: 0.4413\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32298/32298 [==============================] - 6s 177us/sample - loss: 1.2886 - accuracy: 0.4997 - val_loss: 1.3976 - val_accuracy: 0.4634\n",
      "Epoch 55/100\n",
      "32298/32298 [==============================] - 6s 178us/sample - loss: 1.2894 - accuracy: 0.5021 - val_loss: 1.5204 - val_accuracy: 0.4026\n",
      "Epoch 56/100\n",
      "32298/32298 [==============================] - 6s 188us/sample - loss: 1.2881 - accuracy: 0.5018 - val_loss: 1.7603 - val_accuracy: 0.3647\n",
      "Epoch 57/100\n",
      "32298/32298 [==============================] - 6s 192us/sample - loss: 1.2851 - accuracy: 0.5023 - val_loss: 1.3823 - val_accuracy: 0.4458\n",
      "Epoch 58/100\n",
      "32298/32298 [==============================] - 6s 190us/sample - loss: 1.2860 - accuracy: 0.4998 - val_loss: 1.4314 - val_accuracy: 0.4670\n",
      "Epoch 59/100\n",
      "32298/32298 [==============================] - 7s 217us/sample - loss: 1.2872 - accuracy: 0.4999 - val_loss: 1.3224 - val_accuracy: 0.4845\n",
      "Epoch 60/100\n",
      "32298/32298 [==============================] - 9s 277us/sample - loss: 1.2794 - accuracy: 0.5063 - val_loss: 1.3913 - val_accuracy: 0.4531\n",
      "Epoch 61/100\n",
      "32298/32298 [==============================] - 8s 260us/sample - loss: 1.2810 - accuracy: 0.5043 - val_loss: 1.3133 - val_accuracy: 0.4857\n",
      "Epoch 62/100\n",
      "32298/32298 [==============================] - 6s 198us/sample - loss: 1.2825 - accuracy: 0.5032 - val_loss: 1.4492 - val_accuracy: 0.4600\n",
      "Epoch 63/100\n",
      "32298/32298 [==============================] - 6s 198us/sample - loss: 1.2786 - accuracy: 0.5046 - val_loss: 1.4925 - val_accuracy: 0.4503\n",
      "Epoch 64/100\n",
      "32298/32298 [==============================] - 7s 209us/sample - loss: 1.2791 - accuracy: 0.5061 - val_loss: 1.3265 - val_accuracy: 0.4868\n",
      "Epoch 65/100\n",
      "32298/32298 [==============================] - 7s 202us/sample - loss: 1.2771 - accuracy: 0.5078 - val_loss: 1.4776 - val_accuracy: 0.4018\n",
      "Epoch 66/100\n",
      "32298/32298 [==============================] - 7s 218us/sample - loss: 1.2757 - accuracy: 0.5071 - val_loss: 1.3341 - val_accuracy: 0.4798\n",
      "Epoch 67/100\n",
      "32298/32298 [==============================] - 7s 215us/sample - loss: 1.2769 - accuracy: 0.5039 - val_loss: 1.6217 - val_accuracy: 0.3806\n",
      "Epoch 68/100\n",
      "32298/32298 [==============================] - 7s 228us/sample - loss: 1.2790 - accuracy: 0.5059 - val_loss: 1.4782 - val_accuracy: 0.4205\n",
      "Epoch 69/100\n",
      "32298/32298 [==============================] - 7s 224us/sample - loss: 1.2750 - accuracy: 0.5072 - val_loss: 1.4534 - val_accuracy: 0.4271\n",
      "Epoch 70/100\n",
      "32298/32298 [==============================] - 7s 214us/sample - loss: 1.2738 - accuracy: 0.5080 - val_loss: 1.3550 - val_accuracy: 0.4720\n",
      "Epoch 71/100\n",
      "32298/32298 [==============================] - 7s 219us/sample - loss: 1.2718 - accuracy: 0.5068 - val_loss: 1.4145 - val_accuracy: 0.4397\n",
      "Epoch 72/100\n",
      "32298/32298 [==============================] - 7s 211us/sample - loss: 1.2711 - accuracy: 0.5099 - val_loss: 1.3705 - val_accuracy: 0.4597\n",
      "Epoch 73/100\n",
      "32298/32298 [==============================] - 7s 225us/sample - loss: 1.2711 - accuracy: 0.5083 - val_loss: 1.3353 - val_accuracy: 0.4745\n",
      "Epoch 74/100\n",
      "32298/32298 [==============================] - 7s 225us/sample - loss: 1.2690 - accuracy: 0.5088 - val_loss: 1.3526 - val_accuracy: 0.4745\n",
      "Epoch 75/100\n",
      "32298/32298 [==============================] - 7s 225us/sample - loss: 1.2691 - accuracy: 0.5103 - val_loss: 1.4976 - val_accuracy: 0.4274\n",
      "Epoch 76/100\n",
      "32298/32298 [==============================] - 7s 223us/sample - loss: 1.2689 - accuracy: 0.5115 - val_loss: 1.4995 - val_accuracy: 0.4179\n",
      "Epoch 77/100\n",
      "32298/32298 [==============================] - 7s 225us/sample - loss: 1.2685 - accuracy: 0.5096 - val_loss: 1.3821 - val_accuracy: 0.4611\n",
      "Epoch 78/100\n",
      "32298/32298 [==============================] - 8s 235us/sample - loss: 1.2646 - accuracy: 0.5118 - val_loss: 1.4331 - val_accuracy: 0.4271\n",
      "Epoch 79/100\n",
      "32298/32298 [==============================] - 8s 242us/sample - loss: 1.2671 - accuracy: 0.5124 - val_loss: 1.4052 - val_accuracy: 0.4648\n",
      "Epoch 80/100\n",
      "32298/32298 [==============================] - 8s 232us/sample - loss: 1.2678 - accuracy: 0.5102 - val_loss: 1.3843 - val_accuracy: 0.4653\n",
      "Epoch 81/100\n",
      "32298/32298 [==============================] - 7s 232us/sample - loss: 1.2587 - accuracy: 0.5138 - val_loss: 1.4353 - val_accuracy: 0.4553\n",
      "Epoch 82/100\n",
      "32298/32298 [==============================] - 7s 227us/sample - loss: 1.2619 - accuracy: 0.5119 - val_loss: 1.4562 - val_accuracy: 0.4361\n",
      "Epoch 83/100\n",
      "32298/32298 [==============================] - 8s 233us/sample - loss: 1.2603 - accuracy: 0.5125 - val_loss: 1.3778 - val_accuracy: 0.4458\n",
      "Epoch 84/100\n",
      "32298/32298 [==============================] - 8s 235us/sample - loss: 1.2603 - accuracy: 0.5137 - val_loss: 1.3925 - val_accuracy: 0.4606\n",
      "Epoch 85/100\n",
      "32298/32298 [==============================] - 8s 247us/sample - loss: 1.2630 - accuracy: 0.5095 - val_loss: 1.5023 - val_accuracy: 0.4046\n",
      "Epoch 86/100\n",
      "32298/32298 [==============================] - 8s 237us/sample - loss: 1.2600 - accuracy: 0.5140 - val_loss: 1.4717 - val_accuracy: 0.4232\n",
      "Epoch 87/100\n",
      "32298/32298 [==============================] - 8s 241us/sample - loss: 1.2653 - accuracy: 0.5106 - val_loss: 1.3294 - val_accuracy: 0.4870\n",
      "Epoch 88/100\n",
      "32298/32298 [==============================] - 8s 249us/sample - loss: 1.2568 - accuracy: 0.5153 - val_loss: 1.4128 - val_accuracy: 0.4422\n",
      "Epoch 89/100\n",
      "32298/32298 [==============================] - 7s 230us/sample - loss: 1.2586 - accuracy: 0.5121 - val_loss: 1.4302 - val_accuracy: 0.4603\n",
      "Epoch 90/100\n",
      "32298/32298 [==============================] - 7s 222us/sample - loss: 1.2609 - accuracy: 0.5126 - val_loss: 1.3927 - val_accuracy: 0.4664\n",
      "Epoch 91/100\n",
      "32298/32298 [==============================] - 7s 224us/sample - loss: 1.2593 - accuracy: 0.5148 - val_loss: 1.3707 - val_accuracy: 0.4645\n",
      "Epoch 92/100\n",
      "32298/32298 [==============================] - 8s 233us/sample - loss: 1.2565 - accuracy: 0.5149 - val_loss: 1.4937 - val_accuracy: 0.4171\n",
      "Epoch 93/100\n",
      "32298/32298 [==============================] - 8s 244us/sample - loss: 1.2581 - accuracy: 0.5129 - val_loss: 1.3971 - val_accuracy: 0.4603\n",
      "Epoch 94/100\n",
      "32298/32298 [==============================] - 8s 245us/sample - loss: 1.2551 - accuracy: 0.5154 - val_loss: 1.3452 - val_accuracy: 0.4809\n",
      "Epoch 95/100\n",
      "32298/32298 [==============================] - 8s 235us/sample - loss: 1.2545 - accuracy: 0.5114 - val_loss: 1.3700 - val_accuracy: 0.4609\n",
      "Epoch 96/100\n",
      "32298/32298 [==============================] - 8s 245us/sample - loss: 1.2575 - accuracy: 0.5154 - val_loss: 1.4671 - val_accuracy: 0.4327\n",
      "Epoch 97/100\n",
      "32298/32298 [==============================] - 7s 227us/sample - loss: 1.2536 - accuracy: 0.5154 - val_loss: 1.3381 - val_accuracy: 0.4834\n",
      "Epoch 98/100\n",
      "32298/32298 [==============================] - 7s 222us/sample - loss: 1.2549 - accuracy: 0.5134 - val_loss: 1.4366 - val_accuracy: 0.4283\n",
      "Epoch 99/100\n",
      "32298/32298 [==============================] - 7s 222us/sample - loss: 1.2557 - accuracy: 0.5149 - val_loss: 1.4126 - val_accuracy: 0.4581\n",
      "Epoch 100/100\n",
      "32298/32298 [==============================] - 8s 244us/sample - loss: 1.2541 - accuracy: 0.5118 - val_loss: 1.3902 - val_accuracy: 0.4609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc440d430a0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(XDB,YDB,batch_size=64,epochs=100,validation_data=(XTB,YTB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4608526051825021"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(XTB).argmax(axis=1)==YTB.argmax(axis=1)).sum()/len(XTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTB).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 6, ..., 0, 3, 2])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTB.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from udp_streamer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = udp_handler()\n",
    "handler.make_listener('0.0.0.0',5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    global handler,img\n",
    "    buffer = handler.get_data()\n",
    "    if buffer is not None:\n",
    "        try:\n",
    "            npimg = np.frombuffer(buffer, dtype=np.uint8)\n",
    "            img = cv2.imdecode(npimg, 1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "#     ret, img = cam.read()\n",
    "    img=get_img()\n",
    "    gimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gimg, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        landmarks=[]\n",
    "        svx,svy=x,y\n",
    "        gray=gimg[y:y+h,x:x+w]\n",
    "        try:\n",
    "            gray=cv2.resize(gray, (face_dim, face_dim))\n",
    "        except:\n",
    "            print(gray,x,y,w,h)\n",
    "            continue\n",
    "        shape=predictor(gray,dlib.rectangle(0,0,face_dim,face_dim))\n",
    "        xlist=[]\n",
    "        ylist=[]\n",
    "        for i in range(68):\n",
    "            xp=shape.part(i).x\n",
    "            yp=shape.part(i).y\n",
    "            cv2.circle(gray, (xp, yp), 2, (255, 255, 255), -1)\n",
    "            xlist.append(float(xp))\n",
    "            ylist.append(float(yp))\n",
    "        cv2.imshow('gray',gray)\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        res=[]\n",
    "        for (x,y) in zip(xcentral,ycentral):\n",
    "            res.append(x)\n",
    "            res.append(y)\n",
    "        landmarks.append((np.asarray(res)/face_dim+1)/2)\n",
    "        if len(landmarks)>0:\n",
    "            y_out=model.predict(np.asarray(landmarks))\n",
    "            res=np.argmax(y_out,axis=1)\n",
    "            for r in res:\n",
    "                cv2.putText(img,emotions[r],(svx,svy),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
