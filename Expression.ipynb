{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../face_recognition/haarcascade_frontalface_default.xml')\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=\"../facial_expressions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_keypoints(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (face_dim, face_dim))\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces)==0:\n",
    "        param=[0,0,face_dim,face_dim]\n",
    "    else:\n",
    "        (x,y,w,h)=faces[0]\n",
    "        param=[x,y,x+w,y+h]\n",
    "    shape=predictor(gray,dlib.rectangle(*param))\n",
    "    xlist=[]\n",
    "    ylist=[]\n",
    "    for i in range(68):\n",
    "        xlist.append(np.float32(shape.part(i).x))\n",
    "        ylist.append(np.float32(shape.part(i).y))\n",
    "    xmean = np.mean(xlist)\n",
    "    ymean = np.mean(ylist)\n",
    "#     plt.imshow(gray,cmap='gray')\n",
    "#     plt.scatter(xlist,ylist, marker='.')\n",
    "#     plt.show()\n",
    "    xcentral = [(x-xmean) for x in xlist]\n",
    "    ycentral = [(y-ymean) for y in ylist]\n",
    "    res=[]\n",
    "    for (x,y) in zip(xcentral,ycentral):\n",
    "        res.append(x)\n",
    "        res.append(y)\n",
    "    return (np.asarray(res)/face_dim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_keypoints():\n",
    "    X_inp=[]\n",
    "    y_inp=[]\n",
    "    for em in emotions:\n",
    "        ltt=os.listdir(IMG_PATH+em)\n",
    "        lnltt=len(ltt)\n",
    "        for idx,imn in enumerate(ltt):\n",
    "            print(\"\\r\",idx+1,'/',lnltt,end=\" \")\n",
    "            image = cv2.imread(IMG_PATH+em+\"/\"+imn)\n",
    "            landmarks=ret_keypoints(image)\n",
    "            if landmarks is not None:\n",
    "                X_inp.append(landmarks)\n",
    "                yy=np.zeros(len(emotions))\n",
    "                yy[emotions.index(em)]=1\n",
    "                y_inp.append(yy)\n",
    "        print()\n",
    "    return np.asarray(X_inp),np.asarray(y_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 124 / 124 \n",
      " 84 / 84 \n",
      " 67 / 67 \n",
      " 127 / 127 \n",
      " 132 / 132 \n",
      "\n",
      " 123 / 123 \n"
     ]
    }
   ],
   "source": [
    "XXD,YYD=prep_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(len(XXD))\n",
    "for i in range(5):\n",
    "    np.random.shuffle(s)\n",
    "    XXD=XXD[s]\n",
    "    YYD=YYD[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"extra_data.pkl\",\"wb\") as f:\n",
    "    pickle.dump((XXD,YYD), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,activation='relu', input_shape=(68*2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(emotions),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              140288    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 837,766\n",
      "Trainable params: 833,926\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut=80\n",
    "XDB=XXD[cut:]\n",
    "YDB=YYD[cut:]\n",
    "\n",
    "XTB=XXD[:cut]\n",
    "YTB=YYD[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 577 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "577/577 [==============================] - 0s 349us/sample - loss: 0.6789 - accuracy: 0.7331 - val_loss: 4.2401 - val_accuracy: 0.2125\n",
      "Epoch 2/100\n",
      "577/577 [==============================] - 0s 368us/sample - loss: 0.6672 - accuracy: 0.7348 - val_loss: 3.2057 - val_accuracy: 0.3125\n",
      "Epoch 3/100\n",
      "577/577 [==============================] - 0s 379us/sample - loss: 0.6158 - accuracy: 0.7331 - val_loss: 4.0774 - val_accuracy: 0.3375\n",
      "Epoch 4/100\n",
      "577/577 [==============================] - 0s 427us/sample - loss: 0.6851 - accuracy: 0.7383 - val_loss: 1.2222 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "577/577 [==============================] - 0s 426us/sample - loss: 0.6544 - accuracy: 0.7591 - val_loss: 1.3314 - val_accuracy: 0.5250\n",
      "Epoch 6/100\n",
      "577/577 [==============================] - 0s 521us/sample - loss: 0.5997 - accuracy: 0.7730 - val_loss: 1.6246 - val_accuracy: 0.5625\n",
      "Epoch 7/100\n",
      "577/577 [==============================] - 0s 393us/sample - loss: 0.6466 - accuracy: 0.7418 - val_loss: 2.0303 - val_accuracy: 0.3750\n",
      "Epoch 8/100\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 0.6169 - accuracy: 0.7695 - val_loss: 2.2021 - val_accuracy: 0.4125\n",
      "Epoch 9/100\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 0.6377 - accuracy: 0.7487 - val_loss: 1.9790 - val_accuracy: 0.4125\n",
      "Epoch 10/100\n",
      "577/577 [==============================] - 0s 330us/sample - loss: 0.6269 - accuracy: 0.7608 - val_loss: 2.0204 - val_accuracy: 0.3875\n",
      "Epoch 11/100\n",
      "577/577 [==============================] - 0s 359us/sample - loss: 0.6223 - accuracy: 0.7626 - val_loss: 3.0865 - val_accuracy: 0.3500\n",
      "Epoch 12/100\n",
      "577/577 [==============================] - 0s 351us/sample - loss: 0.6060 - accuracy: 0.7487 - val_loss: 1.6091 - val_accuracy: 0.4875\n",
      "Epoch 13/100\n",
      "577/577 [==============================] - 0s 326us/sample - loss: 0.6154 - accuracy: 0.7574 - val_loss: 4.4089 - val_accuracy: 0.3000\n",
      "Epoch 14/100\n",
      "577/577 [==============================] - 0s 345us/sample - loss: 0.6169 - accuracy: 0.7695 - val_loss: 2.3675 - val_accuracy: 0.3125\n",
      "Epoch 15/100\n",
      "577/577 [==============================] - 0s 347us/sample - loss: 0.6252 - accuracy: 0.7730 - val_loss: 1.8174 - val_accuracy: 0.4875\n",
      "Epoch 16/100\n",
      "577/577 [==============================] - 0s 451us/sample - loss: 0.5957 - accuracy: 0.7799 - val_loss: 1.8440 - val_accuracy: 0.5500\n",
      "Epoch 17/100\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 0.5598 - accuracy: 0.7920 - val_loss: 1.0675 - val_accuracy: 0.6125\n",
      "Epoch 18/100\n",
      "577/577 [==============================] - 0s 478us/sample - loss: 0.5885 - accuracy: 0.7747 - val_loss: 1.8570 - val_accuracy: 0.4375\n",
      "Epoch 19/100\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 0.6251 - accuracy: 0.7470 - val_loss: 1.5179 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "577/577 [==============================] - 0s 367us/sample - loss: 0.6188 - accuracy: 0.7730 - val_loss: 2.2044 - val_accuracy: 0.3375\n",
      "Epoch 21/100\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 0.6164 - accuracy: 0.7608 - val_loss: 2.1709 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "577/577 [==============================] - 0s 360us/sample - loss: 0.5835 - accuracy: 0.7972 - val_loss: 1.6032 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "577/577 [==============================] - 0s 426us/sample - loss: 0.6167 - accuracy: 0.7782 - val_loss: 2.4298 - val_accuracy: 0.4125\n",
      "Epoch 24/100\n",
      "577/577 [==============================] - 0s 525us/sample - loss: 0.5700 - accuracy: 0.7920 - val_loss: 1.7848 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "577/577 [==============================] - 0s 493us/sample - loss: 0.5990 - accuracy: 0.7955 - val_loss: 1.8787 - val_accuracy: 0.4625\n",
      "Epoch 26/100\n",
      "577/577 [==============================] - 0s 471us/sample - loss: 0.5837 - accuracy: 0.7782 - val_loss: 1.9209 - val_accuracy: 0.4625\n",
      "Epoch 27/100\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 0.5940 - accuracy: 0.7816 - val_loss: 4.0525 - val_accuracy: 0.4125\n",
      "Epoch 28/100\n",
      "577/577 [==============================] - 0s 494us/sample - loss: 0.6133 - accuracy: 0.7695 - val_loss: 2.6525 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "577/577 [==============================] - 0s 487us/sample - loss: 0.6144 - accuracy: 0.7747 - val_loss: 2.0289 - val_accuracy: 0.3875\n",
      "Epoch 30/100\n",
      "577/577 [==============================] - 0s 456us/sample - loss: 0.5904 - accuracy: 0.7868 - val_loss: 3.6219 - val_accuracy: 0.3000\n",
      "Epoch 31/100\n",
      "577/577 [==============================] - 0s 383us/sample - loss: 0.5720 - accuracy: 0.7799 - val_loss: 1.9194 - val_accuracy: 0.6500\n",
      "Epoch 32/100\n",
      "577/577 [==============================] - 0s 455us/sample - loss: 0.5734 - accuracy: 0.7868 - val_loss: 5.8535 - val_accuracy: 0.2500\n",
      "Epoch 33/100\n",
      "577/577 [==============================] - 0s 511us/sample - loss: 0.6536 - accuracy: 0.7262 - val_loss: 3.3983 - val_accuracy: 0.2625\n",
      "Epoch 34/100\n",
      "577/577 [==============================] - 0s 389us/sample - loss: 0.5637 - accuracy: 0.7955 - val_loss: 4.2918 - val_accuracy: 0.2250\n",
      "Epoch 35/100\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 0.6203 - accuracy: 0.7608 - val_loss: 2.5771 - val_accuracy: 0.3500\n",
      "Epoch 36/100\n",
      "577/577 [==============================] - 0s 473us/sample - loss: 0.6148 - accuracy: 0.7920 - val_loss: 1.6381 - val_accuracy: 0.5250\n",
      "Epoch 37/100\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 0.5368 - accuracy: 0.8007 - val_loss: 6.1322 - val_accuracy: 0.2375\n",
      "Epoch 38/100\n",
      "577/577 [==============================] - 0s 377us/sample - loss: 0.6008 - accuracy: 0.7972 - val_loss: 3.3161 - val_accuracy: 0.2875\n",
      "Epoch 39/100\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 0.5728 - accuracy: 0.7903 - val_loss: 1.7379 - val_accuracy: 0.4125\n",
      "Epoch 40/100\n",
      "577/577 [==============================] - 0s 552us/sample - loss: 0.5292 - accuracy: 0.8215 - val_loss: 2.7117 - val_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "577/577 [==============================] - 0s 468us/sample - loss: 0.5564 - accuracy: 0.7972 - val_loss: 2.4921 - val_accuracy: 0.3125\n",
      "Epoch 42/100\n",
      "577/577 [==============================] - 0s 409us/sample - loss: 0.5387 - accuracy: 0.8042 - val_loss: 2.1132 - val_accuracy: 0.4125\n",
      "Epoch 43/100\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 0.6094 - accuracy: 0.7712 - val_loss: 2.8704 - val_accuracy: 0.3250\n",
      "Epoch 44/100\n",
      "577/577 [==============================] - 0s 398us/sample - loss: 0.5683 - accuracy: 0.7747 - val_loss: 2.0955 - val_accuracy: 0.4375\n",
      "Epoch 45/100\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 0.5883 - accuracy: 0.7834 - val_loss: 3.0826 - val_accuracy: 0.3000\n",
      "Epoch 46/100\n",
      "577/577 [==============================] - 0s 464us/sample - loss: 0.5489 - accuracy: 0.7851 - val_loss: 1.5259 - val_accuracy: 0.4625\n",
      "Epoch 47/100\n",
      "577/577 [==============================] - 0s 517us/sample - loss: 0.5272 - accuracy: 0.8076 - val_loss: 2.7361 - val_accuracy: 0.3875\n",
      "Epoch 48/100\n",
      "577/577 [==============================] - 0s 552us/sample - loss: 0.5449 - accuracy: 0.8128 - val_loss: 2.3628 - val_accuracy: 0.4250\n",
      "Epoch 49/100\n",
      "577/577 [==============================] - 0s 461us/sample - loss: 0.5739 - accuracy: 0.7816 - val_loss: 2.5877 - val_accuracy: 0.3500\n",
      "Epoch 50/100\n",
      "577/577 [==============================] - 0s 514us/sample - loss: 0.5599 - accuracy: 0.7955 - val_loss: 2.0432 - val_accuracy: 0.4625\n",
      "Epoch 51/100\n",
      "577/577 [==============================] - 0s 386us/sample - loss: 0.5860 - accuracy: 0.7816 - val_loss: 2.8678 - val_accuracy: 0.3625\n",
      "Epoch 52/100\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 0.5063 - accuracy: 0.8128 - val_loss: 2.8764 - val_accuracy: 0.4625\n",
      "Epoch 53/100\n",
      "577/577 [==============================] - 0s 387us/sample - loss: 0.5236 - accuracy: 0.8024 - val_loss: 2.4523 - val_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "577/577 [==============================] - 0s 481us/sample - loss: 0.5453 - accuracy: 0.7903 - val_loss: 2.3766 - val_accuracy: 0.3625\n",
      "Epoch 55/100\n",
      "577/577 [==============================] - 0s 359us/sample - loss: 0.5513 - accuracy: 0.7799 - val_loss: 1.6423 - val_accuracy: 0.5625\n",
      "Epoch 56/100\n",
      "577/577 [==============================] - 0s 383us/sample - loss: 0.5467 - accuracy: 0.7730 - val_loss: 1.4514 - val_accuracy: 0.5625\n",
      "Epoch 57/100\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 0.5360 - accuracy: 0.7938 - val_loss: 1.4465 - val_accuracy: 0.5750\n",
      "Epoch 58/100\n",
      "577/577 [==============================] - 0s 377us/sample - loss: 0.5622 - accuracy: 0.7955 - val_loss: 3.9941 - val_accuracy: 0.3500\n",
      "Epoch 59/100\n",
      "577/577 [==============================] - 0s 372us/sample - loss: 0.4689 - accuracy: 0.8440 - val_loss: 1.4457 - val_accuracy: 0.5375\n",
      "Epoch 60/100\n",
      "577/577 [==============================] - 0s 382us/sample - loss: 0.5094 - accuracy: 0.8024 - val_loss: 2.7359 - val_accuracy: 0.3375\n",
      "Epoch 61/100\n",
      "577/577 [==============================] - 0s 375us/sample - loss: 0.5341 - accuracy: 0.7834 - val_loss: 2.6754 - val_accuracy: 0.3750\n",
      "Epoch 62/100\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 0.4708 - accuracy: 0.8267 - val_loss: 4.5654 - val_accuracy: 0.2375\n",
      "Epoch 63/100\n",
      "577/577 [==============================] - 0s 397us/sample - loss: 0.4871 - accuracy: 0.8284 - val_loss: 1.2305 - val_accuracy: 0.6250\n",
      "Epoch 64/100\n",
      "577/577 [==============================] - 0s 368us/sample - loss: 0.4550 - accuracy: 0.8232 - val_loss: 3.8965 - val_accuracy: 0.3000\n",
      "Epoch 65/100\n",
      "577/577 [==============================] - 0s 380us/sample - loss: 0.5002 - accuracy: 0.8024 - val_loss: 1.7735 - val_accuracy: 0.5250\n",
      "Epoch 66/100\n",
      "577/577 [==============================] - 0s 376us/sample - loss: 0.5503 - accuracy: 0.7938 - val_loss: 1.1850 - val_accuracy: 0.6250\n",
      "Epoch 67/100\n",
      "577/577 [==============================] - 0s 385us/sample - loss: 0.5561 - accuracy: 0.7903 - val_loss: 3.5753 - val_accuracy: 0.4000\n",
      "Epoch 68/100\n",
      "577/577 [==============================] - 0s 362us/sample - loss: 0.5072 - accuracy: 0.8163 - val_loss: 3.5849 - val_accuracy: 0.3125\n",
      "Epoch 69/100\n",
      "577/577 [==============================] - 0s 353us/sample - loss: 0.4747 - accuracy: 0.8267 - val_loss: 2.6942 - val_accuracy: 0.3375\n",
      "Epoch 70/100\n",
      "577/577 [==============================] - 0s 374us/sample - loss: 0.5376 - accuracy: 0.7920 - val_loss: 3.1294 - val_accuracy: 0.3750\n",
      "Epoch 71/100\n",
      "577/577 [==============================] - 0s 364us/sample - loss: 0.5045 - accuracy: 0.8059 - val_loss: 1.1952 - val_accuracy: 0.6250\n",
      "Epoch 72/100\n",
      "577/577 [==============================] - 0s 351us/sample - loss: 0.5271 - accuracy: 0.8180 - val_loss: 2.7019 - val_accuracy: 0.2500\n",
      "Epoch 73/100\n",
      "577/577 [==============================] - 0s 344us/sample - loss: 0.4696 - accuracy: 0.8284 - val_loss: 3.8024 - val_accuracy: 0.3250\n",
      "Epoch 74/100\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 0.5094 - accuracy: 0.7990 - val_loss: 1.8840 - val_accuracy: 0.4250\n",
      "Epoch 75/100\n",
      "577/577 [==============================] - 0s 358us/sample - loss: 0.5082 - accuracy: 0.8180 - val_loss: 4.3831 - val_accuracy: 0.3250\n",
      "Epoch 76/100\n",
      "577/577 [==============================] - 0s 375us/sample - loss: 0.5020 - accuracy: 0.8007 - val_loss: 1.9432 - val_accuracy: 0.4250\n",
      "Epoch 77/100\n",
      "577/577 [==============================] - 0s 351us/sample - loss: 0.4939 - accuracy: 0.8146 - val_loss: 1.9165 - val_accuracy: 0.5500\n",
      "Epoch 78/100\n",
      "577/577 [==============================] - 0s 357us/sample - loss: 0.5098 - accuracy: 0.7972 - val_loss: 3.2050 - val_accuracy: 0.3375\n",
      "Epoch 79/100\n",
      "577/577 [==============================] - 0s 369us/sample - loss: 0.5477 - accuracy: 0.7886 - val_loss: 1.5664 - val_accuracy: 0.5500\n",
      "Epoch 80/100\n",
      "577/577 [==============================] - 0s 375us/sample - loss: 0.4948 - accuracy: 0.8163 - val_loss: 2.5952 - val_accuracy: 0.4500\n",
      "Epoch 81/100\n",
      "577/577 [==============================] - 0s 381us/sample - loss: 0.4421 - accuracy: 0.8302 - val_loss: 2.6769 - val_accuracy: 0.4625\n",
      "Epoch 82/100\n",
      "577/577 [==============================] - 0s 458us/sample - loss: 0.4758 - accuracy: 0.8059 - val_loss: 2.6866 - val_accuracy: 0.4250\n",
      "Epoch 83/100\n",
      "577/577 [==============================] - 0s 407us/sample - loss: 0.4540 - accuracy: 0.8302 - val_loss: 3.2726 - val_accuracy: 0.3500\n",
      "Epoch 84/100\n",
      "577/577 [==============================] - 0s 346us/sample - loss: 0.4129 - accuracy: 0.8562 - val_loss: 1.6787 - val_accuracy: 0.5750\n",
      "Epoch 85/100\n",
      "577/577 [==============================] - 0s 326us/sample - loss: 0.5164 - accuracy: 0.8042 - val_loss: 1.9085 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "577/577 [==============================] - 0s 375us/sample - loss: 0.5572 - accuracy: 0.8024 - val_loss: 1.4898 - val_accuracy: 0.6750\n",
      "Epoch 87/100\n",
      "577/577 [==============================] - 0s 341us/sample - loss: 0.4471 - accuracy: 0.8180 - val_loss: 1.8078 - val_accuracy: 0.5500\n",
      "Epoch 88/100\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 0.4867 - accuracy: 0.8094 - val_loss: 3.0763 - val_accuracy: 0.3500\n",
      "Epoch 89/100\n",
      "577/577 [==============================] - 0s 357us/sample - loss: 0.5132 - accuracy: 0.7938 - val_loss: 3.2075 - val_accuracy: 0.3000\n",
      "Epoch 90/100\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 0.4819 - accuracy: 0.8232 - val_loss: 2.1036 - val_accuracy: 0.3750\n",
      "Epoch 91/100\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 0.4820 - accuracy: 0.7972 - val_loss: 2.3042 - val_accuracy: 0.4125\n",
      "Epoch 92/100\n",
      "577/577 [==============================] - 0s 363us/sample - loss: 0.4439 - accuracy: 0.8128 - val_loss: 1.7521 - val_accuracy: 0.5375\n",
      "Epoch 93/100\n",
      "577/577 [==============================] - 0s 370us/sample - loss: 0.4452 - accuracy: 0.8215 - val_loss: 2.3385 - val_accuracy: 0.4500\n",
      "Epoch 94/100\n",
      "577/577 [==============================] - 0s 364us/sample - loss: 0.4406 - accuracy: 0.8267 - val_loss: 3.2395 - val_accuracy: 0.4125\n",
      "Epoch 95/100\n",
      "577/577 [==============================] - 0s 349us/sample - loss: 0.4781 - accuracy: 0.8180 - val_loss: 3.5007 - val_accuracy: 0.3625\n",
      "Epoch 96/100\n",
      "577/577 [==============================] - 0s 341us/sample - loss: 0.4632 - accuracy: 0.8146 - val_loss: 1.5534 - val_accuracy: 0.4625\n",
      "Epoch 97/100\n",
      "577/577 [==============================] - 0s 347us/sample - loss: 0.4363 - accuracy: 0.8319 - val_loss: 5.3601 - val_accuracy: 0.2625\n",
      "Epoch 98/100\n",
      "577/577 [==============================] - 0s 356us/sample - loss: 0.5421 - accuracy: 0.7920 - val_loss: 3.6265 - val_accuracy: 0.3375\n",
      "Epoch 99/100\n",
      "577/577 [==============================] - 0s 355us/sample - loss: 0.4645 - accuracy: 0.8423 - val_loss: 2.5003 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "577/577 [==============================] - 0s 342us/sample - loss: 0.5464 - accuracy: 0.7938 - val_loss: 5.8744 - val_accuracy: 0.3250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f214c086a00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(XDB,YDB,batch_size=32,epochs=100,validation_data=(XTB,YTB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.325"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(XTB).argmax(axis=1)==YTB.argmax(axis=1)).sum()/len(XTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 5, 2, 5, 3, 2, 5, 2, 0, 2, 2, 5, 3, 2, 3, 3, 5, 2, 2,\n",
       "       2, 5, 3, 3, 3, 5, 3, 2, 5, 5, 3, 2, 3, 2, 3, 3, 2, 2, 3, 2, 0, 3,\n",
       "       2, 3, 2, 2, 5, 4, 3, 2, 2, 2, 3, 2, 5, 2, 2, 3, 5, 3, 2, 2, 3, 2,\n",
       "       3, 2, 2, 2, 0, 5, 3, 3, 2, 3, 2, 5, 5, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTB).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 0, 5, 4, 5, 2, 5, 5, 4, 1, 0, 5, 5, 3, 5, 3, 0, 0, 0, 0,\n",
       "       4, 0, 3, 3, 0, 2, 3, 5, 3, 0, 0, 5, 1, 4, 2, 3, 0, 1, 3, 1, 0, 2,\n",
       "       2, 4, 0, 5, 0, 0, 4, 2, 4, 1, 3, 5, 5, 0, 4, 1, 5, 3, 3, 5, 0, 4,\n",
       "       0, 0, 2, 4, 0, 5, 1, 1, 4, 4, 2, 0, 5, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTB.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 231 201 186 186\n",
      "[] 230 201 187 187\n",
      "[] 233 201 185 185\n",
      "[] 231 201 186 186\n",
      "[] 230 200 188 188\n",
      "[] 224 196 196 196\n",
      "[] 225 197 190 190\n",
      "[] 223 196 196 196\n",
      "[] 222 196 196 196\n",
      "[] 224 195 196 196\n",
      "[] 222 196 196 196\n",
      "[] 222 196 196 196\n",
      "[] 225 198 192 192\n",
      "[] 224 196 196 196\n",
      "[] 224 196 196 196\n",
      "[] 223 196 196 196\n",
      "[] 82 202 116 116\n",
      "[] 80 203 116 116\n",
      "[] 228 201 192 192\n",
      "[] 226 199 196 196\n",
      "[] 225 197 196 196\n",
      "[] 224 196 196 196\n",
      "[] 224 196 196 196\n",
      "[] 224 195 196 196\n",
      "[] 225 195 196 196\n",
      "[] 222 196 196 196\n",
      "[] 224 196 196 196\n",
      "[] 225 197 196 196\n",
      "[] 225 196 196 196\n",
      "[] 226 196 196 196\n",
      "[] 222 197 196 196\n",
      "[] 229 199 192 192\n",
      "[] 226 199 196 196\n",
      "[] 226 201 192 192\n",
      "[] 227 201 189 189\n",
      "[] 223 199 196 196\n",
      "[] 224 201 191 191\n",
      "[] 219 199 196 196\n",
      "[] 68 203 112 112\n",
      "[] 220 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 224 203 196 196\n",
      "[] 225 202 192 192\n",
      "[] 66 202 112 112\n",
      "[] 221 203 196 196\n",
      "[] 223 202 196 196\n",
      "[] 225 203 192 192\n",
      "[] 220 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 222 199 201 201\n",
      "[] 222 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 220 200 196 196\n",
      "[] 69 206 109 109\n",
      "[] 65 205 112 112\n",
      "[] 221 200 196 196\n",
      "[] 221 200 196 196\n",
      "[] 67 206 110 110\n",
      "[] 227 200 192 192\n",
      "[] 225 197 192 192\n",
      "[] 228 200 183 183\n",
      "[] 227 199 184 184\n",
      "[] 232 201 178 178\n",
      "[] 234 198 181 181\n",
      "[] 234 199 182 182\n",
      "[] 235 196 185 185\n",
      "[] 240 196 186 186\n",
      "[] 244 198 183 183\n",
      "[] 252 199 180 180\n",
      "[] 247 193 190 190\n",
      "[] 250 191 190 190\n",
      "[] 250 197 184 184\n",
      "[] 249 196 188 188\n",
      "[] 252 198 182 182\n",
      "[] 250 200 181 181\n",
      "[] 242 191 192 192\n",
      "[] 238 195 192 192\n",
      "[] 239 195 190 190\n",
      "[] 54 202 120 120\n",
      "[] 238 194 190 190\n",
      "[] 239 199 183 183\n",
      "[] 237 192 196 196\n",
      "[] 239 197 187 187\n",
      "[] 235 194 193 193\n",
      "[] 36 204 127 127\n",
      "[] 240 196 189 189\n",
      "[] 244 194 190 190\n",
      "[] 245 196 188 188\n",
      "[] 242 199 185 185\n",
      "[] 239 194 192 192\n",
      "[] 242 198 186 186\n",
      "[] 240 197 188 188\n",
      "[] 244 198 189 189\n",
      "[] 243 198 189 189\n",
      "[] 247 202 183 183\n",
      "[] 243 197 192 192\n",
      "[] 242 199 188 188\n",
      "[] 240 194 196 196\n",
      "[] 243 195 193 193\n",
      "[] 340 176 174 174\n",
      "[] 60 199 116 116\n",
      "[] 347 183 182 182\n",
      "[] 347 178 190 190\n",
      "[] 346 179 190 190\n",
      "[] 352 186 183 183\n",
      "[] 348 182 184 184\n",
      "[] 344 180 188 188\n",
      "[] 346 189 174 174\n",
      "[] 455 238 158 158\n",
      "[] 119 235 114 114\n",
      "[] 113 234 117 117\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    landmarks=[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        svx,svy=x,y\n",
    "        gray=gray[y:y+h,x:x+w]\n",
    "        try:\n",
    "            gray=cv2.resize(gray, (face_dim, face_dim))\n",
    "        except:\n",
    "            print(gray,x,y,w,h)\n",
    "            continue\n",
    "        shape=predictor(gray,dlib.rectangle(0,0,face_dim,face_dim))\n",
    "        xlist=[]\n",
    "        ylist=[]\n",
    "        for i in range(68):\n",
    "            xp=shape.part(i).x\n",
    "            yp=shape.part(i).y\n",
    "            cv2.circle(gray, (xp, yp), 2, (255, 255, 255), -1)\n",
    "            xlist.append(float(xp))\n",
    "            ylist.append(float(yp))\n",
    "        cv2.imshow('gray',gray)\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        res=[]\n",
    "        for (x,y) in zip(xcentral,ycentral):\n",
    "            res.append(x)\n",
    "            res.append(y)\n",
    "        landmarks.append((np.asarray(res)/face_dim+1)/2)\n",
    "    if len(landmarks)>0:\n",
    "        y_out=model.predict(np.asarray(landmarks))\n",
    "        res=np.argmax(y_out,axis=1)\n",
    "        for r in res:\n",
    "            cv2.putText(img,emotions[r],(svx,svy),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
