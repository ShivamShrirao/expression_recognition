{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../face_recognition/haarcascade_frontalface_default.xml')\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=\"../facial_expressions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"anger\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_keypoints(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (face_dim, face_dim))\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces)==0:\n",
    "        param=[0,0,face_dim,face_dim]\n",
    "    else:\n",
    "        (x,y,w,h)=faces[0]\n",
    "        param=[x,y,x+w,y+h]\n",
    "    shape=predictor(gray,dlib.rectangle(*param))\n",
    "    xlist=[]\n",
    "    ylist=[]\n",
    "    for i in range(68):\n",
    "        xlist.append(np.float32(shape.part(i).x))\n",
    "        ylist.append(np.float32(shape.part(i).y))\n",
    "    xmean = np.mean(xlist)\n",
    "    ymean = np.mean(ylist)\n",
    "#     plt.imshow(gray,cmap='gray')\n",
    "#     plt.scatter(xlist,ylist, marker='.')\n",
    "#     plt.show()\n",
    "    xcentral = [(x-xmean) for x in xlist]\n",
    "    ycentral = [(y-ymean) for y in ylist]\n",
    "    res=[]\n",
    "    for (x,y) in zip(xcentral,ycentral):\n",
    "        res.append(x)\n",
    "        res.append(y)\n",
    "    return (np.asarray(res)/face_dim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_keypoints():\n",
    "    X_inp=[]\n",
    "    y_inp=[]\n",
    "    for em in emotions:\n",
    "        ltt=os.listdir(IMG_PATH+em)\n",
    "        lnltt=len(ltt)\n",
    "        for idx,imn in enumerate(ltt):\n",
    "            print(\"\\r\",idx+1,'/',lnltt,end=\" \")\n",
    "            image = cv2.imread(IMG_PATH+em+\"/\"+imn)\n",
    "            landmarks=ret_keypoints(image)\n",
    "            if landmarks is not None:\n",
    "                X_inp.append(landmarks)\n",
    "                yy=np.zeros(len(emotions))\n",
    "                yy[emotions.index(em)]=1\n",
    "                y_inp.append(yy)\n",
    "        print()\n",
    "    return np.asarray(X_inp),np.asarray(y_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 124 / 124 \n",
      " 84 / 84 \n",
      " 67 / 67  67 \n",
      " 127 / 127 \n",
      " 123 / 123 \n",
      " 132 / 132 \n"
     ]
    }
   ],
   "source": [
    "XXD,YYD=prep_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(len(XXD))\n",
    "for i in range(5):\n",
    "    np.random.shuffle(s)\n",
    "    XXD=XXD[s]\n",
    "    YYD=YYD[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,activation='relu', input_shape=(68*2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(emotions),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              140288    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 837,766\n",
      "Trainable params: 833,926\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut=80\n",
    "XDB=XXD[cut:]\n",
    "YDB=YYD[cut:]\n",
    "\n",
    "XTB=XXD[:cut]\n",
    "YTB=YYD[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 577 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "577/577 [==============================] - 0s 406us/sample - loss: 0.6627 - accuracy: 0.7470 - val_loss: 2.6617 - val_accuracy: 0.3125\n",
      "Epoch 2/100\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 0.6858 - accuracy: 0.7331 - val_loss: 2.2152 - val_accuracy: 0.3625\n",
      "Epoch 3/100\n",
      "577/577 [==============================] - 0s 430us/sample - loss: 0.6915 - accuracy: 0.7487 - val_loss: 1.4944 - val_accuracy: 0.4875\n",
      "Epoch 4/100\n",
      "577/577 [==============================] - 0s 401us/sample - loss: 0.6633 - accuracy: 0.7452 - val_loss: 1.0188 - val_accuracy: 0.7125\n",
      "Epoch 5/100\n",
      "577/577 [==============================] - 0s 429us/sample - loss: 0.6084 - accuracy: 0.7764 - val_loss: 2.1063 - val_accuracy: 0.3375\n",
      "Epoch 6/100\n",
      "577/577 [==============================] - 0s 456us/sample - loss: 0.5865 - accuracy: 0.7660 - val_loss: 1.9143 - val_accuracy: 0.4250\n",
      "Epoch 7/100\n",
      "577/577 [==============================] - 0s 439us/sample - loss: 0.6749 - accuracy: 0.7227 - val_loss: 1.6732 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "577/577 [==============================] - 0s 469us/sample - loss: 0.6292 - accuracy: 0.7574 - val_loss: 1.6765 - val_accuracy: 0.5250\n",
      "Epoch 9/100\n",
      "577/577 [==============================] - 0s 447us/sample - loss: 0.5924 - accuracy: 0.7678 - val_loss: 3.6619 - val_accuracy: 0.3000\n",
      "Epoch 10/100\n",
      "577/577 [==============================] - 0s 452us/sample - loss: 0.6733 - accuracy: 0.7418 - val_loss: 5.4040 - val_accuracy: 0.2125\n",
      "Epoch 11/100\n",
      "577/577 [==============================] - 0s 482us/sample - loss: 0.5977 - accuracy: 0.7834 - val_loss: 1.8003 - val_accuracy: 0.4750\n",
      "Epoch 12/100\n",
      "577/577 [==============================] - 0s 409us/sample - loss: 0.6307 - accuracy: 0.7712 - val_loss: 2.0531 - val_accuracy: 0.3875\n",
      "Epoch 13/100\n",
      "577/577 [==============================] - 0s 419us/sample - loss: 0.6100 - accuracy: 0.7678 - val_loss: 1.6686 - val_accuracy: 0.4750\n",
      "Epoch 14/100\n",
      "577/577 [==============================] - 0s 467us/sample - loss: 0.6545 - accuracy: 0.7470 - val_loss: 2.2047 - val_accuracy: 0.3625\n",
      "Epoch 15/100\n",
      "577/577 [==============================] - 0s 562us/sample - loss: 0.5889 - accuracy: 0.7886 - val_loss: 2.1128 - val_accuracy: 0.4625\n",
      "Epoch 16/100\n",
      "577/577 [==============================] - 0s 614us/sample - loss: 0.6027 - accuracy: 0.7712 - val_loss: 4.1193 - val_accuracy: 0.2750\n",
      "Epoch 17/100\n",
      "577/577 [==============================] - 0s 644us/sample - loss: 0.6080 - accuracy: 0.7834 - val_loss: 2.1691 - val_accuracy: 0.3875\n",
      "Epoch 18/100\n",
      "577/577 [==============================] - 0s 615us/sample - loss: 0.5979 - accuracy: 0.7712 - val_loss: 6.3436 - val_accuracy: 0.1875\n",
      "Epoch 19/100\n",
      "577/577 [==============================] - 0s 476us/sample - loss: 0.5920 - accuracy: 0.7764 - val_loss: 2.2751 - val_accuracy: 0.4500\n",
      "Epoch 20/100\n",
      "577/577 [==============================] - 0s 483us/sample - loss: 0.5930 - accuracy: 0.7886 - val_loss: 2.1027 - val_accuracy: 0.4375\n",
      "Epoch 21/100\n",
      "577/577 [==============================] - 0s 691us/sample - loss: 0.6198 - accuracy: 0.7556 - val_loss: 1.6556 - val_accuracy: 0.4625\n",
      "Epoch 22/100\n",
      "577/577 [==============================] - 0s 649us/sample - loss: 0.6215 - accuracy: 0.7955 - val_loss: 4.1285 - val_accuracy: 0.2125\n",
      "Epoch 23/100\n",
      "577/577 [==============================] - 0s 577us/sample - loss: 0.5867 - accuracy: 0.7626 - val_loss: 1.2092 - val_accuracy: 0.5625\n",
      "Epoch 24/100\n",
      "577/577 [==============================] - 0s 558us/sample - loss: 0.6662 - accuracy: 0.7487 - val_loss: 5.9046 - val_accuracy: 0.1500\n",
      "Epoch 25/100\n",
      "577/577 [==============================] - 0s 524us/sample - loss: 0.5422 - accuracy: 0.8007 - val_loss: 4.5616 - val_accuracy: 0.2375\n",
      "Epoch 26/100\n",
      "577/577 [==============================] - 0s 474us/sample - loss: 0.5766 - accuracy: 0.7920 - val_loss: 2.1803 - val_accuracy: 0.3625\n",
      "Epoch 27/100\n",
      "577/577 [==============================] - 0s 647us/sample - loss: 0.5977 - accuracy: 0.7799 - val_loss: 2.1984 - val_accuracy: 0.4750\n",
      "Epoch 28/100\n",
      "577/577 [==============================] - 0s 627us/sample - loss: 0.5921 - accuracy: 0.7816 - val_loss: 5.1730 - val_accuracy: 0.2500\n",
      "Epoch 29/100\n",
      "577/577 [==============================] - 0s 514us/sample - loss: 0.6317 - accuracy: 0.7695 - val_loss: 4.5656 - val_accuracy: 0.2125\n",
      "Epoch 30/100\n",
      "577/577 [==============================] - 0s 576us/sample - loss: 0.5802 - accuracy: 0.7955 - val_loss: 3.0072 - val_accuracy: 0.3375\n",
      "Epoch 31/100\n",
      "577/577 [==============================] - 0s 589us/sample - loss: 0.6101 - accuracy: 0.7747 - val_loss: 3.7688 - val_accuracy: 0.2750\n",
      "Epoch 32/100\n",
      "577/577 [==============================] - 0s 423us/sample - loss: 0.5750 - accuracy: 0.8024 - val_loss: 1.6708 - val_accuracy: 0.4750\n",
      "Epoch 33/100\n",
      "577/577 [==============================] - 0s 470us/sample - loss: 0.5839 - accuracy: 0.7938 - val_loss: 1.1692 - val_accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "577/577 [==============================] - 0s 453us/sample - loss: 0.5628 - accuracy: 0.8059 - val_loss: 1.2378 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "577/577 [==============================] - 0s 451us/sample - loss: 0.5705 - accuracy: 0.7747 - val_loss: 1.6025 - val_accuracy: 0.4500\n",
      "Epoch 36/100\n",
      "577/577 [==============================] - 0s 410us/sample - loss: 0.5746 - accuracy: 0.7955 - val_loss: 1.8592 - val_accuracy: 0.3750\n",
      "Epoch 37/100\n",
      "577/577 [==============================] - 0s 454us/sample - loss: 0.5670 - accuracy: 0.7834 - val_loss: 6.3934 - val_accuracy: 0.1750\n",
      "Epoch 38/100\n",
      "577/577 [==============================] - 0s 434us/sample - loss: 0.6037 - accuracy: 0.7764 - val_loss: 3.2828 - val_accuracy: 0.3250\n",
      "Epoch 39/100\n",
      "577/577 [==============================] - 0s 448us/sample - loss: 0.5804 - accuracy: 0.7782 - val_loss: 2.2428 - val_accuracy: 0.4250\n",
      "Epoch 40/100\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 0.5484 - accuracy: 0.7990 - val_loss: 1.5487 - val_accuracy: 0.4750\n",
      "Epoch 41/100\n",
      "577/577 [==============================] - 0s 451us/sample - loss: 0.5662 - accuracy: 0.7834 - val_loss: 3.5276 - val_accuracy: 0.2875\n",
      "Epoch 42/100\n",
      "577/577 [==============================] - 0s 469us/sample - loss: 0.6136 - accuracy: 0.7816 - val_loss: 5.7239 - val_accuracy: 0.2875\n",
      "Epoch 43/100\n",
      "577/577 [==============================] - 0s 413us/sample - loss: 0.5776 - accuracy: 0.7868 - val_loss: 5.2245 - val_accuracy: 0.2250\n",
      "Epoch 44/100\n",
      "577/577 [==============================] - 0s 411us/sample - loss: 0.5474 - accuracy: 0.7990 - val_loss: 1.7879 - val_accuracy: 0.4625\n",
      "Epoch 45/100\n",
      "577/577 [==============================] - 0s 483us/sample - loss: 0.5827 - accuracy: 0.7955 - val_loss: 2.3206 - val_accuracy: 0.4875\n",
      "Epoch 46/100\n",
      "577/577 [==============================] - 0s 429us/sample - loss: 0.5895 - accuracy: 0.7747 - val_loss: 1.7040 - val_accuracy: 0.5625\n",
      "Epoch 47/100\n",
      "577/577 [==============================] - 0s 411us/sample - loss: 0.5636 - accuracy: 0.7920 - val_loss: 2.7744 - val_accuracy: 0.3625\n",
      "Epoch 48/100\n",
      "577/577 [==============================] - 0s 425us/sample - loss: 0.5624 - accuracy: 0.8007 - val_loss: 1.7947 - val_accuracy: 0.4750\n",
      "Epoch 49/100\n",
      "577/577 [==============================] - 0s 537us/sample - loss: 0.5308 - accuracy: 0.7886 - val_loss: 2.5159 - val_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "577/577 [==============================] - 0s 451us/sample - loss: 0.5616 - accuracy: 0.7764 - val_loss: 5.0884 - val_accuracy: 0.2250\n",
      "Epoch 51/100\n",
      "577/577 [==============================] - 0s 421us/sample - loss: 0.6401 - accuracy: 0.7522 - val_loss: 2.6643 - val_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "577/577 [==============================] - 0s 421us/sample - loss: 0.5125 - accuracy: 0.8111 - val_loss: 1.9684 - val_accuracy: 0.4500\n",
      "Epoch 53/100\n",
      "577/577 [==============================] - 0s 493us/sample - loss: 0.6107 - accuracy: 0.7799 - val_loss: 1.5650 - val_accuracy: 0.4875\n",
      "Epoch 54/100\n",
      "577/577 [==============================] - 0s 440us/sample - loss: 0.4996 - accuracy: 0.8128 - val_loss: 2.3480 - val_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "577/577 [==============================] - 0s 444us/sample - loss: 0.5089 - accuracy: 0.8146 - val_loss: 2.2332 - val_accuracy: 0.4000\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 401us/sample - loss: 0.5580 - accuracy: 0.7990 - val_loss: 2.9871 - val_accuracy: 0.2875\n",
      "Epoch 57/100\n",
      "577/577 [==============================] - 0s 416us/sample - loss: 0.5428 - accuracy: 0.8007 - val_loss: 3.3723 - val_accuracy: 0.3750\n",
      "Epoch 58/100\n",
      "577/577 [==============================] - 0s 397us/sample - loss: 0.5878 - accuracy: 0.7886 - val_loss: 5.5034 - val_accuracy: 0.2000\n",
      "Epoch 59/100\n",
      "577/577 [==============================] - 0s 385us/sample - loss: 0.5482 - accuracy: 0.8059 - val_loss: 1.4419 - val_accuracy: 0.5500\n",
      "Epoch 60/100\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 0.4703 - accuracy: 0.8423 - val_loss: 2.2443 - val_accuracy: 0.4875\n",
      "Epoch 61/100\n",
      "577/577 [==============================] - 0s 403us/sample - loss: 0.4638 - accuracy: 0.8146 - val_loss: 1.6149 - val_accuracy: 0.4750\n",
      "Epoch 62/100\n",
      "577/577 [==============================] - 0s 391us/sample - loss: 0.5058 - accuracy: 0.8215 - val_loss: 1.5256 - val_accuracy: 0.5375\n",
      "Epoch 63/100\n",
      "577/577 [==============================] - 0s 383us/sample - loss: 0.5283 - accuracy: 0.8146 - val_loss: 1.1506 - val_accuracy: 0.7000\n",
      "Epoch 64/100\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 0.5569 - accuracy: 0.7886 - val_loss: 1.4444 - val_accuracy: 0.5125\n",
      "Epoch 65/100\n",
      "577/577 [==============================] - 0s 426us/sample - loss: 0.5278 - accuracy: 0.8042 - val_loss: 3.4861 - val_accuracy: 0.2500\n",
      "Epoch 66/100\n",
      "577/577 [==============================] - 0s 477us/sample - loss: 0.4642 - accuracy: 0.8336 - val_loss: 4.4087 - val_accuracy: 0.2625\n",
      "Epoch 67/100\n",
      "577/577 [==============================] - 0s 405us/sample - loss: 0.4326 - accuracy: 0.8371 - val_loss: 3.1247 - val_accuracy: 0.3250\n",
      "Epoch 68/100\n",
      "577/577 [==============================] - 0s 391us/sample - loss: 0.4963 - accuracy: 0.7990 - val_loss: 4.7767 - val_accuracy: 0.2750\n",
      "Epoch 69/100\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 0.5057 - accuracy: 0.8267 - val_loss: 3.3471 - val_accuracy: 0.2750\n",
      "Epoch 70/100\n",
      "577/577 [==============================] - 0s 404us/sample - loss: 0.5079 - accuracy: 0.8007 - val_loss: 1.8906 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "577/577 [==============================] - 0s 403us/sample - loss: 0.4866 - accuracy: 0.8336 - val_loss: 1.5607 - val_accuracy: 0.6125\n",
      "Epoch 72/100\n",
      "577/577 [==============================] - 0s 395us/sample - loss: 0.5076 - accuracy: 0.8250 - val_loss: 2.0056 - val_accuracy: 0.4875\n",
      "Epoch 73/100\n",
      "577/577 [==============================] - 0s 398us/sample - loss: 0.5529 - accuracy: 0.7972 - val_loss: 2.3989 - val_accuracy: 0.3750\n",
      "Epoch 74/100\n",
      "577/577 [==============================] - 0s 456us/sample - loss: 0.5058 - accuracy: 0.8042 - val_loss: 1.8109 - val_accuracy: 0.5250\n",
      "Epoch 75/100\n",
      "577/577 [==============================] - 0s 380us/sample - loss: 0.4824 - accuracy: 0.8180 - val_loss: 1.3067 - val_accuracy: 0.5875\n",
      "Epoch 76/100\n",
      "577/577 [==============================] - 0s 397us/sample - loss: 0.4385 - accuracy: 0.8284 - val_loss: 1.3666 - val_accuracy: 0.5875\n",
      "Epoch 77/100\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 0.4659 - accuracy: 0.8302 - val_loss: 1.7769 - val_accuracy: 0.5625\n",
      "Epoch 78/100\n",
      "577/577 [==============================] - 0s 418us/sample - loss: 0.5004 - accuracy: 0.8042 - val_loss: 1.1736 - val_accuracy: 0.6250\n",
      "Epoch 79/100\n",
      "577/577 [==============================] - 0s 390us/sample - loss: 0.5331 - accuracy: 0.8076 - val_loss: 6.4249 - val_accuracy: 0.2500\n",
      "Epoch 80/100\n",
      "577/577 [==============================] - 0s 395us/sample - loss: 0.5145 - accuracy: 0.7990 - val_loss: 6.2050 - val_accuracy: 0.3000\n",
      "Epoch 81/100\n",
      "577/577 [==============================] - 0s 401us/sample - loss: 0.4945 - accuracy: 0.8094 - val_loss: 3.6977 - val_accuracy: 0.2750\n",
      "Epoch 82/100\n",
      "577/577 [==============================] - 0s 408us/sample - loss: 0.4476 - accuracy: 0.8354 - val_loss: 6.6107 - val_accuracy: 0.2750\n",
      "Epoch 83/100\n",
      "577/577 [==============================] - 0s 400us/sample - loss: 0.5243 - accuracy: 0.8042 - val_loss: 1.2916 - val_accuracy: 0.6000\n",
      "Epoch 84/100\n",
      "577/577 [==============================] - 0s 389us/sample - loss: 0.4778 - accuracy: 0.8128 - val_loss: 1.3882 - val_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "577/577 [==============================] - 0s 394us/sample - loss: 0.4523 - accuracy: 0.8302 - val_loss: 1.4751 - val_accuracy: 0.5750\n",
      "Epoch 86/100\n",
      "577/577 [==============================] - 0s 406us/sample - loss: 0.4755 - accuracy: 0.8198 - val_loss: 2.0232 - val_accuracy: 0.5125\n",
      "Epoch 87/100\n",
      "577/577 [==============================] - 0s 493us/sample - loss: 0.4657 - accuracy: 0.8267 - val_loss: 2.3467 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "577/577 [==============================] - 0s 383us/sample - loss: 0.5288 - accuracy: 0.7920 - val_loss: 1.6342 - val_accuracy: 0.5750\n",
      "Epoch 89/100\n",
      "577/577 [==============================] - 0s 396us/sample - loss: 0.4448 - accuracy: 0.8267 - val_loss: 5.2121 - val_accuracy: 0.2250\n",
      "Epoch 90/100\n",
      "577/577 [==============================] - 0s 397us/sample - loss: 0.5176 - accuracy: 0.8076 - val_loss: 5.5671 - val_accuracy: 0.2625\n",
      "Epoch 91/100\n",
      "577/577 [==============================] - 0s 447us/sample - loss: 0.5116 - accuracy: 0.7903 - val_loss: 3.9680 - val_accuracy: 0.3000\n",
      "Epoch 92/100\n",
      "577/577 [==============================] - 0s 391us/sample - loss: 0.5180 - accuracy: 0.8146 - val_loss: 3.2152 - val_accuracy: 0.3750\n",
      "Epoch 93/100\n",
      "577/577 [==============================] - 0s 428us/sample - loss: 0.4898 - accuracy: 0.8042 - val_loss: 2.4024 - val_accuracy: 0.3375\n",
      "Epoch 94/100\n",
      "577/577 [==============================] - 0s 388us/sample - loss: 0.4423 - accuracy: 0.8510 - val_loss: 3.9508 - val_accuracy: 0.3250\n",
      "Epoch 95/100\n",
      "577/577 [==============================] - 0s 434us/sample - loss: 0.4414 - accuracy: 0.8215 - val_loss: 2.8731 - val_accuracy: 0.3250\n",
      "Epoch 96/100\n",
      "577/577 [==============================] - 0s 431us/sample - loss: 0.4041 - accuracy: 0.8458 - val_loss: 4.6939 - val_accuracy: 0.2875\n",
      "Epoch 97/100\n",
      "577/577 [==============================] - 0s 473us/sample - loss: 0.4768 - accuracy: 0.8250 - val_loss: 1.7189 - val_accuracy: 0.5375\n",
      "Epoch 98/100\n",
      "577/577 [==============================] - 0s 428us/sample - loss: 0.4607 - accuracy: 0.8128 - val_loss: 1.7288 - val_accuracy: 0.4750\n",
      "Epoch 99/100\n",
      "577/577 [==============================] - 0s 427us/sample - loss: 0.4889 - accuracy: 0.8146 - val_loss: 1.9974 - val_accuracy: 0.5375\n",
      "Epoch 100/100\n",
      "577/577 [==============================] - 0s 399us/sample - loss: 0.4454 - accuracy: 0.8440 - val_loss: 1.5313 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f592eef2940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(XDB,YDB,batch_size=32,epochs=100,validation_data=(XTB,YTB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(XTB).argmax(axis=1)==YTB.argmax(axis=1)).sum()/len(XTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 5, 5, 0, 0, 5, 5, 0, 4, 4, 4, 3, 4, 5, 4, 0, 4, 4, 0, 0,\n",
       "       3, 3, 3, 4, 0, 3, 3, 2, 0, 0, 0, 2, 4, 0, 2, 0, 5, 4, 2, 4, 3, 4,\n",
       "       0, 4, 0, 0, 0, 5, 0, 2, 5, 2, 0, 0, 0, 5, 2, 2, 0, 0, 3, 2, 4, 3,\n",
       "       0, 2, 3, 0, 0, 3, 4, 0, 4, 5, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTB).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 5, 5, 0, 0, 5, 3, 0, 4, 4, 4, 3, 4, 5, 4, 1, 4, 4, 3, 0,\n",
       "       3, 3, 3, 4, 1, 3, 3, 5, 5, 3, 5, 5, 4, 1, 2, 0, 5, 4, 5, 1, 3, 4,\n",
       "       0, 4, 2, 0, 0, 5, 5, 3, 2, 2, 0, 0, 2, 5, 5, 2, 3, 1, 3, 4, 4, 3,\n",
       "       2, 3, 3, 5, 1, 3, 4, 5, 4, 0, 1, 4, 4, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTB.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 308 234 120 120\n",
      "[] 311 235 120 120\n",
      "[] 310 233 120 120\n",
      "[] 308 236 116 116\n",
      "[] 314 236 119 119\n",
      "[] 315 238 116 116\n",
      "[] 315 237 116 116\n",
      "[] 328 234 123 123\n",
      "[] 337 192 156 156\n",
      "[] 340 193 190 190\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    landmarks=[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        gray=gray[y:y+h,x:x+w]\n",
    "        try:\n",
    "            gray=cv2.resize(gray, (face_dim, face_dim))\n",
    "        except:\n",
    "            print(gray,x,y,w,h)\n",
    "            continue\n",
    "        shape=predictor(gray,dlib.rectangle(0,0,face_dim,face_dim))\n",
    "        xlist=[]\n",
    "        ylist=[]\n",
    "        for i in range(68):\n",
    "            xp=shape.part(i).x\n",
    "            yp=shape.part(i).y\n",
    "            cv2.circle(gray, (xp, yp), 2, (255, 255, 255), -1)\n",
    "            xlist.append(float(xp))\n",
    "            ylist.append(float(yp))\n",
    "        cv2.imshow('gray',gray)\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        res=[]\n",
    "        for (x,y) in zip(xcentral,ycentral):\n",
    "            res.append(x)\n",
    "            res.append(y)\n",
    "        landmarks.append((np.asarray(res)/face_dim+1)/2)\n",
    "    if len(landmarks)>0:\n",
    "        y_out=model.predict(np.asarray(landmarks))\n",
    "        res=np.argmax(y_out,axis=1)\n",
    "        for r in res:\n",
    "            cv2.putText(img,emotions[r],(xp,yp),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
