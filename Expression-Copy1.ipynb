{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../face_recognition/haarcascade_frontalface_default.xml')\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH=\"../facial_expressions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=[\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(IMG_PATH+\"icml_face_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(to_replace=\"PrivateTest\",value=\"Testing\")\n",
    "df=df.replace(to_replace=\"PublicTest\",value=\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>Testing</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>Testing</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>Testing</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>Testing</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion     Usage                                             pixels\n",
       "0            0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1            0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2            2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3            4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4            6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
       "...        ...       ...                                                ...\n",
       "35882        6   Testing  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
       "35883        3   Testing  178 174 172 173 181 188 191 194 196 199 200 20...\n",
       "35884        0   Testing  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
       "35885        3   Testing  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
       "35886        2   Testing  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
       "\n",
       "[35887 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"Training\":[],\"Testing\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35887  4965      32797  "
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    print(\"\\r\",i+1,end=\" \")\n",
    "    row=df.iloc[i]\n",
    "    img=np.array(list(map(np.uint8,row[2].split()))).reshape(48,48)\n",
    "    data[row[1]].append([row[0],ret_keypoints(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\",\"wb\") as f:\n",
    "    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_keypoints(image):\n",
    "    gray=image\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (face_dim, face_dim))\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    param=[0,0,face_dim,face_dim]\n",
    "    shape=predictor(gray,dlib.rectangle(*param))\n",
    "    xlist=[]\n",
    "    ylist=[]\n",
    "    for i in range(68):\n",
    "        xlist.append(np.float32(shape.part(i).x))\n",
    "        ylist.append(np.float32(shape.part(i).y))\n",
    "    xmean = np.mean(xlist)\n",
    "    ymean = np.mean(ylist)\n",
    "#     plt.imshow(gray,cmap='gray')\n",
    "#     plt.scatter(xlist,ylist, marker='.')\n",
    "#     plt.show()\n",
    "    xcentral = [(x-xmean) for x in xlist]\n",
    "    ycentral = [(y-ymean) for y in ylist]\n",
    "    res=[]\n",
    "    for (x,y) in zip(xcentral,ycentral):\n",
    "        res.append(x)\n",
    "        res.append(y)\n",
    "    return (np.asarray(res)/face_dim+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=np.arange(len(XXD))\n",
    "# for i in range(5):\n",
    "#     np.random.shuffle(s)\n",
    "#     XXD=XXD[s]\n",
    "#     YYD=YYD[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,activation='relu', input_shape=(68*2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(emotions),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              140288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 837,895\n",
      "Trainable params: 834,055\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "XDB=np.vstack(np.asarray(data[\"Training\"])[:,1])\n",
    "YDY=np.asarray(data[\"Training\"])[:,0]\n",
    "YDB=np.zeros((len(YDY),len(emotions)))\n",
    "for i in range(len(YDB)):\n",
    "    YDB[i][YDY[i]]=1\n",
    "XTB=np.vstack(np.asarray(data[\"Testing\"])[:,1])\n",
    "YTY=np.asarray(data[\"Testing\"])[:,0]\n",
    "YTB=np.zeros((len(YTY),len(emotions)))\n",
    "for i in range(len(YTB)):\n",
    "    YTB[i][YTY[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32298 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "32298/32298 [==============================] - 11s 330us/sample - loss: 1.7338 - accuracy: 0.3588 - val_loss: 1.6107 - val_accuracy: 0.3550\n",
      "Epoch 2/100\n",
      "32298/32298 [==============================] - 10s 295us/sample - loss: 1.5031 - accuracy: 0.4248 - val_loss: 1.5522 - val_accuracy: 0.3968\n",
      "Epoch 3/100\n",
      "32298/32298 [==============================] - 10s 298us/sample - loss: 1.4679 - accuracy: 0.4372 - val_loss: 1.5718 - val_accuracy: 0.3678\n",
      "Epoch 4/100\n",
      "32298/32298 [==============================] - 10s 320us/sample - loss: 1.4493 - accuracy: 0.4432 - val_loss: 1.6192 - val_accuracy: 0.3722\n",
      "Epoch 5/100\n",
      "32298/32298 [==============================] - 11s 332us/sample - loss: 1.4409 - accuracy: 0.4463 - val_loss: 1.4759 - val_accuracy: 0.4218\n",
      "Epoch 6/100\n",
      "32298/32298 [==============================] - 11s 344us/sample - loss: 1.4355 - accuracy: 0.4459 - val_loss: 1.4650 - val_accuracy: 0.4441\n",
      "Epoch 7/100\n",
      "32298/32298 [==============================] - 11s 336us/sample - loss: 1.4264 - accuracy: 0.4504 - val_loss: 1.7180 - val_accuracy: 0.3009\n",
      "Epoch 8/100\n",
      "32298/32298 [==============================] - 11s 343us/sample - loss: 1.4174 - accuracy: 0.4541 - val_loss: 1.3801 - val_accuracy: 0.4673\n",
      "Epoch 9/100\n",
      "32298/32298 [==============================] - 11s 346us/sample - loss: 1.4130 - accuracy: 0.4582 - val_loss: 1.3921 - val_accuracy: 0.4483\n",
      "Epoch 10/100\n",
      "32298/32298 [==============================] - 11s 337us/sample - loss: 1.4058 - accuracy: 0.4589 - val_loss: 1.8353 - val_accuracy: 0.3589\n",
      "Epoch 11/100\n",
      "32298/32298 [==============================] - 13s 393us/sample - loss: 1.4029 - accuracy: 0.4608 - val_loss: 1.6905 - val_accuracy: 0.3374\n",
      "Epoch 12/100\n",
      "32298/32298 [==============================] - 13s 395us/sample - loss: 1.4011 - accuracy: 0.4601 - val_loss: 1.5107 - val_accuracy: 0.4015\n",
      "Epoch 13/100\n",
      "32298/32298 [==============================] - 13s 388us/sample - loss: 1.3912 - accuracy: 0.4643 - val_loss: 1.5232 - val_accuracy: 0.4140\n",
      "Epoch 14/100\n",
      "32298/32298 [==============================] - 12s 370us/sample - loss: 1.3880 - accuracy: 0.4660 - val_loss: 1.4414 - val_accuracy: 0.4394\n",
      "Epoch 15/100\n",
      "32298/32298 [==============================] - 10s 299us/sample - loss: 1.3867 - accuracy: 0.4648 - val_loss: 1.6235 - val_accuracy: 0.3500\n",
      "Epoch 16/100\n",
      "32298/32298 [==============================] - 9s 281us/sample - loss: 1.3790 - accuracy: 0.4667 - val_loss: 1.5724 - val_accuracy: 0.3806\n",
      "Epoch 17/100\n",
      "32298/32298 [==============================] - 10s 307us/sample - loss: 1.3786 - accuracy: 0.4691 - val_loss: 1.5534 - val_accuracy: 0.3792\n",
      "Epoch 18/100\n",
      "32298/32298 [==============================] - 11s 341us/sample - loss: 1.3765 - accuracy: 0.4714 - val_loss: 1.4094 - val_accuracy: 0.4430\n",
      "Epoch 19/100\n",
      "22432/32298 [===================>..........] - ETA: 2s - loss: 1.3684 - accuracy: 0.4728"
     ]
    }
   ],
   "source": [
    "model.fit(XDB,YDB,batch_size=32,epochs=100,validation_data=(XTB,YTB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.325"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(XTB).argmax(axis=1)==YTB.argmax(axis=1)).sum()/len(XTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 5, 2, 5, 3, 2, 5, 2, 0, 2, 2, 5, 3, 2, 3, 3, 5, 2, 2,\n",
       "       2, 5, 3, 3, 3, 5, 3, 2, 5, 5, 3, 2, 3, 2, 3, 3, 2, 2, 3, 2, 0, 3,\n",
       "       2, 3, 2, 2, 5, 4, 3, 2, 2, 2, 3, 2, 5, 2, 2, 3, 5, 3, 2, 2, 3, 2,\n",
       "       3, 2, 2, 2, 0, 5, 3, 3, 2, 3, 2, 5, 5, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(XTB).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 0, 5, 4, 5, 2, 5, 5, 4, 1, 0, 5, 5, 3, 5, 3, 0, 0, 0, 0,\n",
       "       4, 0, 3, 3, 0, 2, 3, 5, 3, 0, 0, 5, 1, 4, 2, 3, 0, 1, 3, 1, 0, 2,\n",
       "       2, 4, 0, 5, 0, 0, 4, 2, 4, 1, 3, 5, 5, 0, 4, 1, 5, 3, 3, 5, 0, 4,\n",
       "       0, 0, 2, 4, 0, 5, 1, 1, 4, 4, 2, 0, 5, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTB.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 231 201 186 186\n",
      "[] 230 201 187 187\n",
      "[] 233 201 185 185\n",
      "[] 231 201 186 186\n",
      "[] 230 200 188 188\n",
      "[] 224 196 196 196\n",
      "[] 225 197 190 190\n",
      "[] 223 196 196 196\n",
      "[] 222 196 196 196\n",
      "[] 224 195 196 196\n",
      "[] 222 196 196 196\n",
      "[] 222 196 196 196\n",
      "[] 225 198 192 192\n",
      "[] 224 196 196 196\n",
      "[] 224 196 196 196\n",
      "[] 223 196 196 196\n",
      "[] 82 202 116 116\n",
      "[] 80 203 116 116\n",
      "[] 228 201 192 192\n",
      "[] 226 199 196 196\n",
      "[] 225 197 196 196\n",
      "[] 224 196 196 196\n",
      "[] 224 196 196 196\n",
      "[] 224 195 196 196\n",
      "[] 225 195 196 196\n",
      "[] 222 196 196 196\n",
      "[] 224 196 196 196\n",
      "[] 225 197 196 196\n",
      "[] 225 196 196 196\n",
      "[] 226 196 196 196\n",
      "[] 222 197 196 196\n",
      "[] 229 199 192 192\n",
      "[] 226 199 196 196\n",
      "[] 226 201 192 192\n",
      "[] 227 201 189 189\n",
      "[] 223 199 196 196\n",
      "[] 224 201 191 191\n",
      "[] 219 199 196 196\n",
      "[] 68 203 112 112\n",
      "[] 220 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 224 203 196 196\n",
      "[] 225 202 192 192\n",
      "[] 66 202 112 112\n",
      "[] 221 203 196 196\n",
      "[] 223 202 196 196\n",
      "[] 225 203 192 192\n",
      "[] 220 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 222 199 201 201\n",
      "[] 222 200 196 196\n",
      "[] 222 200 196 196\n",
      "[] 220 200 196 196\n",
      "[] 69 206 109 109\n",
      "[] 65 205 112 112\n",
      "[] 221 200 196 196\n",
      "[] 221 200 196 196\n",
      "[] 67 206 110 110\n",
      "[] 227 200 192 192\n",
      "[] 225 197 192 192\n",
      "[] 228 200 183 183\n",
      "[] 227 199 184 184\n",
      "[] 232 201 178 178\n",
      "[] 234 198 181 181\n",
      "[] 234 199 182 182\n",
      "[] 235 196 185 185\n",
      "[] 240 196 186 186\n",
      "[] 244 198 183 183\n",
      "[] 252 199 180 180\n",
      "[] 247 193 190 190\n",
      "[] 250 191 190 190\n",
      "[] 250 197 184 184\n",
      "[] 249 196 188 188\n",
      "[] 252 198 182 182\n",
      "[] 250 200 181 181\n",
      "[] 242 191 192 192\n",
      "[] 238 195 192 192\n",
      "[] 239 195 190 190\n",
      "[] 54 202 120 120\n",
      "[] 238 194 190 190\n",
      "[] 239 199 183 183\n",
      "[] 237 192 196 196\n",
      "[] 239 197 187 187\n",
      "[] 235 194 193 193\n",
      "[] 36 204 127 127\n",
      "[] 240 196 189 189\n",
      "[] 244 194 190 190\n",
      "[] 245 196 188 188\n",
      "[] 242 199 185 185\n",
      "[] 239 194 192 192\n",
      "[] 242 198 186 186\n",
      "[] 240 197 188 188\n",
      "[] 244 198 189 189\n",
      "[] 243 198 189 189\n",
      "[] 247 202 183 183\n",
      "[] 243 197 192 192\n",
      "[] 242 199 188 188\n",
      "[] 240 194 196 196\n",
      "[] 243 195 193 193\n",
      "[] 340 176 174 174\n",
      "[] 60 199 116 116\n",
      "[] 347 183 182 182\n",
      "[] 347 178 190 190\n",
      "[] 346 179 190 190\n",
      "[] 352 186 183 183\n",
      "[] 348 182 184 184\n",
      "[] 344 180 188 188\n",
      "[] 346 189 174 174\n",
      "[] 455 238 158 158\n",
      "[] 119 235 114 114\n",
      "[] 113 234 117 117\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    landmarks=[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        svx,svy=x,y\n",
    "        gray=gray[y:y+h,x:x+w]\n",
    "        try:\n",
    "            gray=cv2.resize(gray, (face_dim, face_dim))\n",
    "        except:\n",
    "            print(gray,x,y,w,h)\n",
    "            continue\n",
    "        shape=predictor(gray,dlib.rectangle(0,0,face_dim,face_dim))\n",
    "        xlist=[]\n",
    "        ylist=[]\n",
    "        for i in range(68):\n",
    "            xp=shape.part(i).x\n",
    "            yp=shape.part(i).y\n",
    "            cv2.circle(gray, (xp, yp), 2, (255, 255, 255), -1)\n",
    "            xlist.append(float(xp))\n",
    "            ylist.append(float(yp))\n",
    "        cv2.imshow('gray',gray)\n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "        res=[]\n",
    "        for (x,y) in zip(xcentral,ycentral):\n",
    "            res.append(x)\n",
    "            res.append(y)\n",
    "        landmarks.append((np.asarray(res)/face_dim+1)/2)\n",
    "    if len(landmarks)>0:\n",
    "        y_out=model.predict(np.asarray(landmarks))\n",
    "        res=np.argmax(y_out,axis=1)\n",
    "        for r in res:\n",
    "            cv2.putText(img,emotions[r],(svx,svy),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
